# Deep Learning - Yann LeCun

# 개요

Deep Learning은 여러 처리 계층으로 구성된 계산 모델을 통해 여러 수준의 추상화를 가진 데이터의 표현을 학습할 수 있다. 이러한 방법은 음성 인식, 시각적 물체 인식, 물체 감지, 약물 발견, 유전체학 같은 많은 다른 영역에서 최첨단 기술을 크게 향상시켰다. Deep Learning은 역전파 알고리즘을 사용하여 기계가 이전 계층의 표현에서 각 계층의 표현을 계산하는 데 사용되는 내부 매개 변수를 어떻게 변경해야 하는지를 표시함으로써 대규모 데이터 세트의 복잡한 구조를 발견한다. 심층 컨볼루션 망은 이미지, 비디오, 음성 및 오디오 처리에 획기적인 발전을 가져온 반면, 반복 망은 텍스트와 음성 같은 순차적 데이터에 발전을 가져왔다.

## 목차

[**1. 서론**](#서론)     
[**2. Supervised learning(지도학습)**](#supervised-learning(지도학습))         
[**3. 여러 계층 아키텍처 교육을 위한 Backpropagation(역전파)**](#여러-계층-아키텍처-교육을-위한-backpropagation\(역전파))      
[**4. Convolutional neural networks(컨볼루션 신경망)**](#convolutional-neural-networks(컨볼루션-신경망))         
[**5. Deep Convolutional neural networks를 통한 이미지 이해**](#deep-convolutional-neural-networks를-통한-이미지-이해)           
[**6. 분산 표현 및 언어 처리**](#분산-표현-및-언어-처리)           
[**7. 반복 신경망**](#반복-신경망)                   
[**8. Deep Learning의 미래**](#deep-learning의-미래)            

# 서론

Machine Learning 기술은 현대 사회의 많은 측면(웹 검색, 소셜 네트워크의 콘텐츠 필터링, 전자상거래 웹 사이트의 권장 사항, 카메라와 스마트폰 같은 소비자 제품)에 힘을 실어 준다. Machine Learning 시스템은 이미지에서 물체를 식별하고, 음성을 텍스트로 기록하며, 뉴스 항목, 게시물, 제품을 사용자의 관심사와 일치시키고, 관련 검색 결과를 선택하는 데 사용된다. 점점 더 이러한 응용 프로그램은 Deep Learning이라는 기술 클래스를 사용한다.

기존의 Machine Learning 기법은 자연 데이터를 원시 형태로 처리하는 데 한계가 있었다. 패턴 인식 또는 Machine Learning 시스템을 구축하기 위해서는 학습 하위 시스템이 적절한 내부 표현 또는 특성 벡터로 원시 데이터(예: 이미지의 픽셀 값)를 변환하는 특성 추출기를 설계하기 위해 신중한 엔지니어링과 상당한 영역별 전문 지식이 필요했다. 이러한 분류기는 입력에서 패턴을 탐지하거나 분류할 수 있다. 

Representation Learning은 기계에 원시 데이터를 공급하고 탐지 또는 분류에 필요한 표현을 자동으로 검색할 수 있는 일련의 방법이다. Deep Learning 방법은 다양한 수준의 표현을 가진 Representation Learning 방법으로 각각 하나의 수준(원시 입력부터 시작)에서 표현을 더 높고, 추상적인 수준으로 변환하는 단순하지만 비선형적인 모듈을 구성함으로써 얻어진다. 이러한 변환이 충분히 구성되면 매우 복잡한 함수를 학습할 수 있다. 분류 작업의 경우, 더 높은 표현 계층은 차이의 중요한 입력 측면을 증폭시키고 관련 없는 변동을 억제한다. 예를 들어 이미지는 픽셀 값의 배열 형태로 제공된다. 첫 번째 표현 계층에서 학습된 특징은 일반적으로 이미지의 특정 방향과 위치에서 가장자리의 존재여부를 나타낸다. 두 번째 계층에서는 일반적으로 가장자리 위치의 작은 변동에 관계없이 가장자리의 특정 배열을 감지하여 디자인을 감지한다. 세 번째 계층은 디자인을 익숙한 계체의 일부에 해당하는 더 큰 조합으로 조합할 수 있고, 후속 계층은 이러한 일부의 조합으로 객체를 감지한다. **Deep Learning의 핵심 측면은 이러한 기능 계층이 인간에 의해 설계되지 않고, 범용 학습 절차를 통해 데이터에서 학습한다.**

Deep Learning은 수년 동안 인공지능 커뮤니티의 가장 어려웠던 문제를 해결하는데 큰 역할을 보이고 있다. Deep Learning은 고차원 데이터에서 복잡한 구조를 발견하는 데 매우 능숙한 것으로 밝혀졌으며 이는 많은 과학, 사업, 행정 분야에 적용할 수 있다. 그리고 이미지 인식과 음성 인식에서 기록을 능가하는 것 외에도, 잠재적인 약물 분자의 활동을 예측하고, 입자 가속기 데이터를 분석하고, 뇌 회로를 재구성하고, 비코딩 DNA의 돌연변이가 유전자 발현과 질병에 미치는 영향을 예측하는 다른 Machine Learning 기법들을 능가했다. 더 놀랍게도, Deep Learning은 자연어 이해, 특히 주제 분류, 감정 분석, 질문 답변 및 언어 번역의 다양한 작업에 대해 매우 유망한 결과를 낳았다.

우리는 Deep Learning이 수작업 엔지니어링을 거의 필요로 하지 않기 때문에 사용 가능한 계산과 데이터의 양의 증가를 쉽게 이용할 수 있기 때문에 가까운 미래에 더 많은 성공을 거둘 것이라고 생각한다. 현재 심층 신경망을 위해 개발 중인 새로운 학습 알고리즘과 아키텍처는 이 진전을 가속화한다. 

# Supervised learning(지도학습)
Machibe Learning의 가장 흔한 형태는 Supervised Learning이다. 이미지를 집, 자동차, 사람, 애완동물로 분류할 수 있는 시스템을 만들고 싶다고 상상해 보자. 우리는 먼저 집, 자동차, 사람, 애완동물의 대용량 데이터 세트를 수집한다. 각 이미지에는 해당 범주가 표시되어 있다. 훈련 중에서 기계가 이미지를 보여주고 점수 벡터 형태의 출력을 각 범주마다 하나씩 생성한다. 우리는 원하는 범주가 모든 범주 중에서 가장 높은 점수를 받기를 원하지만 훈련 전에는 이런 일이 일어날 것 같지 않다. 그래서 우리는 출력 점수와 원하는 점수 패턴 사이의 오차(또는 거리)를 측정하는 목표 함수를 계산한다. 그런 다음 기계가 내부 조정 가능한 파라미터를 수정하여 이 오류를 줄입니다. 가중치라고 불리는 이 조절 가능한 파라미터들은 기계의 입출력 기능을 정의하는 "손잡이"로 볼 수 있는 실수이다. 전형적인 Deep Learning 시스템에는 수억개의 이런 조절 가능한 가중치와 기계를 훈련시킬 수 있는 라벨이 붙은 예들이 들어있다. 가중치 벡터를 적절하게 조정하려면, 학습 알고리즘은 각각의 가중치에 대해 가중치가 증가하면서 오차가 얼마나 증가하거나 감소하는지를 나타내는 경사도 벡터를 계산하다. 그런 다음 가중치 벡터가 경사도 벡터와 반대 방향으로 조정된다.

모든 교육 예제의 걸쳐 평균을 낸 목표 기능은 가중치의 가치가 높은 고차원의 공간에서 일종의 경사 지대로 볼 수 있다. 음의 기울기 벡터는 이러한 지형에서 가장 가파른 하강 방향을 나타내기 때문에 낮을수록 출력 오류의 평균이 낮아진다. 

실제로 대부분의 실무자들은 **확률적 경사 하강법(SGD)** 이라는 철차를 사용한다. 이것은 몇 가지 예에 대한 입력 벡터를 보여주고, 출력과 오류를 계산하고, 그러한 예에 대한 평균 기울기를 계산하고, 그에 따라 가중치를 조정하는 것으로 구성된다. 이 프로세스는 목표 기능의 평균 감소가 멈출 때까지 교육 세트의 많은 예에 대해 반복됩니다. 각 예제 집합이 모든 예에 대한 평균 기울기의 노이즈를 추정하기 때문에 확률적이라 불린다. 이 간단한 절차는 일반적으로 훨씬 정교한 최적화 기술과 비교할 때 놀랄 만큼 빠르게 좋은 가중치 집합을 찾는다. 훈련 후, 시스템의 성능은 테스트 세트라고 하는 다른 예제로 측정된다. 이러한 학습 중 본 적이 없는 새로운 입력에 대한 합리적인 답번을 도출할 수 있는 능력은 기계의 일반화 능력을 테스트하는 데 도움이 된다. 

![1](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/Deep%20Learning/Deep%20Learning/Image/1.png?raw=true)

그림 1 : 다층 신경망 및 역전파

> **a.** 다중 계층 신경망(연결된 점으로 표시됨)은 입력 공간을 왜곡하여 데이터 클래스(빨간색과 파란색 라인에 있는 예)를 선형으로 분리할 수 있다. 입력 공간의 일반 격자무늬(왼쪽에 표시됨)도 숨겨진 단위에 의해 변환(중앙 패널에 표시됨)되는 방법을 참고한다. 이 그림은 2개의 입력 장치, 2개의 숨겨진 장치, 1개의 출력 장치로 구성되고, 사물 인식이나 자연어 처리에 사용되는 네트워크는 수만 또는 수십만 개를 포함한다. 이에 대한 자료는 [C.Olah](http://colah.github.io/)의 자료이다.

![6](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/Deep%20Learning/Deep%20Learning/Image/6.png?raw=true)

> **b.** 파생물의 연쇄 법칙은 x와 y, y와 z 간의 작은 변화가 어떻게 나타나는지 알려준다. Δx는 ∂y/∂x(부분 파생물의 정의)를 곱함으로써  Δy로 변환된다. 마찬가지로 Δy의 변화는 Δz를 변화시킨다. 이렇게 Δx에 ∂y/∂x와 ∂z/∂x를 곱하여 Δz로 변하는 방법과 같이 한 방정식을 다른 방정식으로 대체하면 파생물의 연쇄 규칙이 제시된다. 이 이론은 x, y, z가 벡터일 때도 작동한다. 

![7](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/Deep%20Learning/Deep%20Learning/Image/7.png?raw=true)

> **c.** 두 개의 숨겨진 계층과 하나의 출력 계층이 있는 신경망에서 앞으로 값을 전달하는 계산에 사용되는 방정식은 각각 경사도를 역전파할 수 있는 모듈을 구성한다. 각 계층은 각 유닛에 대한 아래 계층의 단위 출력의 가중치 합계인 총 입력 z를 계산하다. 그런 다음 비선형 함수 f()가 z에 적용되어 장치의 출력을 가져온다. 최근 몇 년 동안 다음과 같은 비선형 함수가 신경망에 사용되고 있다. 출력 계층에서, 유닛의 출력과 관련된 오류 파생은 비용 함수를 차별화함으로써 계산된다.
>> **ReLU 함수**          
   *f(z) = max(0,z)*           
   **Sigmoid 함수**         
   *f(z) =1/(1 + exp(−z))*         
   **logistic 함수**        
   *f(z) =(exp(z)− exp(−z))/(exp(z)+exp(−z))*
  
![8](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/Deep%20Learning/Deep%20Learning/Image/8.png?raw=true)
  
> **b.** 뒤로 값을 전달하는 계산에 사용하는 방정식이다. 각 은닉 계층에서 우리는 각 단위의 출력과 관련하여 오류 파생물을 계산한다. 이는 위 계층의 단위에 대한 총 입력과 관련된 오류 파생물의 가중 합계이다. 그런 다음 출력과 관련된 오류 파생물을 입력에 *f(z)* 의 경사도를 곱하여 오류 파생물로 변환한다. 이러게 하면 유닛 *l*에 대한 비용 함수가 *0.5(y<sub>l</sub>-t<sub>l</sub>)<sup>2</sup>* 이면, *y<sub>l</sub>-t<sub>l</sub>* 가 나온다. 여기서 t<sub>l</sub>은 목표값이다. *∂E/∂z<sub>k</sub>* 가 알려지면, 아래 층의 유닛 *j*에서 연결부의 가중치 *w<sub>jk</sub>* 에 대해 파생된 오차는 *y<sub>j</sub>∂E/∂z<sub>k</sub>* 가 된다.


현재 Machine Learning의 많은 실제 응용 프로그램은 수작업으로 설계된 특징 위에 선형 분류기를 사용한다. 2개의 클래스로 구성된 선형 분류기는 특징 벡터 성분의 가중 합계를 계산한다. 가중 합계가 임계값을 초과할 경우, 입력은 특정 범주에 속하는 것으로 분류된다. 

1960년대 이후 우리는 선형 분류기가 입력 공간을 매우 단순한 영역, 즉 초평면(선형 공간의 차원보다 한 단계 낮은 차원을 가진 부분 선형 공간을 평행 이동하여 얻은 평면)으로 분리된 반쪽 공간으로만 분할할 수 있다는 것을 알고 있었다. 그러나 이미지 및 음성 인식과 같은 문제는 입출력 기능이 특정 미세한 변화(예: 차이)에 매우 민감하면서 물체의 위치, 방향 또는 조도의 변화, 음조 또는 말투의 변화 등 입력의 관련되지 않은 변화에는 둔감해야 한다. 픽셀 수준에서 서로 다른 포즈와 다른 환경에서 두 사모예드의 이미지는 서로 매우 다를 수 있다. 반면에 같은 위치와 비슷한 배경에 있는 사모예드와 늑대의 두 이미지는 서로 매우 유사할 수 있다. 선형 분류기 또는 원시 픽셀에서 작동하는 다른 '얕은' 분류기는 앞의 두 분류기를 동일한 범주에 넣는 동안 후자의 두 분류기를 구분할 수 없다. 그렇기 때문에 얕은 분류기에는 선택성-불변성 딜레마를 해결하는 좋은 특징 추출기를 통해 차이에 대한 선별적인 표현을 생성하야 한다. 이러한 표현은 동물의 자세와 같은 무관한 측면에 의해서 변하면 안된다. 분류기를 더 강력하게 만들기 위해 커널 방법과 마찬가지로 일반적인 비선형 기능을 사용할 수 있다. 그러나 가우스 커널에서 발생하는 것과 같은 일반적인 특징들은 학습자가 훈련 예제에서 멀리 떨어진 곳에서 일반화하는 것을 허용하지 않는다. 기존의 방식은 우수한 기능 추출기를 직접 설계하는 것이며, 이는 상당한 양의 엔지니어링 기술과 영역별 전문 지식을 필요로 한다. 그러나 범용 학습 절차를 사용하여 좋은 기능을 자동으로 학습할 수 있다면 이 모든 것을 피할 수 있다. 이것인 Deep Learning의 주요 이점이다. 

Deep Learning 아키텍처는 학습의 대상이 되는 모든(또는 대부분의) 비선형 입력-출력 매핑을 계산하는 단순 모듈의 다중 계층 스택이다. 스택의 각 모듈은 입력 정보를 변환하여 표현의 선택성과 불변성을 모두 증가시킨다. 깊이가 5~20인 여러 개의 비선형 계층을 사용할 경우, 시스템은 동시에 민감한 입력의 매우 복잡한 기능을 구현할 수 있다. 예를 들어 사모예드와 흰 늑대를 구별하는 것에서 배경, 포즈, 조명, 주변 객체와 같은 관계 없는 큰 변형에는 무감각해 진다.

![2](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/Deep%20Learning/Deep%20Learning/Image/2.png?raw=true)

그림 2 : 컨볼루션 네트워크 내부

> 왼쪽 아래 사모예드 이미지에 적용되는 일반적인 컨볼루션 네트워크 아키텍쳐의 각 계층의 출력이다. 각 직사각형 이미지는 학습된 기능 중 하나에 대한 출력에 해당하는 기능 맵입니다. 정보는 아래에서 위로 흐르며, 하위 레벨 기능은 방향 가장자리 감지기로 작동하고, 점수는 출력의 각 이미지 클래스에 의해 계산된다.


# 여러 계층 아키텍처 교육을 위한 Backpropagation(역전파)

패턴 인식 초기부터 연구원들의 목적은 손으로 만든 기능을 훈련 가능한 다층 네트워크로 대체하는 것이었지만, 이 문제는 1980년대 중반까지 널리 이해되지 못했다. 위에서 이야기한 바와 같이 다층 아키텍처는 단순한 확률적 경사 하강에 의해 훈련될 수 있다. 모듈이 입력과 내부 가중치에 비교적 부드러운 기능을 제공한다면 역전파 절차를 이용하여 경사도를 계산할 수 있다. 이런 생각은 1970년대와 1980년대에 몇몇 다른 그룹들에 의해 독립적으로 발견되었다.

모듈 다층 스택의 가중치와 관련하여 목적 함수의 기울기를 계산하는 역전파 절차는 파생 모델에 대한 체인 규칙의 실용적인 적용에 지나지 않는다. 이것의 핵심은 모듈의 입력(또는 후속 모듈의 입력)과 관련하여 기울기에서 역방향으로 작업함으로써 모듈의 파생물(또는 기울기)을 계산할 수 있다는 것이다(그림 1 참조). 역전파 방정식은 모든 모듈을 통해 (네트워크가 예측을 생성하는) 상단의 출력에서 시작하여 (외부 입력이 공급되는) 하단으로 이동하면서 경사도를 전파하는 데 반복적으로 적용될 수 있다. 이러한 경사도를 계산한 후에는 각 모듈의 가중치에 대한 경사도를 계산하는 것이 간단해진다.

Deep Learning의 많은 응용 프로그램은 feed-forward 신경망 아키텍처(실행 전에 결함을 예측하고 행하는 피드백 과정의 제어)를 사용하여(그림 1 참조) 고정 크기 입력(예: 이미지)을 고정 크기 출력(예: 여러 범주에 대한 확률)에 매핑하는 방법을 배운다. 한 계층에서 다음 계층으로 이동하기 위해, 단위 집합은 이전 계층으로부터 입력의 가중 합계를 계산하고 비선형 함수를 통해 결과를 전달한다. 현재 가장 많이 사용되는 비선형 함수는 반파장 정류기인 ReLU(정류 선형 유닛)이다. 지난 수십 년 동안 신경망은 부드러운 비 선형성을 사용하는 tanh(z)나 1/(1+exp(−z))를 사용했다. 하지만 ReLU는 일반적으로 많은 계층이 있는 네트워크에서 훨씬 더 빨리 학습하여 비지도 사전 교육 없이 심층적인 감독 네트워크를 훈련할 수 있다. 입력 또는 출력 계층에 없는 단위를 은닉 계층아리고 한다. 은닉 계층은 마지막 계층에 의해 범주가 선형적으로 분리될 수 있도록 비선형 방식으로 입력을 왜곡하는 것으로 볼 수 있다(그림 1 참조).

1990년대 후반, 신경망과 역전파는 주로 Machine Learning 커뮤니티에 의해 버려졌고 컴퓨터 비전 및 음성 인식 커뮤니티에 의해 무시되었다. 사전 지식이 거의 없는 유용한 다단계 특징 추출기를 학습하는 것은 불가능하다고 널리 생각되었다. 특히, 일반적으로 단순한 경사 하강이 작은 변화 없이 평균 오차를 줄일 수 있는 가중치로 구성된 지역 최소치에 갇힐 것으로 생각되었다.

실제로, 열악한 지역 최소화는 대형 네트워크에서 거의 문제가 되지 않는다. 이러한 시스템은 초기 조건에 상관없이 시스템은 거의 항상 매우 유사한 품질의 해결책에 도달한다. 최근의 이론, 경험적 결과는 국소적 최소화가 일반적으로 심각한 문제가 아님을 강력히 시사한다. 대신 경사가 0인 안장점이 조합적으로 많은 지형이 채워지고, 표면은 대부분의 차원으로 곡선을 이룬다. 이러한 내용을 분석한 결과, 몇 개의 하향 곡면 방향만 있는 안장점이 매우 많이 존재하는 것으로 나타났지만 거의 모든 것들이 목적 함수의 유사한 가치를 가지고 있다. 따라서 알고리즘이 어느 안장 지점에 고착되는지는 그다지 중요하지 않다.

심층 feed-forward 네트워크에 대한 관심은 2006년 캐나다 고등 연구소(CIFAR)에 의해 되살아났다. 연구진은 라벨링된 데이터를 요구하지 않고 기능 검출기의 계층을 생성할 수 있는 비지도 학습 절차를 도입했다. 형상 검출기의 각 계층을 학습하는 목적은 아래 계층에서 형상 검출기(또는 원시 입력)의 활동을 재구성하거나 모델링하는 것이다. 이 재구성 목표를 사용하여 점진적으로 더 복잡한 형상 검출기의 여러 계층을 '사전 훈련'함으로써 심층 네트워크의 가중치는 합리적인 값으로 초기화될 수 있다. 그런 다음 출력 장치의 최종 계층 네트워크 상단에 추가되고 전체 심층 시스템이 표준 역전파를 사용하여 미세 조정될 수 있다. 이는 특히 손으로 쓴 숫자를 인식하거나 보행자를 감지하는 것과 같이 라벨링된 데이터의 양이 매우 제한적일 때 매우 효과적이었다.

이러한 사전 훈련 접근법은 음성 인식에 처음으로 적용되었다.  이는 프로그래밍이 편리하고 연구자들이 네트워크를 10배 또는 20배 더 빠르게 훈련할 수 있는 빠른 그래픽 처리 장치(GPU)의 출현으로 가능해졌다. 이 접근 방식은 음파에서 추출한 계수의 짧은 시간 창을 창 중앙의 프레임으로 나타낼 수 있는 다양한 음성 조각에 대한 확률 집합에 매팡하는데 사용되었다. 이것은 작은 어휘를 사용한 표준 음성 인식 벤치마크에서 기록적인 결과를 달성했고, 큰 어휘 작업에 대한 기록적 결과를 제공하기 위해 빠르게 개발되었다. 2009년의 딥넷 버전은 많은 주요 음성 그룹에 의해 개발되고 있었고 2012년 안드로이드 폰에 이미 배치되어 있었다. 소규모 데이터 세트에서 감독되지 않은 사전 훈련은 과적합을 방지하는 데 도움이 되며, 라벨링된 예제의 수가 적을 때 또는 일부 '소스' 작업에 대한 예는 많지만 일부 '대상' 작업에 대한 예는 거의 없는 전송 설정에서 훨씬 더 나은 일반화로 이어진다. Deep Learning이 재활성화된 후, 사전 교육 단계는 작은 데이터 세트에만 필요한 것으로 밝혀졌다.

그러나, 인접한 계층들 사이의 완전한 연결을 가진 네트워크보다 훨씬 더 훈련하기 쉽고 일반화된 특정한 유형의 심층 feed-forward 네트워크가 있었다. 이것은 Convolutional Neural Network(ConvNet)이다. 이것은 신경망의 인기가 떨어졌던 기간 동안 많은 실질적인 성공을 거두었고 최근 컴퓨터 비전 커뮤니티에 의해 널리 채택되었다.

# Convolutional neural networks(컨볼루션 신경망)

ConvNets은 여러 배열의 형태로 제공되는 데이터(예: 3가지 컬러 채널에서 픽셀 강도를 포함하는 3개의 2D 어레이로 구성된 컬러 이미지)를 처리하도록 설계되었다.

> 1D : 언어를 포함한 신호 및 순서         
  2D : 영상, 오디오 스펙트럼 프로그램         
  3D : 비디오, 볼륨 이미지
  
ConvNets 뒤에는 자연 신호의 속성을 활용하는 4가지 핵심 아이디어(지역 연결, 공유 가중치, 풀링, 많은 계층 사용)가 있다. 

일반적인 ConvNet의 아키텍처(그림 2 참조)는 일련의 단계로 구성된다. 처음 몇 단계는 두 가지 유형(컨볼루션 계층, 풀링 계층)의 레이어로 구성된다. 컨볼루션 계층의 단위는 특징 맵에서 구성되며, 각 단위는 필터 뱅크라는 가중치 집합을 통해 이전 계층의 특징 맵에서 지역 조각에 연결된다. 그런 다음 이 국소 가중 합계의 결과는 ReLU와 같은 비선형성을 통과한다. 모든 유닛은 특징 맵의 모든 단위가 동일한 필터 뱅크를 공유하고, 한 계층의 서로 다른 특징 맵은 서로 다른 필터 뱅크를 사용한다. 이러한 아키텍쳐를 사용하는 이유는 아래와 같다.

> 1. 이미지와 같은 배열 데이터에서 값의 지역 그룹이 높은 상관관계를 갖고, 쉽게 감지되는 고유한 지역 디자인을 형성한다.         
  2. 영상 및 기타 신호의 지역 통계는 불변한다.       

디자인이 이미지의 한 부분에 나타날 수 있다면 서로 다른 위치에 있는 장치들이 동일한 가중치를 공유하고 배열의 다른 부분에서 동일한 패턴을 감지할 수 있다. 그래서 형상도에 의해 수행되는 필터링 작업은 이산 컨볼루션 이라는 수학적인 이름이 붙었다. 

비록 컨볼루션 계층의 역할은 이전 레이어에서 형상의 로컬 연결을 감지하는 것이지만 풀링 계층의 역할은 의미론적으로 유사한 기능을 하나로 병합하는 것이다. 디자인을 형성하는 형상의 상대적 위치가 다소 다를 수 있기 때문에 각 형상의 위치를 거칠게 그려 디자인을 신뢰성 있게 검출할 수 있어야 한다. 일반적인 풀링 장치는 하나의 특징 맵(또는 몇 개의 특징 맵)에서 단위의 지역 조각의 최대값을 계산한다. 인접 풀링 유닛은 둘 이상의 행 또는 열에 의해 이동되는 조각으로부터 입력을 받아 표현 차원을 줄이고 작은 이동과 왜곡에 대한 불편성을 생성한다. 풀링으로 만들어진 비선형성 2,3단계 컨볼루션은 더 많은 컨볼루션 및 완전히 연결된 계층이 뒤따른다. ConvNet을 통해 경사도를 역전파하는 것은 일반 심층 네트워크를 통과하는 것만큼 간단하며, 모든 필터 뱅크의 모든 가중치를 훈련시킬 수 있다.

심층 신경망은 많은 자연 신호가 구성 계층이라는 특성을 활용하는데, 여기서 하위 수준을 구성함으로써 더 높은 수준의 특징을 얻는다. 이미지에서 가장자리의 국부적인 조합은 디자인을 형성하고, 디자인은 조각을 조립하고, 조각은 객체를 형성한다. 음성에서 전화, 음소, 음절, 단어 및 문장에 이르는 언어와 텍스트에도 유사한 계층이 존재한다. 풀링을 사용하면 이전 계층의 요소가 위치와 모양이 다를 때 표현이 거의 변경되지 않는다. 

ConvNets의 컨볼루션 및 풀링 계층은 시각적 신경 과학의 단순한 세포와 복잡한 세포의 고전적인 개념에서 영감을 받았다. 그리고 전체 아키텍쳐는 시각 피질 복부 경로 내부의 LGN–V1–V2–V4–IT 계층을 연상시킨다. ConvNet 모델과 원숭이에게 같은 그림을 보여줄 때 ConvNet에서 높은 레벨의 유닛의 활성화는 원숭이의 IT에서 160개의 뉴런들 중 무작위한 절반의 변화를 설명한다. ConvNets은 신인식기(신경 회로망에서의 패턴 인식 모델)에 뿌리를 두고 있다. 그러나 역전파와 같은 end-to-end 감독 학습 알고리즘은 가지고 있지 않다. 시간 지연 신경망이라 불리는 원시 1D ConvNet은 음소 및 간단한 단어의 인식에 사용되었다.

1990년대 초반에 수많은 컨볼루션 네트워크의 응용이 있었다. 이는 음성 인식 및 문서 읽기를 위한 시간 경과에 따른 신경망으로 시작한다. 문서 읽기 시스템은 언어 제약을 구현한 확률적 모델과 공동으로 훈련된 ConvNet을 사용했다. 많은 ConvNet 기반의 광학 문자 인식 및 필기 인식 시스템은 나중에 마이크로소프트에 의해 구현되었다. ConvNets는 또한 얼굴 인식을 위해 얼굴과 손을 포함한 자연 이미지에서 물체 감지가 연구되었다.

# Deep Convolutional neural networks를 통한 이미지 이해

# 분산 표현 및 언어 처리

# 반복 신경망

# Deep Learning의 미래
