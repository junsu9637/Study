# Deep Learning - Yann LeCun

# 개요

Deep Learning은 여러 처리 계층으로 구성된 계산 모델을 통해 여러 수준의 추상화를 가진 데이터의 표현을 학습할 수 있다. 이러한 방법은 음성 인식, 시각적 물체 인식, 물체 감지, 약물 발견, 유전체학 같은 많은 다른 영역에서 최첨단 기술을 크게 향상시켰다. Deep Learning은 역전파 알고리즘을 사용하여 기계가 이전 계층의 표현에서 각 계층의 표현을 계산하는 데 사용되는 내부 매개 변수를 어떻게 변경해야 하는지를 표시함으로써 대규모 데이터 세트의 복잡한 구조를 발견한다. 심층 컨볼루션 망은 이미지, 비디오, 음성 및 오디오 처리에 획기적인 발전을 가져온 반면, 반복 망은 텍스트와 음성 같은 순차적 데이터에 발전을 가져왔다.

# 서론

Machine Learning 기술은 현대 사회의 많은 측면(웹 검색, 소셜 네트워크의 콘텐츠 필터링, 전자상거래 웹 사이트의 권장 사항, 카메라와 스마트폰 같은 소비자 제품)에 힘을 실어 준다. Machine Learning 시스템은 이미지에서 물체를 식별하고, 음성을 텍스트로 기록하며, 뉴스 항목, 게시물, 제품을 사용자의 관심사와 일치시키고, 관련 검색 결과를 선택하는 데 사용된다. 점점 더 이러한 응용 프로그램은 Deep Learning이라는 기술 클래스를 사용한다.

기존의 Machine Learning 기법은 자연 데이터를 원시 형태로 처리하는 데 한계가 있었다. 패턴 인식 또는 Machine Learning 시스템을 구축하기 위해서는 학습 하위 시스템이 적절한 내부 표현 또는 특성 벡터로 원시 데이터(예: 이미지의 픽셀 값)를 변환하는 특성 추출기를 설계하기 위해 신중한 엔지니어링과 상당한 영역별 전문 지식이 필요했다. 이러한 분류기는 입력에서 패턴을 탐지하거나 분류할 수 있다. 

Representation Learning은 기계에 원시 데이터를 공급하고 탐지 또는 분류에 필요한 표현을 자동으로 검색할 수 있는 일련의 방법이다. Deep Learning 방법은 다양한 수준의 표현을 가진 Representation Learning 방법으로 각각 하나의 수준(원시 입력부터 시작)에서 표현을 더 높고, 추상적인 수준으로 변환하는 단순하지만 비선형적인 모듈을 구성함으로써 얻어진다. 이러한 변환이 충분히 구성되면 매우 복잡한 함수를 학습할 수 있다. 분류 작업의 경우, 더 높은 표현 계층은 차이의 중요한 입력 측면을 증폭시키고 관련 없는 변동을 억제한다. 예를 들어 이미지는 픽셀 값의 배열 형태로 제공된다. 첫 번째 표현 계층에서 학습된 특징은 일반적으로 이미지의 특정 방향과 위치에서 가장자리의 존재여부를 나타낸다. 두 번째 계층에서는 일반적으로 가장자리 위치의 작은 변동에 관계없이 가장자리의 특정 배열을 감지하여 디자인을 감지한다. 세 번째 계층은 디자인을 익숙한 계체의 일부에 해당하는 더 큰 조합으로 조합할 수 있고, 후속 계층은 이러한 일부의 조합으로 객체를 감지한다. **Deep LEarning의 핵심 측면은 이러한 기능 계층이 인간에 의해 설계되지 않고, 범용 학습 절차를 통해 데이터에서 학습한다.**

Deep Learning은 수년 동안 인공지능 커뮤니티의 가장 어려웠던 문제를 해결하는데 큰 역할을 보이고 있다. Deep Learning은 고차원 데이터에서 복잡한 구조를 발견하는 데 매우 능숙한 것으로 밝혀졌으며 이는 많은 과학, 사업, 행정 분야에 적용할 수 있다. 그리고 이미지 인식과 음성 인식에서 기록을 능가하는 것 외에도, 잠재적인 약물 분자의 활동을 예측하고, 입자 가속기 데이터를 분석하고, 뇌 회로를 재구성하고, 비코딩 DNA의 돌연변이가 유전자 발현과 질병에 미치는 영향을 예측하는 다른 Machine Learning 기법들을 능가했다. 더 놀랍게도, Deep Learning은 자연어 이해, 특히 주제 분류, 감정 분석, 질문 답변 및 언어 번역의 다양한 작업에 대해 매우 유망한 결과를 낳았다.

우리는 Deep Learning이 수작업 엔지니어링을 거의 필요로 하지 않기 때문에 사용 가능한 계산과 데이터의 양의 증가를 쉽게 이용할 수 있기 때문에 가까운 미래에 더 많은 성공을 거둘 것이라고 생각한다. 현재 심층 신경망을 위해 개발 중인 새로운 학습 알고리즘과 아키텍처는 이 진전을 가속화한다. 

# Supervised learning(지도학습)
Machibe Learning의 가장 흔한 형태는 Supervised Learning이다. 이미지를 집, 자동차, 사람, 애완동물로 분류할 수 있는 시스템을 만들고 싶다고 상상해 보자. 우리는 먼저 집, 자동차, 사람, 애완동물의 대용량 데이터 세트를 수집한다. 각 이미지에는 해당 범주가 표시되어 있다. 훈련 중에서 기계가 이미지를 보여주고 점수 벡터 형태의 출력을 각 범주마다 하나씩 생성한다. 우리는 원하는 범주가 모든 범주 중에서 가장 높은 점수를 받기를 원하지만 훈련 전에는 이런 일이 일어날 것 같지 않다. 그래서 우리는 출력 점수와 원하는 점수 패턴 사이의 오차(또는 거리)를 측정하는 목표 함수를 계산한다. 그런 다음 기계가 내부 조정 가능한 파라미터를 수정하여 이 오류를 줄입니다. 가중치라고 불리는 이 조절 가능한 파라미터들은 기계의 입출력 기능을 정의하는 "손잡이"로 볼 수 있는 실수이다. 전형적인 Deep Learning 시스템에는 수억개의 이런 조절 가능한 가중치와 기계를 훈련시킬 수 있는 라벨이 붙은 예들이 들어있다. 가중치 벡터를 적절하게 조정하려면, 학습 알고리즘은 각각의 가중치에 대해 가중치가 증가하면서 오차가 얼마나 증가하거나 감소하는지를 나타내는 경사도 벡터를 계산하다. 그런 다음 가중치 벡터가 경사도 벡터와 반대 방향으로 조정된다.

모든 교육 예제의 걸쳐 평균을 낸 목표 기능은 가중치의 가치가 높은 고차원의 공간에서 일종의 경사 지대로 볼 수 있다. 음의 기울기 벡터는 이러한 지형에서 가장 가파른 하강 방향을 나타내기 때문에 낮을수록 출력 오류의 평균이 낮아진다. 

실제로 대부분의 실무자들은 **확률적 경사 하강법(SGD)** 이라는 철차를 사용한다. 이것은 몇 가지 예에 대한 입력 벡터를 보여주고, 출력과 오류를 계산하고, 그러한 예에 대한 평균 기울기를 계산하고, 그에 따라 가중치를 조정하는 것으로 구성된다. 이 프로세스는 목표 기능의 평균 감소가 멈출 때까지 교육 세트의 많은 예에 대해 반복됩니다. 각 예제 집합이 모든 예에 대한 평균 기울기의 노이즈를 추정하기 때문에 확률적이라 불린다. 이 간단한 절차는 일반적으로 훨씬 정교한 최적화 기술과 비교할 때 놀랄 만큼 빠르게 좋은 가중치 집합을 찾는다. 훈련 후, 시스템의 성능은 테스트 세트라고 하는 다른 예제로 측정된다. 이러한 학습 중 본 적이 없는 새로운 입력에 대한 합리적인 답번을 도출할 수 있는 능력은 기계의 일반화 능력을 테스트하는 데 도움이 된다. 

![1]()


현재 Machine Learning의 많은 실제 응용 프로그램은 수작업으로 설계된 특징 위에 선형 분류기를 사용한다. 2개의 클래스로 구성된 선형 분류기는 특징 벡터 성분의 가중 합계를 계산한다. 가중 합계가 임계값을 초과할 경우, 입력은 특정 범주에 속하는 것으로 분류된다. 

1960년대 이후 우리는 선형 분류기가 입력 공간을 매우 단순한 영역, 즉 초평면(선형 공간의 차원보다 한 단계 낮은 차원을 가진 부분 선형 공간을 평행 이동하여 얻은 평면)으로 분리된 반쪽 공간으로만 분할할 수 있다는 것을 알고 있었다. 그러나 이미지 및 음성 인식과 같은 문제는 입출력 기능이 특정 미세한 변화(예: 차이)에 매우 민감하면서 물체의 위치, 방향 또는 조도의 변화, 음조 또는 말투의 변화 등 입력의 관련되지 않은 변화에는 둔감해야 한다. 픽셀 수준에서 서로 다른 포즈와 다른 환경에서 두 사모예드의 이미지는 서로 매우 다를 수 있다. 반면에 같은 위치와 비슷한 배경에 있는 사모예드와 늑대의 두 이미지는 서로 매우 유사할 수 있다. 선형 분류기 또는 원시 픽셀에서 작동하는 다른 '얕은' 분류기는 앞의 두 분류기를 동일한 범주에 넣는 동안 후자의 두 분류기를 구분할 수 없다. 그렇기 때문에 얕은 분류기에는 선택성-불변성 딜레마를 해결하는 좋은 특징 추출기를 통해 차이에 대한 선별적인 표현을 생성하야 한다. 이러한 표현은 동물의 자세와 같은 무관한 측면에 의해서 변하면 안된다. 분류기를 더 강력하게 만들기 위해 커널 방법과 마찬가지로 일반적인 비선형 기능을 사용할 수 있다. 그러나 가우스 커널에서 발생하는 것과 같은 일반적인 특징들은 학습자가 훈련 예제에서 멀리 떨어진 곳에서 일반화하는 것을 허용하지 않는다. 기존의 방식은 우수한 기능 추출기를 직접 설계하는 것이며, 이는 상당한 양의 엔지니어링 기술과 영역별 전문 지식을 필요로 한다. 그러나 범용 학습 절차를 사용하여 좋은 기능을 자동으로 학습할 수 있다면 이 모든 것을 피할 수 있다. 이것인 Deep Learning의 주요 이점이다. 

Deep Learning 아키텍처는 학습의 대상이 되는 모든(또는 대부분의) 비선형 입력-출력 매핑을 계산하는 단순 모듈의 다중 계층 스택이다. 스택의 각 모듈은 입력 정보를 변환하여 표현의 선택성과 불변성을 모두 증가시킨다. 깊이가 5~20인 여러 개의 비선형 계층을 사용할 경우, 시스템은 동시에 민감한 입력의 매우 복잡한 기능을 구현할 수 있다. 예를 들어 사모예드와 흰 늑대를 구별하는 것에서 배경, 포즈, 조명, 주변 객체와 같은 관계 없는 큰 변형에는 무감각해 진다.

![2]()

# 여러 계층 아키텍처 교육을 위한 Backpropagation(역전파)




# Convolutional neural networks(컨볼루션 신경망)

# Deep Convolutional neural networks를 통한 이미지 이해

# 분산 표현 및 언어 처리

# 반복 신경망

# Deep Learning의 미래
