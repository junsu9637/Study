# On the Measure of Intelligence - Francois Chollet

지능의 척도에 관하여

## 개요

보다 지능적이고 인간다운 인공 시스템의 발전을 위해서는 패드백 신호를 따라가야 한다. 이러기 위해서는 인간과의 비교뿐만 아니라 두 시스템 간의 비교를 가능하게 하는 방법으로 지능을 정의하고 평가할 수 있어야 한다. 지난 100년간 심리학과 AI 분야를 넘나들며 지능을 정의하고 측정하려는 많은 시도들이 있었다. 우리는 암묵적으로 그들이 인도해 온 지능의 두 역사적 개념을 분명히 하면서 이러한 정의와 평가 접근법을 요약하고 비판적으로 평가한다. 현대 AI 커뮤니티는 여전히 특정 작업에만 AI와 인간이 보여주는 기술을 비교하면서 지능을 벤치마크 하는 경향이 있다. 기술은 사전 지식과 경험에 의해 크게 변형되기 때문에 주어진 작업에서 기술을 측정하는 것만으로는 지능을 측정하는 데 부족하다. 시스템 자체의 일반화 능력을 가리는 방식으로 무한한 사전 또는 무한한 교육 데이터를 통해 실험자는 시스템에 대한 임의 수준의 기술을 "구매"할 수 있다. 그런 다음 알고리즘 정보 이론을 기반으로 지능에 대한 새로운 공식 정의를 표현한다. 지능적 시스템을 특성화 할 때 고려해야할 중요한 요소로서의 지능은 기술과 평가간의 효율성으로 설명되고, *범위, 일반화, 문제, 선행 및 경험의 개념*을 강조한다. 이 정의를 사용하면서 우리는 일반적인 AI 벤치마크가 어떻게 보여야 하는지에 대한 일련의 지침을 제안한다. 최종적으로 추상화 및 추론 언어 집합(ARC)을 밀접하게 따르는 새로운 벤치마크를 제시한다. 이는 타고난 인간의 선입견에 최대한 근접하도록 설계된 명확한 선입견을 바탕으로 제작되었다. 우리는 ARC가 인간과 유사한 형태의 일반 유체 지능을 측정하는 데 사용될 수 있으며 AI 시스템과 인간 사이의 공정한 일반 지능 비교가 가능하게 한다고 주장한다.

# 1. 맥락과 역사

## 1.1 실행 가능한 지능의 정의 및 측정 필요성

1950년대 시작하여 수없이 반복되어온 AI 분야의 도전은 인간과 견줄 만한 지능으로 발전하는 것이다. 하지만 AI는 그 이후로 그 이상에 미치지 못하고 있다. 특정 업무에서 잘 수행하는 시스템을 엔지니어링할 수 있지만, 여전히 데이터가 부족하고, 훈련 데이터나 창작자의 가정으로부터 약간 벗어난 상황을 이해할 수 없고, 인간 연구자의 관여 없이 새로운 작업을 처리하기 위한 용도 변환을 할 수 없다는 한계를 지니고 있다. 

만약 AI의 성공이 작업별 시스템을 개발하는 것이었다면 좁고 근거가 있는 문맥 안에서만 우리의 목표를 정의하고 실행 가능한 방법으로 진행 상활을 측정할 수 있기 때문일 것이다. 목표의 정의와 평가 벤치마크는 과학적 발전의 가장 강력한 원동력 중 하나이다. 우리 분야의 발전시키기 위해서는 인간과 유사한 일반 지능과 지능의 양적 정의와 척도에 정밀해질 필요가 있다. 

이는 정확하지만 단순히 지능을 설명하거나 특징짓기 위한 정의와 척도는 아닐 것이다. 명확한 표적을 향한 길을 보여주는 객관적 기능으로서 도움이 될 만한 설명적 정의는 우리의 발전에 대한 신뢰할 수 있는 척도와 즉시 적용할 수는 없는새로운 접근법을 식별하고 강조하기 위한 방법으로서의 역할을 수행할 수 있다. 

지능의 상식적인 사전적 정의는 우리가 같은 개념에 대해 말하고 있는지 확인하는데 유용할 수 있다. 하지만 이는 실행 가능하거나, 설명하거나, 측정할 수 없기 때문에 우리의 목적에는 유용하지 않다. 마찬가지로 튜링 테스트와 많은 변형은 객관적으로 지능을 정의하고 측정하는 것을 완전히 배제하고 명확한 정의나 평가 규약을 가지고 있지 않은 신뢰할 수 없는 과제를 위탁하기 때문에  발전에 유용하지 않았다.

> *튜링의 이미테이션 게임은 주로 철학적인 논의에서 문자 그대로의 지능 테스트로서가 아닌 논쟁적인 장치로 의미되었다. AI분야 목표의 테스트 담당자로 오인되는 것은 아직도 진행 중인 문제이다.*

지능에 대해 이야기를 할 때 지능이 의미하는 것이 무엇인지에 대한 질문이 여전히 만족스러운 답을 얻지 못한다는 것은 우리 분야의 미성숙함을 보여주는 증거다. 이것을 엄격하게 정의하거나 이것에 대한 우리의 발전을 벤치마킹하는데 주의를 기울이지 않았다.  
 
> *지능의 정의와 평가 방법에 대한 일반적인 설문조사는 발표되지 않았다* <br>
  \- Legg, Hutte
  
Hernandez-Orallo는 AI 평가에 관한 종합적인 책 뿐만 아니라 평가 방법에 대한 광범위한 설무조사를 발표했다. 하지만 커뮤니티에서 대부분 무시되었다.

우리는 이러한 주의력 부족이 널리 알려진 명시적 정의의 부재가 암묵정 적의와 편견으로 대체되어서 생긴 실수라고 믿는다. 이러한 편견들은 오늘날에도 많은 연구를 요구하고 있다. 이 문서의 목적은 우리 분야가 연구해 온 암묵적 가정을 지적하고 중요한 편견을 수정하는 것이다. 그리고 발달 인지 심리학에서 현대적 통찰력을 활용하는 것과 인간다운 일반 지능을 위해 실행 가능한 공식 정의 및 측정 벤치마크를 제공한다.

## 1.2 지능의 정의 : 서로 다른 두 가지

지난 수십 년 동안 많은 공식적이거나 비공식적인 정보 정의가 제안되어 왔다. 하지만 이 정의에는 기존의 과학적 합의는 없었다. 이로 인해 Sternberg와 Detterman는 심리학자들에게 지능을 정의해 달라는 요쳥을 받았고, 서로 다른 대답을 하게 되었다. Legg와 Hutter은 70개 이상의 정의를 하나의 진술로 요약했다.
> *지능은 광범위한 환경에서 목표를 달성하는 객체의 능력을 측정한다.* <br>
  \- Legg, Hutter -

지능의 정의는 보편적이지만 분리되어있다. 이는 직무별 기술*"목표"* 에 중점을 둔 기술과 *"광범위한 환경에서"* 일반성과 적응에 초점을 맞추는 기술의 두가지 특성을 보인다. 지능형 에이전트는 다양한 작업에 걸쳐 높은 기술을 달성할 수 있다(예 : 다양한 비디오 게임에서 높은 점수 획득). 반드시 작업을 사전에 알 필요는 없다. 진정한 일반화를 달성하기 위해서는 에이전트가 새로운 작업을 처리하는 법을 배울 수 있어야 한다. 

이러한 두 가지 특성은 Catell의 유동성 및 결정성 지능 이론(Gf-Gc)에 연결된다.  Cattell-Horn-Caroll 이론(CHC)은 인간 인지 능력의 지배적인 이론의 한 축이 되었다. 그리고 이 분야가 시작된 이래로 인지과학에 깊은 영향을 미쳐온 인간 정신의 본질에 대한 두 개의 반대되는 견해와 밀접하게 관련되어 있다. 이 견해는 정신이 진화에 의해 발전된 특수 목적 메커니즘의 비교적 정적인 집합체이고, 오직 이것이 프로그램된 것을 배울 수 있고, 정신이 임의의 경험을 지식과 기술로 바꿀 수 있는 일반 목적의 "빈 슬레이트"라는 것이다. 

이 문서의 주요 내용은 AI 연구의 맥락에서 우리가 어떻게 지능을 개념화하고 평가해 왔는지에 대한 기초에 암묵적으로 존재해온 이 이중 정의를 파악하고 비판적으로 평가하는 것이다. 이는 확고해지는 기술과 다른 것에 대한 기술 습득 능력이다. 이러한 지적 맥락과 이것의 지속적인 영향을 이해하는 것은 우리가 현대적 관점에서 지능의 공식적인 정의를 제안하기 전에 필요한 단계이다.

### 1.2.1 업무별 기술 모음으로서의 지능

인간 본성에 대한 진화심리학의 견해는 인간 인지 기능의 상당 부분이 인간이 진화 과정에서 겪었던 특정한 문제를 해결하기 위해 생겨난 특수 목적 적응의 결과라는 것이다. 초기 AI 연구자의 이러한 생각들이 인지심리학에서 두각을 나타내고 있다. 논리 연산자에 의존하고, 학습된 지식을 데이터베이스와 같은 메모리에 저장하는 전자컴퓨터에서 정적인 프로그램 같은 일련의 일상으로서의 지능을 볼 수 있을 것이다. 

> *수직적으로 넚은 집합체로서의 정신에 대한 미래는 "지능"을 집합적으로 구현하는 상대적인 정적 프로그램이다.*
  \- Marvin Minsky -

Marvin Minsky의 견해는 작업별 성능에 초점을 맞춘 지능에 대한 지능 및 평가 규정의 정의를 만들었다. 이 정의는 AI 커뮤니티 내에서 인간의 기술을 공식 규칙으로 인코딩하고 인간의 지식을 명시적 데이터베이스로 인코딩할 수 있다면 "지능의 문제"가 해결된다는 것으로 널리 받아들여졌다.

> *AI는 지능을 필요로 하는 작업을 수행할 수 있는 기계를 만드는 과학이다.*
  - Marvin Minsky -
  
이러한 지능의 관점은 한때 매우 지배적이었기 때문에 1980년대 중반까지 AI 교과서에 "학습(순수한 암기)"이 전혀 언급되지 않는 경우가 많았다. AI의 일반론을 옹호했던 McCarthy조차 일반성을 달성하는 열쇠는 더 나은 지식이 기반이 되어야 한다고 믿었다. 이 정의와 평가 철학은 일반적으로 인간이 다루는 좁은 작업에서의 기술에 초점을 두고 오늘날까지 이어지는 역설로 이어졌다.

> *인공지능 분야는 지능을 나타내지 않고 이러한 작업을 수행하는 인공 시스템을 개발하는 데 매우 성공적이었다.*
  \- Hernandez-Orallo -

### 1.2.2 일반 학습 능력으로서의 지능

많은 연구자들은 지능이 학습을 통해 새로운 기술을 습득하는 일반적인 능력에 있다는 입장을 취했다. 이 능력은 이전에 알려지지 않았던 광범위한 문제나 어떤 문제라도 발생시킬 수 있다. Hernandez-Orallo는 Minsky의 업무 중심 AI 정의를 통해 McCarthy에서 AI를 정의했다. 

> *AI는 기계가 본 적도 없고 사전에 준비되지 않은 작업을 하도록 만드는 과학과 공학이다.*
  \- Hernandez-Orallo -
  
기계가 인간의 어린이와 유사한 학습 과정을 통해 새로운 기술을 습득할 수 있다는 개념은 1950년 논문에서 처음 제시되었다. 

> *만약 우리가 인간의 언어를 말하고, 이해하고, 번역하고, 상상력으로 수학 문제를 풀고, 조직을 지휘하는 기계를 만든다면 우리는 이러한 활동을 과학으로 줄여 기계에게 정확히 어떻게 해야 하는지 방법을 알리지 않고 일을 처리할 수 있도록 해야한다.*
  \- Friedberg -
  
그러나 학문을 통한 일반성에 대한 생각은 그 분야의 탄생에서 중요한 문제기 발생했다. 이는 McCarthy와 Papert와 같은 분야 개척자들에게 의해 오랫동안 옹호되어왔지만 1980년대에 Machine Learning이 부활하면서 표면으로 올라오게되었다. 

지능에 대한 이러한 견해는 인지 과학의 역사에 지대한 영향을 끼친 인간의 본성에 대한 또 다른 개념을 반영하고 있다. 이 개념은 경험을 행동, 지식, 기술로 바꾸는 유연하고 적응력이 뛰어난 일반적인 과정으로서의 정신의 미래에 대한 심리학적인 관점과는 대조된다. 이러한 인간 정신의 개념은 아리스토텔레스로 인해 시작되었고, Hobebs, Locke, Rousseau와 같은 계몽주의 사상가들에 의해 받아들여지고 대중화 되었다. 최근에는 연결주의를 통해 인지심리학과 AI에서 대중화가 이루어지고 있다.

1980년대의 Machine Learning의 부활과 2000년대에 지적 재배력의 상승은 2010년대 후반 Deep Learning을 통해 AI의 지적 독점으로서 최고조를 달성했다. 연결론자에서 영감을 받은 Tabula Rasa는 AI 연구가 이루어지고 있는 지배적인 프레임워크가 되어가고 있다. 많은 연구자들은 아무것도 없이 시작하고 "훈련 데이터"에서 기술을 도출하는 "랜덤하게 초기화된 신경망"의 비유를 통해 암묵적으로 정신을 개념화하고 있다. 

특수 목적 프로그램 집합 Tabula Rasa와 같은 인간 지능의 본질에 대한 두 가지 관점이 모두 정확하지 않을 가능성이 점점 더 명백해지고 있으며, 우리는 인공지능에 대한 영향을 2.1.3에서 논의한다.

## 1.3 AI 평가 : 기술 측정부터 능력 측정까지

이러한 두 가지 지능 개념화는 인간의 각 측면의 요소를 결합하는 다른 많은 중간 관점과 함께 기계에서 지능을 평가하기 위한 다수의 접근 방식에 영향을 미쳤다. 이 문서는 AI 평가 방법에 대한 광범위한 조사를 의미하는 것은 아니다.  

### 1.3.1 기술 기반 좁은 AI 평가

AI에 대한 Minsky의 목표에 따라 이 분야의 주요 성공은 좁고 잘 다듬어진 작업을 처리할 수 있는 특수 목적 시스템을 구축하는데 있다. 이러한 성공은 주어진 작업에서 시스템의 기술을 정량화하는 성능 조치에 의해 주도되었다(예: AI의 체스, 이미지 분류). 기술 기반 평가를 수행할 수 있는 공식화된 단일 방법은 없지만 역사적으로 성공적인 접근 방식은 아래와 같다.

> **인간의 검토** <br>
  인간의 검토는 시스템의 입출력 반응을 관찰하고 점수를 매기는 것이다. 이것은 튜링 테스트와 그 변형에 대한 아이디어다. 이 평가는 비용이 많이 들고 자동화가 불가능하며 주관적이기 때문에 실제로 거의 사용되지 않는다. 일부 인간과 직접 대면하는 AI 시스템은 이를 다중 평가 메커니즘의 하나로 사용한다.
  
> **화이트 박스 분석** <br>
  화이트 박스 분석은 입력-출력 응답을 결정하고 점수를 매기기 위한 시스템 구현 검사이다. 이는 모든 가능한 입력을 명시적으로 열겨하거나 분석적으로 설명할 수 있는 환경에서 완전히 기술된 작업을 해결하는 알고리즘과 관련이 있고, 종종 최적성을 입증하곤 했다.
  
> **동료 대립** <br>
  동료 대립은 시스템이 다른 AI 또는 인간과 경쟁하도록 하는 방법이다. 이것은 체스와 같은 플레이어 대 플레이어 게임에서 선호되는 평가 모드이다. 
  
> **벤치마크** <br>
  벤치마크는 시스템이 원하는 결과를 알 수 있는 입력 또는 환경의 "테이블 세트"에 대한 출력을 생성하고 이에 대한 점수를 매기는 방식이다.

벤치마크는 재현 가능성(테스트 세트가 고정), 공정성(테스트 세트는 모두에게 동일), 확장 가능성(평가를 여러번 실행하는 것이 저렴), 설정이 용이하며 광범위한 작업에 적용할 수 있을 정도로 유연하기 때문에 AI의 발전을 이끄는 주요 원동력이 되었다. 벤치마크는 대규모 이미지 인식에 대한 ILSVRC 과제(ImageNet) 또는 자율 주행에 대한 DARPA Grand Challenge 과제와 같이 종종 서로 다른 연구 팀 간의 경쟁 상황에서 가장 큰 영향을 미쳤다. 이러한 벤치마크 기반 경쟁이 발전을 가속화시킨다는 전제 하에 ChaLearn과 같은 학문적 대안들 뿐만 아니라 다수의 민간 및 지역사회 주도 계획이 시작되었다. 그리고 일부 정부 기관들은 경쟁을 이용하여 기술적 발전을 촉발하기도 했다.

이러한 성공은 *명확한 목표를 설정하고 연구 커뮤니티 전반에 걸쳐 공유되는 목표 성과 척도를 채택*하는 것의 중요성을 보여준다. 그러나 단일 단위 계량 또는 일련의 단위 계량에 대해 최적화하는 것은 종종 측정 및 최적화되지 않는 모든 것에 대해 지름길을 제공한다. AI의 경우 시스템이 이 성능에 도달하는 방법에 아무런 조건도 두지 않으면서 작업별 성능을 달성하는 데 초점을 맞추는 것은 시스템이 목표를 잘 이루는데도 불구하고 AI 분야가 구축하기 시작한 인간 지능을 특징으로 하지 않는다. 

이는 McCorduck이 AI 발전에 나설 때마다 최종점이 움직이는 "AI 효과"라고 해석되어 왔다. 

> *컴퓨터가 어떻게 좋은 프로그램을 수행하는지 알아낼때마다 간단한 문제를 해결할 수 있다. 하지만 비교적 비공식적인 문제들은 비평가들의 뒷말이 있다.* <br>
  \- McCorduck -

> 기계가 어떻게 "지능"을 갖는지 알게 되면 이는 지능이라고 간주되지 않는다. 만약 내가 체스 챔피언을 이긴다면 나는 똑똑하다고 여겨질 것이다. <br>
  \- Reed - 

Reed의 해석은 지나치게 인간 중심적인 가정으로부터 발생한다. 인간으로서 우리는 일반적으로 기술을 효율적으로 습득할 수 있는 능력이 있어야만 특정 직무에서 높은 기술을 발휘할 수 있다. 이것은 2절에서 특징지어지는 지능에 해당한다. 아무도 체스를 알고 태어나거나 체스를 두는 경향이 있지 않다. 그러므로 만약 인간이 높은 수준에서 체스를 한다면 우리는 암묵적으로 그들이 일생 동안 특정 기술을 습득하기 위해 그들의 일반적인 지능을 사용해야만 했다는 것을 알고 있기 때문에 이 사람이 똑똑하다고 가정할 수 있다. 같은 방법으로 많은 다른 기술을 습득하는 것은 그들의 일반적인 능력을 반영한다. 그러나 같은 가정은 인간이 하는 것처럼 역략에 도달하지 않는 비인간 시스템에는 적용되지 않는다. X 기술에 지능을 입증하는 X 작업이 없고 기술을 습득하는 과정에 지능이 있다면 X가 실제로 광범위한 작업에 걸치 기술 습득과 관련된 메타 작업이 아닐 것이다. "AI 효과" 특성화는 (연구자들이 체스 게임 프로그램을 만드는 것에 의해 보여지는 지능과 같은) 지능의 과정과 이 과정 (결과적인 체스 게임 프로그램)에 의해 생성된 출력을 혼동하고 있다. 이는 지능의 과정과 이 과정의 출력물의 개념이 인간의 경우에는 근본적으로 얽여 있기 때문이다. 이에 관해서는 2.1절에서 더 논의한다.

직무별 성과는 처음에 명시한 대로 업무를 처리하는 것이 시스템의 최종 목표인 경우(성능 측정치가 시스템에 대해 우리가 기대하는 것과 정확하게 포착될 수 있는 경우)에만 효과적인 성공 척도다. 그러나 시스템 생성자가 계획하지 않은 상황을 처리하는데 자율성을 보여줄 수 있는 시스템이 필요할 때 더 이상 인간의 개입 없이 작업의 변화에 동적으로 적응하거나 변경할 수 있는 경우는 적다. 한편 견고성과 유연성은 점점 더 광범위한 특정 AI 하위 분야(L5 자율주행, 가정용 로봇, 개인 보조 장치 등)에 대한 중요한 조건으로 인식되고 있다. 이는 이러한 노력을 상용화하기 위해서는 기술 기반 평가를 넘어서야 한다는 것을 의미한다. 특히 교차 작업 환경에서 견고성과 유연성을 평가를 넘어서는 방법을 찾아야 한다. 하지만 견고함, 유연성, 일반성이 정말 무엇을 의미할까?

### 1.3.2 일반화의 스텍트럼 : 견고성, 유연성, 일반성

1980년대에 Machine Learning의 부활은 일반화를 공식적으로 정의, 측정, 최대화하는 데 관심을 증가시켰다. 일반화는 Machine Learning보다 앞선 개념으로 원래 통계 모델이 훈련 데이터의 일부가 아닌 입력에서 얼마나 잘 수행하는지 특징짓기 위해 개발되었다. 최근 Deep Learning의 성공은 Machine Learning의 맥락에서 일반화 이론에 대한 새로운 관심을 촉발시켰다. 일반화 개념은 다양한 맥락에서 공식적으로 정의될 수 있다. 특히 통계 학습 이론은 Machine Learning과 관련 있는 공식 정의를 제공하며 이에 대하여 2.2에서 일반적인 공식화를 제공한다. 우리는 모든 AI 시스템에 대해 "일반화" 또는 "일반화의 힘"을 비공식적으로 정의하여 "전에 직면했던 상황과 다른 상황을 처리할 수 있는 능력"을 광범위하게 의미할 수 있다. 

"사전에 접한 상황"의 개념은 다소 모호하기 때문에 우리가 다음과 같은 두 가지 유형의 일반화를 구별해야 한다. 

> **시스템 중심 일반화** <br>
  시스템 중심 일반화는 이전에 접하지 않았던 상황들을 다루는 학습 시스템 능력이다. 통계 학습 이론에서 일반화 오류의 공식 개념은 여기에 속한다. 
  - 만약 엔지니어가 Machine Learning 분류 알고리즘을 개발하여 N개의 샘플의 훈련 세트에 적합시킨다면, 이 학습 알고리즘의 "일반화"는 훈련 세트의 일부가 아닌 이미지에 대한 분류 오류를 참조할 수 있다.
  - 알고리즘 일반화의 힘은 부분적으로 시스템 개발자가 주입한 사전 지식에 의해 결정될 수 있다. 이러한 사전 지식은 이 일반화의 척도로 무시할 수 있다.
  
> **개발자 인식 일반화** <br>
  학습 시스템이나 고정 시스템은 시스템이나 시스템 개발자가 이전에 겪지 않았던 상황을 처리한다. 
  - 만약 엔지니어가 하드 코딩된 체험적인 규칙을 사용하는 정적 분류 알고리즘을 만들기 위해 N개의 샘플의 "개발 세트"를 사용한다면, 이 정적 알고리즘의 "일반화"는 "개발 세트"의 일부가 아닌 이미지에 대한 분류 오류를 참조한다. 
  - 시스템 개발자를 시스템의 일부로 포함하면 "개발자 인식 일반화"는 "시스템 중심 일반화"와 동일하다는 점에 유의한다.
  - "개발자 인식 일반화"는 시스템 개발자가 이 시스템에 주입한 모든 사전 지식을 설명하지만 "시스템 중심 일반화는 그렇지 않다."
  
이를 통해 우리는 정보 처리 시스템에 대한 일반화 정도를 질적으로 정의하는 것이 유용하다는 것을 알게 되었다.

> **일반화의 부재** <br>
  위에서 비공식적으로 정의한 일반화 개념은 근본적으로 새로움과 불확실성의 관련 개념에 의존한다. 시스템은 시스템이나 그것의 창조자에게 미리 알 수 없었던 새로운 정보들로만 일반화할 수 있다. 불확실성이 없는 AI 시스템은 일반화를 표시하지 않는다. 예를 들어 정확하다고 증명된 정렬 알고리즘은 모든 정수 목록에 "일반화"라고 말할 수 없다. 
  
> **지역 일반화 또는 "강건성"** <br>
  이는 단일 작업 또는 잘 알려진 작업 집합에 대해 알려진 분포로부터 충분한 표본 추출이 주어진 상태에서 새로운 점을 처리하는 시스템의 능력이다. 예를 들어 고양이를 포함하는 처음보는 이미지와 개를 포함하는 이미지를 구별할 수 있는 이미지 분류기가 여러 이미제이 대해 교육을 받는다면 이 기계가 지역 일반화를 수행한다고 할 수 있다. 이를 *"단일 작업 또는 잘 정의된 작업 집합 내에서 알려진 알 수 없는 작업에 대한 적응"* 으로 특성화할 수 있다. 이것이 1950년대부터 오늘날까지 Machinge Learning이 관심을 가져왔던 일반화의 한 형태이다. 
  
> **광범위한 일반화 또는 "유연성"** <br>
  이는 더 이상 인간의 개입 없이 광범위한 작업 및 환경을 처리할 수 있는 시스템의 능력이다. 여기에는 시스템 생성자가 예측할 수 없었던 상황을 처리할 수 있는 기능이 포함된다. 이는 광범위한 단일 영역에서 인간 수준 능력을 반영하는 것과 *"관련 업무의 광범위한 범주에 걸쳐 알려지지 않은 미지의 것에 대한 적응"* 으로 간주될 수 있다. 예를 들어 자율자동차 또는 Wozniak의 커피잔 테스트를 통과할 수 있는 로봇은 광범위한 일반화를 나타낸다고 말할 수 있다. 하지만 오늘날 가장 진보된 AI 시스템도 이 범주에 속하지 않는다. 
    
> **극단적인 일반화** <br>
  이는 이전에 접한 상황에서 추상적인 공통점을 공유해서 완전히 새로운 작업을 처리할 수 있는 광범위한 작업 및 영역에 적용 가능한 개방형 시스템이다. 이는 *"알 수 없는 범위의 작업 및 영역에 걸쳐 알려지지 않은 알 수 없는 것에 대한 적응"* 으로 특징지어질 수 있다. 생물학적 형태의 지능(인간과 다른 종)은 현재 이러한 시스템의 유일한 예이다. *인간 중심의 극단적 일반화*는 범위가 인간의 경험에 맞는 작업 및 영역의 공간이라고 간주되는 특정한 경우다. 우리는 "인간 중심 극단적 일반화"를 "일반성"이라고 부를 것이다. 우리가 여기에서 의도적으로 일반성을 정의함에 따라, 제한된 의미의 "일반"의 기준 프레임으로서 인간의 인식을 사용한다(이는 2.1.2에서 논의한다). 인간은 시스템 중심 일반화(작은 경험에서 나온 새로운 상황에 대한 빠른 적응성)와 개발자 인식 일반화(이전 인류가 진화 역사 동안 경험하지 못했던 상황을 처리하는 현대 인간의 능력) 측면에서 모두 극단적인 일반화를 보여준다. 

이러한 목표들에 이론적으로 *"보편성"* 을 추가할 수 있다. 보편성은 세계 내에서 실질적으로 문제될 수 있는 모든 작업에 대해 인간과 관련된 작업 영역의 범위 이상으로 "일반성"을 확장할 수 있다. 우리는 왜 보편성을 AI의 합리적인 목표로 생각하지 않는지 2.1.2에서 논한다. 

AI의 역사는 크게 일반화(기호적 AI)를 표시하지 않은 시스템에서 시작하여 국소적 일반화가 가능한 강력한 시스템(Machine Learning)으로 진화하는 등의 스펙트럼이 있다. 우리는 지금 광범위한 일반화가 가능한 유연한 시스템(AI 보조 장치 또는 하이브리드 기호 및 학습 시스템)의 새로운 단계로 접어들고 있다. 기술 중심 직무별 평가는 알려지지 않은 것만 특징인 환경에서 견고함을 목표로 하는 폐쇠형 시스템에 적합했고, 이를 개발하는 것은 일반적인 의미에서 그들의 능력을 평가해야 한다. 

위에서 설명한 일반화의 스텍트럼은 인지심리학에서 지능의 구조에 대한 이론에 의해 제시된 인간 인지 능력의 조직을 바탕으로 하는 것처럼 보인다. 인간 지능 구조의 주요 이론(CHC, g-VPR)은 아래 그림과 같이 모두 3개 층(CHC)이 있는 계층적인 방식으로 인지 능력을 조직한다.

![2-1](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/figure/2-1.png?raw=true)

위 그림은 인지 능력의 계층적 모델과 일반화의 스펙트럼에 대한 매핑을 나타낸다. 비록 능력의 분류법이 이론들 사이에 다르긴 하지만 최상위에는 일반 지능(g 인자), 중간에는 광범위한 능력, 최하위에는 전문화된 기술 또는 데스트 작업(광범위한 능력을 두 계층으로 나누는 g-VPR의 4계층으로 확장됨)에 해당한다. "극단적 일반화(extreme generalization)"는 g 인자에 해당하고, "광범위한 일반화(broad generalization)"는 광범위한 인지 능력에 해당한다. "지역 일반화(local generalization)"는 작업별 기술에 해당한다. 

특정 기술보다는 이러한 광범위한 능력(일반성 자체)을 측정한느 것은 역사적으로 심리측정학 분야에서 문제가 되어왔다. 심리측정학이 AI 시스템의 능력 평가를 알려줄 수 있는 지는 아래 사항을 참조하라.

> 우리는 "광범위한 능력"을 사용하여 광범위하거나 극단적인 일반화를 유도하는 인지 능력은 참조한다. 이러한 능력을 개발하는 것은 유연한 AI 또는 일반 AI에 관심이 있는 모든 연구자들의 목표가 되어야 한다. "광볌위한 능력"은 종종 "지역 일반화"에 반대되는 의미를 갖는다.
> 인간의 일반 지능(g 인자)은 매우 광범위한 인지 능력(능력 계층의 최상위)이기 때문에 "일반화"를 사용하여 지역 일반화를 시작으로 전체 일반화 스텍트럼을 참조한다.

### 1.3.3 광범위한 능력 및 일반 지능 측정 : 정신적 관점

Binet와 Simon는 20세기 초에 정신장애 아동과 행동장애 아동들을 구별하는 공식적인 방법을 찾다가 최초의 지능 테스트인 Binet-Simon와 심리측정학 분야를 설립했다. Spearman은 서로 관련이 없어 보이는 서로 다른 유형의 지능테스트에서 개별 결과가 상관관계가 있다는 것을 관찰하고 일반 지능의 단일 요인인 g 인자 가설을 세웠다. 오늘날 심리측정학은 그 분야의 가장 재현 가능한 결과에 도달한 심리학에서 잘 확립된 하위 분야이다. 현대 지능 테스트는 신뢰성과 관련된 엄격한 표준(낮은 측정 오류, 재현성과 관련된 개념), 유효성(측정하고자 하는 것을 측정하는 것, 통계적 일관성과 예측성에 관련된 계념), 표준화 및 편향으로부터 개발된다. 

심리측정학의 기본 개겸은 지능 테스트가 직무별 기술과 반대로 광범위한 인지 능력을 평가한다는 것이다. 지능 구조 이론(예: CHC, g-VPR)은 심리측정학 테스트와 함께 학습한다(테스트 결과에서 나타나는 현상들이 이러한 이론을 알려주고, 이론들이 테스트 설계의 정보를 제공한다). 이러한 능력은 앞에서 제시한 일반화 스텍트럼과 유사하게 계층적 방식으로 조작한다. 능력은 직접적으로 측정할 수 있는 것과는 반대로 개인 정신의 객관적 속성과 특정 시험의 점수와 같은 추상적인 구조이다. AI 분야에서의 폭넓은 능력은 심리측정학에서 인지능력과 정확히 같은 평가 문제에 빠졌다. 심리측정학에서는 단일 과제보다는 광범위한 시험 과제를 사용하여 능력 정량화와 확률론적 모델을 통한 테스트 결과 분석에 접근한다. 우리는 수험생들이 지능 테스트를 사전에 알지 못하고 연습하지 않는다고 가정한다. 이 접근법은 AI 평가와 매우 관련이 있다. 

심리측정학과 병행하여 더 큰 유연성을 목표로 하는 시스템을 평가하기 위해 광범위한 테스트 작업데 대한 AI 분야의 관심이 증가되고있다.
> Reinforcement Learning 에이전트를 위한 아케이드 학습 환경 <br> 
  MalmO <br>
  행동 스위치 또는 자연어 처리를 위한 GLUD 및 SuperGLUD 벤치마크 <br>
  
이러한 노력의 기본 논리는 목표 과제의 집합을 확대하여 특정 과제의 기술보다 더 일반적인 것을 측정하는 것이다. 그러나 융통성 평가에 관한 한 다중 작업 벤치마크의 중요한 결함은 작업 집합이 여전히 모든 시험 응시 시스템의 개발자에게 미리 알려져 있다. 그리고 시험 응시 시스템이 목표 과제에 대해 연습할 수 있고, 시스템 개발자에게서 받은 작업별 사전 지식을 활용하고, 사전 교육을 통해 얻은 외부 지식을 활용한다. 따라서 이러한 벤치마크는 직무별 기술 평갈르 더 많은 직무로 확대한다고 해서 질적으로 다른 종류의 평가가 산출되지 않기 때문에 여전히 게임성이 높은 것을 보인다. 이러한 벤치마크는 여전히 능력보다는 기술을 찾고 있다. 이는 벤치마크가 유용하지 않다는 것이 아니라 이러한 정적 다중 작업 벤치마크가 유연성이나 일반성을 직접 평가하지 않는다는 점에서 심리측정학적 접근법과 대조된다.

이러한 멀티티스킹 벤치마크 외에도 AI의 인지 능력을 위한 더 많은 테스트는 과거에 제안되었지만 실제로 구현되지는 않았다. 구체적인 구현 없이 여러 프로젝트를 해결하기 위해 시작한 능력 평가 문제를 다룰 수 있을지 여부를 평가하는 것은 어렵다. 근래에는 비슷하지만 특정 과제가 아닌 일반화 기능에 초첨을 맞춰 보다 성숙된 두 개의 테스트가 등장했다(Animal-AI Olympics, GVGAI).두 평가 모두 특수 목적의 기술보다는 학습 또는 계획 능력을 테스트하기 위해 보이지 않는 작업이나 게임에서 AI 에이전트를 평가해야 한다는 입장을 취한다. 그리고 둘 다 다중 게임 환경과 지속적인 공공 경쟁을 특징으로 한다. 

### 1.3.4 AI 평가 및 정신 측정의 통합

과제별 평가를 멀티태스킹 테스트로 확대하려는 노력 외에도 AI 평가와 정신 측정학을 통합하려는 직접적이고 명확한 시도가 있었다. 첫 번째 접근 방식은 기존의 정신 측정학 지능 테스트르 재사용하는 것이다. 이 방법은 AI 시스템의 지능을 평가하는 방법으로서 인간을 위해 처음 개발되었다. 1964년에 Evans는 채내측정 지능 테스트에서 발견될 수 있는 종류의 기하학적 유추 작업을 풀 수 있는 LISP라는 유추 프로그램을 제안했다. 그리고 1973년에 Newell의 논문 "자연에서의 20개의 문제 실행을 성공할 수 없다."와 2000년대 Bringsjord의 논문 "정신력 측정 AI(PAI)"에서 다시 제안되었다. 이러한 테스트에 사용된 테스크를 시스템 개발자가 사용할 수 있기 때문에 AI 시스템 개발자들이 인간 지능 테스트를 하는 것이 가능하다는 것이 명백해졌다. 따라서 개발자는 이러한 문제의 추상적 형태를 직접 해결하여 프로그램 형태로 문제 해결책을 하드 코딩할 수 있다. 이런 경우는 AI보다도 시험문제를 풀고 있는 시스템 개발자들에게 효과적이다. 정신 측정학 시험 설계자가 설정한 인간 시험 응시자에 대한 암묵적인 가정은 기계의 경우 시행하기 어려운 것으로 들어났다.

이러한 문제의 대안으로는 보다 유망한 접근 방식 설정이 있다. 
> *유망한 접근 방식은 능력 평가 및 테스트 설계에 대해 심리학이 우리에게 가르칠 수 있는 것을 활용하여 AI 시스템의 광범위한 능력 평가를 목표로 하는 새로운 유형의 벤치마크를 만드는 것이다.*
  \- Hernandez-Orallo - 

Hernandez-Orallo은 어떤 지능적인 시스템으로도 심리측정학 평가를 확장시킬 수 있는 "범용 정신 측정학"(AI 에이전트와 동물을 포함)을 제안했다. 

우리는 심리측정학의 몇 가지 중요한 원칙이 광범위한 AI와 일반 AI의 발전 맥락에서 AI의 지능 평가를 알릴 수 있다고 아래와 같이 주장한다.

> 능력 측정(광범위한 일반화 및 기술 습득 효율성)은 광범위한 일반화를 유도한다는 점에서 기술과 구별된다. 즉 광범위한 작업에 걸쳐 이전에는 기술 지원 시스템과 개발자가 알지 못했던 작업을 포함하는 기술의 기초를 형성한다. 
> 단일 작업이 아닌 여러 작업을 통한 작업 수행은 *시험 응시 시스템과 시스템 개발자 모두에게 사전에 알려져 있지 않아야 한다*(이것은 기술이나 지역 일반화와는 반대로 광범위한 일반화를 평가하는데 필요하다).
> 명시적 표준 : 신뢰성, 타당성, 표준화, 편견으로부터의 자유
>> **신뢰성**은 주어진 시스템에 대한 시험 결과가 시간 경과에 따라 연구 그룹에 걸쳐 재현될 수 있어야 함을 의미한다. 
>> **타당성**은 시험이 평가하는 것이 명확하게 이해되어야 함을 의미한다. 테스트 작성자는 "시험은 어떤 가정을 하는가", "시험은 무엇을 예측하는가", "성공적인 결과가 어떤 광범위한 능력을 보여줄 것이가", "이 시험은 이 능력들을 얼마나 잘 예측하는가"에 대해 답변할 수 있어야 한다. 
>> **표준화**는 광범위한 AI와 일반 AI를 추구하는 연구 커뮤니티의 하위 집합에 걸쳐 공유 벤치마크를 채택하는 것을 의미한다. 컴퓨터 비전과 자연어 처리의 표준 벤치마크는 이미 효과적인 발전 촉매제인 것으로 나타났다.
>> **편향으로부터의 자유**는 시험이 평가되는 능력에 직교하는 방식으로 시험 응시자 그불에 편향되어서는 안된다는 것을 의미한다. 예를 들어 인간과 AI 모두를 위해 설계된 지능 테스트는 인간이 획득한 고유 지능을 활용해서는 안되며, 지능과 무관한 제약 조건(예: 빠른 반응 시간)을 수반해서는 안된다.

동시에 우리는 AI에 대한 새로운 지능 테스트의 개발에서 심리학의 어떤 다른 측면들이 버려질 수 있다고 주장한다.

> 인지 심리학 내에서 진행중인 논쟁의 대상이 되는 지나치게 인간 중심적인 내용을 고려하는 인지 능력의 정확한 수와 분류 체계는 인위적인 인지 구조 및 그 평가를 위한 엄격한 템플릿으로 사용되어서는 안된다. 기존 분류법은 기껏해야 영감의 원천이 될 수 있다. 

> 경험을 통해 습득되는 능력인 심리 측정학의 지능 테스트에 의해 평가되는 많은 능력은 기술과 명확하게 구분할 수 없는 기술이다(효과적인 다목적 기술). 그러나 오히려 우리는 유연성과 일반성을 평가하려는 AI 테스트는 결정적인 능력을 고려하기 보다는 새로운 기술을 습득할 수 있는 능력에 초점을 맞춰야 한다고 주장한다. 만약 시스템이 영역에서 효율적인 기술 습득을 가능하게 하는 능력을 보유하고 있다면, 시스템은 상응하는 기술과 결정 능력을 개발하는 데 문제가 없어야한다. 

### 1.3.5 광범위한 AI 평가의 현재 동향

유연한 시스템 구축 또는 일반성 그 자체에 대한 관심이 높아졌음에도 불구하고, 대부분의 경우 AI 커뮤니티는 정신측정학 평가, 정신측정학 AI, 범용 정신측정학에는 별로 관심을 기울이지 않고 있다. 광범위한 AI 연구는 현재 주로 Reinforcement Learning(RL) 접근 방식에 의해 주도되기 때문에 우리가 광범위한 AI 평가의 현대 시대 정신을 평가할 수 있다. 평가에 대한 내용은 다음과 같다. 

> 우리는 몇가지 긍정적인 발전을 이루었다. 2017년 이후 Reinforcement Learning(RL) 알고리즘을 평가할 때 RL 에이전트들은 오랫동안 그들의 훈련 데이터에 대해 시험했던 것을  어떤 형태의 일반화로 구축해야 한다는 인식이 확산되고 있다.
> 아라티 게임이나 마인크래프트와 같은 게임을 위한 RL의 맥락에서 학습 알고리즘의 데이터 효율성 평가에 대한 관심이 높아지고 있다. 
> 1.3.3에서 언급한 바와 같이, 견고성과 유연성을 평가하는 방법으로 다중 작업 벤치마크를 활용하는 경향이 있다.

또한 우리는 몇 가지 부정적인 면에도 주목해야한다. Deep Learning 모델에서 개발 중인 시스템의 견고성은 종종 문제가 생긴다. 이는 대부분의 벤치마크가 공식적으로 견고성을 평가하고 일반화를 정량화하는데 크게 주의를 기울이지 않기 때문이다. 따라서 경사하강법을 적용하기 적합한 "추정"을 통해 해결할 수 있다(예: 컴퓨터 비전에서의 텍스트와 같은 표면 통계). 마찬가지로 Reinforcement Learning에서 연구 결과의 재현성(신뢰성)은 약간의 발전은 있지만 종종 문제가 된다.

가장 중요한 것은 지역 일반화를 넘어 결정적으로 어떤 능력에 대한 평가는 여전히 대체로 개발된 적 없는 분야다.  
> *능력 지향적이고 범용적인 평가 접근 방식은 여전히 매우 초기 단계이며, 더 많은 연구와 논의가 필요하다.*
  \- Hernandez-Orallo -
  
1.3.3절에서 논의한 바와 같이 여러 작업을 포함하여 작업별 벤치마크를 넓히려는 최근의 시도는 모든 작업이 시스템 개발자에게 미리 알려지는 개발자 인식 일반화를 측정하지 않는다. CoinRun이나 Obstacle Tower같은 이전에 보지 못한 게임 수준에서 RL 시스템을 테스트하여 일반화를 평가하려는 시도는 여전히 작업별 지역 일반화를 주목하고 실질적으로 새로운 작업을 사용하지 않으면서 분포로부터 새로운 표본에 대한 후보 시스템을 평가한다(3.3에서 제안된다). 게다가 사용되는 레벨 생성 프로그램이 AI 개발자들이 이용할 수 있다는 사실은 임의의 양의 훈련 데이터를 샘플링함으로써 이러한 벤치마크에서 "부정행위"가 가능하다는 것을 의미한다(2.1.1 참조).

더 나아가서 일반 지능을 향한 단계라고 알려진 현대 연구 "달 탐측선 발사"는 여전히 최고의 인간과 고도로 매개화 된 대결을 통해 보드 게임과 비디오 게임에 대한 기술 기반 작업별 평가에 초점을 맞추고 있는 것으로 보인다. 관련 틍신에서 일반 AI로 진일보한다는 주장에도 불구하고 이러한 평가는 일반화 능력 평가를 포함하지 않기 때문에 유연성과 일반성의 발달과 거의 겹치지 않는다(2.1 참조). 예를 들어 OpenAI의 DotA2를 할 수 있는 AL "Five"는 45,000년의 플레이를 훈련받아 인간 최고 선수들을 이길 수 있지만, 인간 선수들이 AI가 대응할 수 있게된 후 곧바로 새로운 전략을 찾을 수 있기 때문에 부서지기 쉽다고 판명되었다. 게다가 Five는 DorA2로 일반화하지도 않아서 제한된 버전의 게임만 할 수 있었다.

> *"Five"는 현실 세계의 복잡성과 불확실성을 처리할 수 있는 첨단 AI 시스템을 향한 단계이다.*
  \- OpenAI 공개 성명 -

한편으로는 기술 테스트에서 인간을 능가하는 것에 초점을 맞추는 것과 광범위한 능력을 개발하는 데 관심을 보이는 것 사이의 불일치에서 문제가 발생한다(기술이 달성되는 방법이 일반화 가능한지 여부는 완전히 무시한다). 또한 광범위한 인지 능력에 대한 적절한 조치와 기준의 부족 이후의 이러한 불일치가 지능, 기술, 일반화의 명확한 개념화 부족 때문이라고 가정한다. 그리고 우리는 유연한 AI와 일반적인 AI를 추구하기 위해 실행 가능한 지능에 대한 공식적인 정의를 제안한다. 

# 2. 새로운 관점

## 2.1 비판적 평가

### 2.1.1 올바른 것을 측정하는 것 : 기술을 평가하는 것만으로 우리는 발전하지 않는다.

1973년 심리학자이자 컴퓨터 과학의 선구자인 Allen Newell은 최근의 인지심리학 발전이 분야 인식의 총체적 이론에 더 가깝게 하지 못하는 것을 걱정했다. 이러한 걱정은 인지 아키텍쳐 모델링에 대한 연구에 대한 집중과 인간보다 뛰어난 인공지능을 구축하기 위한 연구에 새로운 추진력을 제공했다. 이후 24년 후인 1997년 IBM의 Deep Blue가 세계 최고의 체스 선수인 Gary Kasparov를 이기면서 이러한 탐구를 끝냈다. 연구원들은 인공 체스 챔피언을 만드는 것이 실제로 그들에게 인간 인식에 관하여 많은 것을 가르쳐주지 않았다는 것을 깨달았다. 그들은 체스를 두는 AI를 만드는 법을 배웠지만 이 지식이나 그들이 구축한 AI는 유사한 보드 게임 이외의 어떤 것으로도 일반화할 수 없었다.

현대적 관점에서 미니맥스와 트리 검색에 기반한 정적 체스 플레이 프로그램이 인간의 지능에 대해 유익하지 않다는 것이 명백해졌다. 즉 이것은 체스말고는 인간과 경쟁할 수 없다. 하지만 1970년대에는 많은 사람들은 이성적인 인간 사상의 전체 범위가 필요했다. 아마도 2019년에는 현대적인 Machine Learning 방법을 사용하여 복잡한 비디오 게임을 "해결"하려는 노력이 여전히 동일한 패턴을 따른다는 것이 덜 명백할 것이다. 

> *우리는 이미 기존 연구(인류에 대한 신학 연구)를 통해 작업(체스)이 추론과 검색의 형ㅊ태, 복잡한 지각 및 기억 프로세스를 포함한다는 것을 알고있다. 좀 더 일반적인 고려 사항에서 우리는 상황 평가, 방법 분석, 환경 재정립, 단기 사후 분석, 준비 분석 등이 수반될 것을 알고있다.*
  \- Newell - 
  
체스를 풀려면 이러한 일반적인 능력을 구현해야 한다는 가정이었다. 실제로 인간에게 이러한 능력들을 바탕으로 체스를 둔다. 이러한 일반적인 능력은 일반화로 가는 명확한 경로가 없지만 소유해야 체스를 풀 수 있다. 체스는 이러 능력이 필요하지 않고, 오히려 인간의 인식에 직교하는 급직적인 지름길로 가면 해가 될 수 있다. 

1.3.1에서 설명한 바와 같이 성공 척도가 자신이 추구하는 바를 정확하게 포착할 수 있다면 단일 목적이 성능을 최적화하는 것이 유용하고 유효하다. 만약 최종 목표가 체스라면, 목표가 설정되는 순간부터 해결책을 개발하는 프로세스는 선택 목표를 만족시키기 위해 이용 가능한 모든 지름길이 경사 하강인지 인간 주도 연구인지 택하기 쉽다. 이러한 지름길은 종종 성능 측정치를 통합하지 않은 고려사항에 대해 부작용을 동반한다. 시스템이 작동해야 하는 환경이 모든 것을 포괄하는 목표 기능을 미리 정의하기에는 너무 예측 불가능한 경우(예: 시스템이 알려지지 않은 것에 직면하는 대부분의 실제 로봇 공학 애플리케이션)나 인간공학이 없거나 거의 없는 광볌위한 문제에 적용할 수 있는 범용 AI를 목표로 하는 경우는 특정 작업에 대한 성과만을 위한 것이 아니라 유연성과 일반성을 위해 어떻게든 직접 최적하를 해야한다. 

이는 인간이 설계한 해결책을 하드 코딩하는 정적 프로그램에 대해 오늘날 널리 알려진 견해일 것이다. 사람 엔지니어가 if/else 문을 통해 가능한 각 물음에 대한 답변을 지정하여 챗봇을 구현하는 경우 우리는 이 챗봇이 지능적이라고 생각하지 않고, 엔지니어의 사양을 넘어서 일반화될 것으로 기대하지 않는다. 마찬가지로 엔지니어가 특정 IQ 테스트 작업을 검토하는 경우 해결책을 프로그램 형태로 적는다. 우리는 이러한 프로그램이 새로운 작업으로 일반화 되는 것을 기대하거나 지능을 발휘한다고 믿지 않는다. 그 프로그램은 단지 엔지니어의 사고 과정의 결정화된 결과만을 암호화한 것이다. 

지능은 동일한 프로세스가 이전에 알려지지 않은 광범위한 문제에 적용될 수 있다는 사실(일반 목적의 능력)에 의해 출력 프로그램의 성능으로 입증되지 않는다. 결과 프로그램은 단지 그 프로세스의 출력을 인코딩하는 것이기 때문에 정리의 증거를 적는데 사용되는 잉크와 종이보다 더 똑똑하지 않다.

그러나 인간에 의해 작업을 수행하기 위한 데이터로부터 훈련을 받지 않은 프로그램은 무엇인가? 학습 기계는 지능적일 수 있다. 학습은 새로운 정보에 적응하고 새로운 기술을 습득하기 위해 필요한 조건이다. 그러나 데이터에 대한 노출을 총해 프로그래밍된다고 해서 일반화나 지능이 보장되는 것은 아니다. 사전 지식을 AI에 하드 코딩하는 것만이 일반화 능력을 유도하지 않고 목표 작업에서 성능을 인위적으로 "구매"하는 유일한 방법은 아니다. 다른 방법으로 교육 데이터를 추가하여 일반화에 영향을 미치지 않고 특정 작업에서의 기술을 강화할 수 있다. 

정보 처리 시스템은 두 극단 사이에 스펙트럼을 형성한다. 한 끝부분은 완전히 하드 코딩된 이전 버전(DeepBlue, if/else Chatbot)으로 구성된 정적 시스템이고, 다른 한 끝부분은 매우 적은 수의 이진 시스템을 통합하고 거의 전적으로 데이터에 대한 노출을 통해 프로그래밍되는 시스템(해시 테이블, 조밀하게 연결된 신경망)이다. 2.1.3에서 지적한 바와 같인 가장 지능적인 시스템은 많은 양의 사전 지식과 경험을 결합한다. 결정적으로 일반화 능력은 사전 지식과 경험의 평면에서 직각으로 실행되는 축이다. 특정 수준의 일반화를 달성할 수 있는 학습 시스템을 제공하면 작업에 대한 더 많은 사전 지식 또는 더 많은 훈련 데이터를 통합하여 시스템을 수정하게 되어 일반화에 영향을 미치지 않고 작업별 성능을 향상시킬 수 있다. 이런 경우에 사전 지식과 경험 모두 인간이 동일한 기술을 습득하기 위해 의존하는 범용 능력의 종류를 표시할 필요 없이 주어진 기술 데스크를 "게임"처럼 하는 방법이 된다.

이는 간단한 예를 통해 쉽게 입증될 수 있다. 이전에 본 입력에 새로운 입력을 매핑하기 위해 지역 민감 해시 함수를 사용하는 해시 테이블을 고려한다. 이러한 보이는 데이터 양과는 무관한 고정된 범위 시스템은 해시 함수의 추상화 기능에 의해서만 결정되어 지역 일반화가 가능한 학습 알고리즘을 구현하다. 이러한 시스템은 극히 적은 일반화의 능력에도 불구하고 교육 데이터를 무제한으로 생성할 수 있는 모든 작업을 "처리"하기에 충분하다. 이는 각 상황을 적절한 행동 벡터와 연관시킬 수 있는 상황 공간의 조밀한 샘플링을 얻은 것이다. 

최종 목표가 고려된 작업에 대한 기술이라면 지역 일반화 학습 시스템에 데이터를 추가하는 것은 공정한 전략이다. 하지만 시스템이 본 데이터 이상의 일반화로 이어지지는 않을 것이다(예: OpenAI Five같은 Deep Learning). 결과 시스템은 여전히 취약하여 시스템을 개발하는 것은 우리에게 *유연성과 일반성을 달성하는 것에 대해 아무것도 알려주지 않는다.* 무제한 사전 또는 무제한 데이터를 활용하는 인간 수준 이상의 성능으로 주어진 작업을 "해결"하는 것은 광범위한 AI 또는 일반 AI에 더 가까이 다가가지 않는다. 

현재의 Deep Learning이 개념적으로 지역 민감 해시 테이블과 유사하다는 증거는 Deep Learning 모델이 지역 일반화 시스템이라는 사실을 지적한다. Deep Learning 모델은 임의의 수준의 기술을 직무에서 성취하도록 훈련될 수 있지만 고려된 입력 교차 대상 공간의 조밀한 샘플링이 필요하다. 따라서 높은 가치의 실제 어플리케이션 실현은 불가능하다. 가설적으로 Deep Learning에서 파생된 방법이 더 강력한 형태의 일반화를 가능하게 할 수 있다는 것이 미래에 보여질 수 있다. 하지만 이것을 증명하는 것은 단지 높은 기술을 얻는 것만으로는 이룰 수 없다. 대신 이러한 시스템의 일반화 강도를 정밀하게 설정하고 정량화하는 방법을 모색해야 한다(예: 기술 습득의 사전 효율성 및 데이터 효율성, 고려된 작업의 개발자 인식 일반화 난이도 고려). 본 문서의 핵심 사항은 이를 위한 공식 프레임워크를 제공하는 것이다(2.2 및 2.3 참조). 우리의 평가 방법에서 사전 지식, 경험, 일반화 난이도를 설명하지 못하면 우리는 분야가 일반화 스펙트럼을 따라 일반 AI에 도달하는 것을 막을 수 있다(1.3.2 참조).

요약하자면, 광볌위한 능력(2.1.2에 따라 일반적인 지능을 포함)의 특징은 변화에 적응하고, 기술을 습득하고, 이전에 보지 못했던 문제를 해결하는 힘이다. 기술 자체는 단지 지능 과정의 결정화된 결과일 뿐이다. 시스템 개발자에게 미리 알려진 작업의 기술 테스트(일반 AI 연구의 현재 추세와 동일)는 표시하지 않고도 무한한 사전 지식과 무한한 학습 데이터를 통해 게임을 할 수 있다. 광범위한 능력을 실제로 평가하기 위해 평가 방법에 사전 지식, 경험, 일반화 난이도를 제어하는 것은 필수적이다. 이를 통해 유연한 AI로 나아가고 결국 일반적인 AI로 발전한다. 

### 2.1.2 일반성의 의미 : G 인자 접지

다른 개인들이 다양한 인지능력을 보여주는 것은 인지심리학에서 잘 알려진 사실이다. 이것은 인식이 단일 일반성 요인인 g 요인 위에서 계층적 방식으로 구조화 되는것과 같이 다차원적인 물체라는 것을 나타낸다. 그러나 *"'일반 지능'은 절대적인 의미에서 인지 피라미드의 정점인가, 단지 더 넓은 인지 능력인가?", "전문화된 다른 능력들과 구별되지 않을까?", "인간의 지능은 얼마나 일반적인가?"* 와 같은 물음을 만들어 낸다.

No Free Lunch 정리는 모든 가능한 문제에 걸쳐 성능을 평균화할 때 두 가지 최적화 알고리즘이 동일하다는 것을 우리에게 알려준다. 알고리즘은 무작위보다 나은 성능을 달성하기 위해 목표 문제에 맞게 조정되어야 한다. 그러나 이 맥락에서 "모든 가능한 문제"에 의해 의미되는 것은 문제 공간에 대한 균일한 분포를 가리킨다. 우리의 우주와 실질적으로 관련될 수 있는 과제의 분포는 물리학의 법칙의 선택으로 인해 전문화된 환경이기 때문에 이 정의에 맞지 않을 것이다. 그렇다면 우리는 "인간 인자는 보편적인가?", "이것이 우주의 모든 가능한 일들로 일반화 되는가?"라는 물음을 가질 수 있다.

이러한 질문이 오직 인간과 인간의 경험에서 만 관계한다는 암묵적인 가정을 만드는데, 이는 심리측정학과는 거의 무관한 질문이다. 하지만 이 질문은 AI와 관련성이 높다. 만일 지능이 있고 인간의 이것을 구현한다면, 보편적 지능의 알고리즘은 우리 분야의 최종 목표가 되어야 한다. 이 목표는 인간의 두뇌를 역설계하는 것이 가장 짧은 길이 될 수 있다. 인간의 지능은 광범위하고 특별한 인지 능력으로 인간과 관련된 업무에는 일반적이지만, 그 외의 업무에는 일반적이지 않다. 이는 AI가 특정 적용 범위에 연결된 개방적이고 근본적인 인간 중심적인 추구임을 암시한다. 이는 인간의 지능과 인간 작업을 참조로 사용하여 어떻게 측정해야 하는지, 이를 달성하기 위해 따라야 하는 연구 전략에 영향을 미친다. 

다양한 테스트와 개인 테스트 결과에 인자 분석을 적용하는 것에서 비롯된 g 인자의 정의는 모든 지능 테스트에서 성공하는 데 공통된 단일 인지 능력을 나타낸다. 하지만 인간이 수행할 수 없는 작업을 포함시키는 것은 무의미하기 때문에 지능 테스트의 구조는 오직 인간이 할 수 있는 일을  인간이 즉시 인지하고 이해할 수 있는 작업(인간중심편향)으로 포괄한다. 더 나아가 심리측정학에서는 인가이 중요시하는 활동에 관한 예측성을 입증함으로써 측정의 타당성을 확립한다. 지능의 "유효한" 척도의 생각은 인간의 가치 기준 안에서만 이치에 맞다.

어떤 특정한 능력들은 누군가를 "지적"으로 만드는지에 대한 해석은 문화마다 다르다. 좀 더 광범위하게 인간은 주변의 복잡한 정보 처리 요원들에게 지능을 귀속시키는데 있어서 좋지 않은 역사를 가지고 있다(다른 문화에서 온 인간을 본 경우). 우리는 언어나 도구 사용 같은 우리 지능과 연관되는 인간다운 행동을 보인다면 "지적"일 수 있다는 가능성을 마지못해 받아들인다. 높은 내재적 복잡성과 높은 적응성을 가지고 있지만 직접적으로 연견성이 없는 행동을은 지능적으로 인식되지 않는다. 이러한 관찰은 집단적 실체(예: 시장, 기업, 기관으로서의 과학) 및 자연적 과정(예: 생물학적 진화)으로 확장된다. 능력과 행동이 널리 인정된 지능의 정의와 일치하는 독립 실행형 시스템으로 모델링(다양한 환경에서 목표 달성, 유연성, 적응성 입증)할 수 있지만 이는 인간과 유사할 뿐 우리는 이러한 시스템을 지능이라고 분류하지 않는다.

잘 알려진 교차 영역의 비유를 사용하면 "신체적 건강"의 개념은 직관적으로 "지능"과 유사하게 이해할 수 있다. 지능처럼 건강은 어떤 단일 요소(예: 사람의 나이, 근육량)으로 쉽게 감소되지 않는다. 만약 우리가 인간의 신체적 건강을 엄격하게 측정하려고 한다면 IQ 테스트가 아닌 100m 달리기, 마라톤, 수영 등 다양한 테스트를 할 것이다. 이러한 전체 테스트를 통해 우리는 인지 능력과 엄격히 유사한 광범위한 "육체적 능력"에 대응되는 상관관계 집합을 관찰할 것이다. 인지능력의 경우처럼 전문가들은 아마도 이러한 광범위한 능력의 정확한 분류법에 대해 동의하지 않고 토론을 진행할 것이다("키가 크고 날씬한"능력인가, "키가 큰" 것은 독립적 요소인가). 결정적으로 우리는 직관적으로 *모든 테스트가 결과가 상관관계가 있음*을 예상해야 한다. 우리는 "신체적 적합성"의 일반적인 직관적 구조에 해당하는 물리적 g 인자를 관찰할 것이다. 

하지만 우리는 이것은 인간의 형태학과 운동 능력이 절대적인 의미에서 "일반적"이라는 것을 의미하거나 건강한 사람이 어떤 육체적인 일을 할 수 있을지 알 수 없다. 우리는 우주에서 발견될 수 있는 대부분의 환경에 적응되지 않았다. 인간의 신체적 능력이 진화를 이끈 제한된 환경 및 활동보다 휠씬 더 광범위한  환경과 작업에 일반화된다는 것은 주목할만한 내용이다. 인간의 몸은 동아프리카 사바나에서 뛰기 위해 진화했지만, 그들은 에베레스트 산을 오르고, 호수를 헤엄치고, 스카이다이빙을 하고, 농구를 할 수 있다. 이것은 우연이 아니다. 진화는 필요에 의해 인지적 적응성 또는 감각적 적응성을 최적화한다. 따라서 인간의 신체적 능력은 제한적인 의미에서 "일반적"이라고 말할 수 있다. 넓게 보면 인간이 극도로 전문화되어 있음을 나타낸다.

우리는 인간의 인식이 인간의 신체적 능력과 완전히 동일한 패턴을 따른다고 주장한다. 둘 다 특정 환경의 특정 문제에 대한 진화적 해결책으로 등장했다. 중요한건 둘 다 적응성에 최적화된 진화를 이끈 작업들로 놀라울 정도로 광범위한 작업들과 환경에 적용할 수 있는 것으로 밝혀졌다. 이는 모든 종류의 광범위하고 범용적인 능력에 관심이 있는 누구에게나 가장 주목해야하는 문제이다. 둘 다 다차원적 개념으로, "일반적인" 요소로 이어지는 광범위한 능력의 계층으로 모델링될 수 있다. 그리고 결정적으로 둘 다 고도로 전문화되어 있다. 부피로 볼 때 인간의 육체가 우주의 준총체성에 적합하지 않은 것은 인간의 지성은 생각할 수 있는 대부분의 일에 적응되지 않는다는 것과 매우 흡사하다.

여기에는 몇 년 이상의 장기 계획을 필요로 하는 문제와 같은 명백한 범주의 문제와 대량의 작업 메모리가 필요하다. 이것은 우리의 선천적인 인지적 선입견이 적응되지 않는 문제들을 포함한다. 이러한 문제가 진화적으로 친숙한 작업과 인지적 중첩을 나타낼 때, 인간은 지각 전략을 사용하여 작은 크기의 특정 NP-hard 문제를 해결하는데 매우 효과적일 수 있다(예: 낮은 포인트 수를 가진 유클리드 여행 세일즈맨 문제(TPS)는 거의 선형에 가까운 최적 시간에 인간이 해결할 수 있다). 하지만 매우 큰 규모의 문제 사례나 인지도가 낮은 문제의 경우 진화적으로 친숙한 적업과 중복되어 무작위 검색보다 효과가 떨어진다. 예를 들어 TSP에서 "최단 경로 찾기"에서 "가장 긴 경로 찾기"로 목표를 반전시킬 때, 인간 성과는 심각하게 저하된다. 이 경우 인간은 가장 간단한 경험적 발견 중 하나인 가장 먼 이웃 구조보다 훨씬 더 나쁜 성능을 발휘한다. 

> *이것은 집단으로서의 인간성이 이러한 문제들을 해결할 수 없다는 것을 의미하는 것은 아니다. 시간이 지남에 따라 개별 인간을 모으거나 외부 자원을 통해 인간의 지성을 증강하면 일반성의 증가하지만, 이러한 증가는 여전히 보편성과 근본적으로 다르다.*

치수 편향은 인간의 편견 중에서 특히 눈의 띄인다. 2D 내비게이션 작업 및 2D 형상 포장 퍼즐에서 탁월한 성능을 발휘하는 인간은 성능이 크게 저하되더라도 3D 사례를 처리할 수 있다. 하지만 4D 이상부터는 효과적으로 처리할 수 없다. 이러한 사실은 문제 해결을 위한 2D 항법을 위해 특별이 진화한 신경 메커니즘에 의해 뒷받침되는 지각적 전략에 대한 인간의 의존도를 감안할 때 놀랍지 않을 것이다. 

따라서 이 문서의 중심점은 **"일반 지능"은 시스템이 소유하거나 부족한 이진 속성이 아니라는 것**이다. 이것은 광범위할 수 있는 적용 범위, 시스템이 고려된 범위에 걸쳐 사전 지식 및 경험을 새로운 기술로 변환하는 효율의 정도, 고려된 범위의 다른 점으로 대표되는 일반화 난이도로 연결되어 하나의 스펙트럼을 보인다(2.2 참조). 게다가 다른 적용범위에 대한 적용범위의 "가치"는 전적으로 주관적이다. 우리는 적용 범위가 우리 자신의 범위와 상호 작용하지 않는 시스템에 관심이 없고 지능적으로 인식하지도 않을 것이다. 

이와 같이 개념적으로 절대적인 의미에서 "일반적인 지능"을 목표로 설정하는 것은 좋지 않다. 모든 종류의 광범위한 능력을 구축하기 위해서는 목표 범위에서 출발해야 하며, 이 범위 내에서 잘 정의된 지능 임계치를 달성해야 한다. 이는 단 한개의 문제도 풀지 않은 AI의 깊은 맥락과 모든 노력이다. 그러나 이론상으로는 인간과 같은 인공지능을 창조하는 것이 가능할지도 모른다. 우리는 인간의 지능과 동일한 적용가능성의 범위에 걸쳐 점진적으로 확장되는 시스템을 구축할 수 있다. 이는 인간과 일치할 때까지 점차적으로 일반화 능력을 높일 수 있다. 인간의 인지 효율이 상한이라고 가정할 사전 이유가 없기 때문에 우리는 더 높은 일반화 능력을 가진 시스템을 구축하고 적용 범위가 더 넓은 시스템을 사용할 수 있다. 이러한 시스템은 인간을 뛰어넘는 지능을 특징으로 할 것이다.

결론적으로 우리는 **광범위한 AI 시스템 개발에 대한 연구를 제안한다(최대 "일반" AI)**. 인간 지능에 필적하는 정도의 일반성을 가진 AI는 *인간과 유사한 형태의 지능을 정의, 측정,개발하는 데 중점을 두어야 하며, 특히 인간 지능(그 자체가 고도로 전문화된)에 대한 진행 상황을 벤치마킹해야 한다.* 이것은 우리가 우리 자신과 매우 다른 지능이 존재할 수 없거나 가치를 갖지 못할 것이라고 믿기 때문이 아니다. 오히려 우리는 *지능을 특성화하고 측정하는 것이 잘 정의된 적용 범위에 연결되어야 하는 프로세스라는 것*을 인식하고 있으며, 이 때 *인간 관련 작업의 공간은 우리가 의미 있게 접근하고 평가할 수 있는 유일한 범위이다.* 그러므로 우리는 인간 중심주의를 완전히 배격하고 모든 지능을 단일 절대 척도로 측정하려고 하는 세계적인 정신 측정 또는 Legg와 Hutter의 세계적인 지능의 관점에 동의하지 않는다. **인간 중심적인 틀은 합법적일 뿐만 아니라 필요하다.**


### 2.1.3 선천적인 것과 후천적인 것을 분리하는 것 : 발달 심리학으로부터 통찰력

발달 심리학의 발전은 1.2에서 설명된 정신의 본질에 대한 두 가지 반대되는 견해 중 어느 것도 정확하지 않다는 것을 우리에게 가르쳐준다. 인간의 정신은 단지 진화에 의해 하드 코딩된 특수 목적 프로그램의 집합이 아니다. 이것은 현저한 일반성과 개방성을 가질 수 있어서 환경 및 작업의 범위를 훨씬 뛰어넘는 진화를 이끌었습니다. 우리가 가지고 있는 기술과 지식의 대부분은 타고난 것이 아니고, 하나의 경험으로부터 무엇이든 배울 수 있는 범용 "빈 슬레이트" 시스템이 아니다. 우리의 인식은 특정 방법으로 진화에 의해 형성되어 전문화되어 있다. 우리는 우리 자신, 세상, 학습법에 대한 선입견을 가지고 태어난다. 이것은 우리가 습득할 수 있는 기술의 범주와 우리가 해결할 수 있는 문제의 범주를 결정한다. 

이러한 사전 지식은 우리의 일반화 능력을 제한하지 않는다. 반대로 인간이 놀라운 효율로 특정 범주의 기술을 습득할 수 있는 이유는 자기 자신의 근원이다. No Free Lunch 정리의 중심 메시지는 데이터로부터 데이터에 대한 추측을 배우는 것이다. 이는 인간의 정신에 의해 만들어진 선천적인 가정들의 본질, 구조와 이것들의 강력한 학습 능력을 정확히 연관시킬 수 있다.  

우리는 2.1.1에서 실행 가능한 *사전 및 경험에 대한 통제* 같은 지능 척도가 있어야 한다고 지적했다. 우리는 II.1.2에서 일반 지능을 평가하는 것은 인간 지능이 필요한 참조 프레임으로 활용해야 한다고 제안했다. 인간과 기계 사이의 일반적인 지능을 공정하게 평가하기 위해서는 인간의 *인지 사전 지식*에 대한 명확한 이해가 필요하다.

특히 인간의 인지 사전 지식은 여러 가지 형태로 나타난다. 이 여러 형태 사이의 경계는 유동적이다. 낮은 수준의 사전 지식과 높은 수준의 사전 지식의 구별은 자연적 지식보다 많다. 마찬가지로 지식이 기술 습득을 용이하게 하기 때문에 메타 학습의 선행 지식과 사전 지식의 구별은 주관적이다. 예를 들어 2D 네비게이션을 수행하는 능력 뒤의 신경 메커니즘은 전문 메타 학습 사전 지식 또는 외부 세계의 대한 지식으로 취급될 수 있다.

> **우리 자신의 감각적인 공간 구조에 대한 낮은 수준의 사전 지식**은 사전 지식이 신속하게 감각과 자신을 제아할 수 있도록 하고, 제한된 범위의 상황에서 단순한 행동을 일으킬 수 있다. 

> **지식 획득을 위한 학습 전략 및 기능을 관리하는 메타 학습 사전 지식**은 우주 정보가 모듈론적 구조를 따른다는 가정과 인과관계와 공간적 연속성에 관한 가정을 포함한다. 

> **외부 환경의 객체 및 현상에 대한 고급 사전 지식**은 시각적 목적성에 대한 사전 지식(객체 정의), 2D 및 3D 유클리드 공간에서의 방향 및 탐색에 관한 사전 지식, 목표 지향성(목표에 따라 행동하는 에이전트를 환경에 포함한다는 설명), 자연수에 대한 타고난 개념, 타고난 사회적 직감(예: 정신 이론) 등을 포함한다.

인간다운 AI를 만드는 데 있어서 낮은 수준의 감각적인 선행 지식은 너무 특이해서 관심을 끌 수 없다(인공 인체를 만들려고 하지 않는 한). 인간의 메타 학습 선행 지식은 최대 관심사여야 하지만(경험을 지식과 기술로 바꾸기 위해 뇌가 따르는 전략을 이해하는 것이 효과적으로 우리의 최종 목표) 지능 평가와는 관계 없다. 

인간과 유사한 형태의 지능을 측정할 때 고려해야 할 것은 선행 지식이다. 경험을 교육하는 과정을 인간 과제의 기술로 효율적으로 바꾸는 데 있어서 선천적인 지식을 미리 보유하지 않은 시스템은 인간에 비해 불리하다. 반면에 당면한 작업에 대해 보다 광범위한 하드 코드 지식을 이용할 수 있는 시스템은 2.1.1에서 언급한 바와 같이 인간의 지능과 공정하게 비교할 수 없었다. 시스템 개발자가 주어진 작업에 대해 무제한의 성능을 "구매"할 수 있도록 허용하는 것은 일반화 능력(실제로 달성하고자 하는 것)과 관련되지 않다.

그러므로 우리는 인간과 유사한 일반 지능에 대한 시험이 다음과 같은 이전의 타고난 인간 지식에 기초해야 한다고 제안한다.

> 선행 지식은 우리가 이해하기 전에 가능한 한 인간의 선천적 지식에 가깝게 만들어져야 한다. 이는 시간이 지남에 따라 인간의 사전 지식에 대한 이해도가 향상되어야 한다.

> 테스트는 측정 중인 시스템이 특정 선행 지식을 가지고 있다고 가정해야 한다. 더 광범위한 선행 지식이 있는 AI 시스템은 이러한 테스트를 사용하여 벤치마킹해서는 안 된다. 선행 지식의 수가 적은 AI 시스템은 불리하다는 점을 이해해야 한다.

> 시험에 의해 가정된 선행 지식은 명확하고 완전하게 설명되어야 한다. 현재의 정신적 지능 테스트는 시험 응시자가 보유하고 있는 선행 지식(천성적 또는 후천적)에 대한 많은 가정을 만들지만 이러한 가정을 명시적으로 설명하지는 않는다. 

> 인간 수험생들이 시험 전에 시험을 치르지 않도록 하기 위해서 시험 과제는 습득한 인간 지식(즉, 선천적인 사전 지식을 넘어선 모든 지식)에 의존해서는 안 된다.

이것은 우리에게 "인간이 태어나기 전의 지식의 정확한 목록은 무엇인가?"라는 의문을 만들게 한다. 이는 핵심지식의 발달과학 이론이 답하고자 하는 질문이다. 
> 핵심 지식은 자연 진화에 의해 우리의 DNA에 쓰여져 왔다. 자연 진화(Natural evolution)는 주변 환경의 정보를 유기체의 유전적 코드로 전달하기 위한 극도로 낮은 대역폭의 고도로 선택적인 메커니즘이다. 이것은 충분히 긴 시간 동안 안정된 환경의 양상에 대해서만 쓸 수 있고, 진화적 압력과 관련된 정보만 전송할 수 있다. 인간이 방대한 양의 인간 교유의 사전 지식을 보유하기를 기대하는 것은 합리적이지 않다. 핵심 지식은 진화적으로 고대의 많은 종, 특히 인간이 아닌 영장류에서 주로 공유된다.

핵심 지식은 인간 인식의 기초를 형성하는 네 가지 광범위한 선천적 가정을 식별한다.

> **객관성과 기초물리학**      
  인간은 자신의 환경이 응집력(연속적이고, 연결되어 있고, 경계가 있는 영역으로 특징지어지는 "목표"), 지속성(목표들은 갑자기 존재하지 않고, 갑자기 구체화되지 않음), 접촉(목표들은 거리에서 행동하지 않고, 상호 작용할 수 없음)의 원리로 구분되어야 한다고 가정한다.

> **에이전트성 및 목표 지향성**       
  인간은 환경에 있는 어떤 물체들은 "객체"로서 어떠한 의도를 가지고 있다고 생각한다. 그리고 목표를 달성하기 위해 행동하고 높은 목표 지향적 행동의 효율성을 보여준다. 우리는 이러한 객체들이 우발적이고 호의적으로 행동할 수 있기를 기대한다. 
  
> **자연수 및 기초산수**     
  인간은 소수에 대한 감각 약식을 통해 관찰되는 실체에 적용 가능한 추상적인 숫자 표현에 타고난 재능이 있다. 이 숫자 표현은 증가, 감산, 비교, 정렬될 수 있다. 

> **기본적인 기하학 및 쳬계적 분류**          
  이 핵심 지식 시스템은 우리의 환경과 우리 자신을 위한 사물에 대한 과계의 내/외부 거리의 개념의 방향을 포착한다. 이것은 주변 환경을 고려하여 방향을 정하고 2D 및 3D 환경을 탐색하기 위한 인간의 타고난 능력에 기초한다.


인지 발달 심리학은 아직 인간이 가지고 있는 정확한 선천적 선입견들을 높은 수준의 확실성으로 결정하지 못했다. 우리는 핵심 지식 이론을 인간과 유사한 일반 지능 테스트의 필요성 기초를 제공하는 것으로 간주한다. 따라서 우리는 인간과 기계 모두에게 공정할 수 있는 일반 지능의 실행 가능한 테스트는 위에 나열된 네 가지 핵심 지식 시스템을 가정하는 작업만 특징으로 해야 하고, 이러한 사전 지식 이외의 습득된 지식을 포함해서는 안된다고 제안한다. 또한 일반 AI 시스템은 이러한 핵심 지식 원칙 사전 지식에 기본 사항으로 하드 코딩해야 한다.

## 2.2 지능 정의 : 공식 합성

### 2.2.1 기술 습득 효율성으로서의 지능

지금까지 다음과 같은 비공식적인 직관을 도입했다.

> 지능은 광범위하거나 범용적인 능력이 있다. 기술 그 자체라기보다는 유연성과 적응성(예: 기술 습득 및 일반화)으로 표시된다. AI의 역사는 일반화의 스펙트럼을 따라 천천히 상승해 왔다.

> 지능의 척도는 경험과 선행 지식에 대해 통제하고 일반화 강도를 정량화해야 한다. 이것은 사전 지식 또는 경험이 무제한으로 제공되기 때문에 어떤 수의 작업에서도 높은 기술을 보이는 일반화 능력(또는 지능)이 거의 없는 시스템을 생산할 수 있다.

> 지능과 그 척도는 본질적으로 적용 범위와 관련이 있다. 따라서 일반 AI는 인간의 지능에 대해 벤치마킹되어야 하며 유사한 지식 집합을 기반으로 구축되어야 한다.

이제 이러한 직관을 공식화해보자. 그 이후 우리는 지능과 그 척도의 공식적인 정의를 기초하는 데 필요한 핵심 개념에 대한 일련의 정의를 제공한다. 우리는 알고리즘 정보 이론의 도구를 활용할 것이다. 이러한 정의는 다음과 같은 중심 생각을 표현하는 공식적인 방법으로 이어진다. 

> *시스템의 지능은 사전 지식, 경험 및 일반화의 어려움과 관련하여 작업 범위에 대한 기술 습득 효율성의 척도이다.*

직관적으로 사전 지식과 유사한 지식 집합에서 시작하고, 사전에 알려지지 않은 일련의 작업에 대해 유사한 경험(예: 연습 시간)을 거치는 두 시스템을 고려하는 경우에서 더 높은 지능을 가진 시스템은 결국 더 큰 기술로 끝나는 시스템이다(즉, 사전 지식의 경험과 경험을 더 효율적으로 기술로 바꾼 시스템). 이러한 지능의 정의는 메타 학습 사전 지식, 기억 및 유동적 지능을 포함한다. 이것은 단지 지능의 과정의 결과물인 기술과는 다르다. 

시작하기 전에 지능의 가능한 많은 정의들이 유효할 수 있다는 것을 강조하자. 그리고 우리는 위의 정의와 아래의 형식주의가 "하나의 참된" 정의를 나타낸다고 주장하지 않는다. 또한 우리의 정의는 넓은 합의를 달성하기 위한 것이 아니다. 오히려 우리 정의의 목적은 광범위한 인지 능력에 대한 연구를 위한 유용한 관점 전환의 역할과 새로운 일반 지능 벤치마크의 정량적 토대 역할이다. 우리는 2.2.3에서 우리의 형식주의가 유용하고 실행 가능한 구체적인 방법이라는 것에 대해 논의한다.

> *모든 모델은 잘못되었지만 일부는 유용하다. 우리의 유일한 목표는 유연하고 일반적인 AI에 유용한 방향성을 제공하는 것이다.*           
  \- George Box -

---

### 문제의 위치

우리는 우리의 문제 설정을 확립하기 위해 기본 정의를 도입해야 한다. 우리의 문제 설정 선택이 완전한 지도 학습, 부분 지도 학습, 강화 학습을 모델링하기에 충분하다는 것을 분명히 해야한다. 

우리는 "과제"와 "지능형 시스템" 사이의 상호 작용을 고려한다. 이 상호작용은 "기술 프로그램"(지능형 시스템에 의해 생성됨)과 "점수 함수"(과제의 일부)에 의해 중재된다. 

우리는 프로그램이 실행되는 고정된 범용 튜링 기계의 존재를 암시적으로 고려한다(스킬 프로그램, 프로그램의 일부 및 지능형 시스템의 일부 포함). 또한 고정된 *"상황 공간"* 및 *"응답 공간"* 의 존재를 가정한다. 이러한 각 공간은 앞으로 고려할 모든 기술 프로그램의 입력(및 출력)으로 허용되는 이진 문자열 집합을 정의한다.

![2-2](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/figure/2-2.png?raw=true)
***문제의 위치 : 지능형 시스템은 작업과 상호 작용할 수 있는 기술 프로그램을 생성한다.***

**작업** T는 4개의 객체로 구성된다. 
> 작업 상태(이진 문자열)

> "상황 생성"함수인 *SituationGen(TaskState → Situation)* 은 확률적일 수 있다.           
   \- **상황**은 *상황 공간*에 속하는 이진 문자열이다.
   
> "점수 함수" *채점([Situation, Response, TaskState] → [Score, Feedback])* 은 확률적일 수 있다.         
   \- **응답**은 *응답 공간*에 속하는 이진 문자열입니다.         
   \- **점수**는 스칼라 값으로 상황에 대한 대응의 적절성을 측정한다.          
   \- **피드백**은 이진 문자열으로 현재 점수에 대한 전체, 부분 정보, 과거 응답에 해당하는 점수에 대한 정보를 인코딩할 수 있다.         
   \- 참고 : 상황 파라미터는 실행 시간에 작업 상태로 알 수 있으므로 기술적으로 선택 사항이다.  

> 자체 업데이트를 진행하는 *TakeUpdate([Response, TaskState] → TaskState)* 는 최근 상황에 대한 응답에 따라 작업 상태를 변이시킨다. 이는 확률적일 수 있다.         

예를 들어 체스나 WarCraft 3와 같은 게임(그리고 우리가 3에 제시된 ARC 벤치마크에서 "과제"라고 부르는 것)은 하나의 작업을 구성한다. 주어진 체스 보드 위치, WarCraft 3의 화면 프레임, ARC의 입력 격자 무늬는 상황이 될 수 있다.

**지능형 시스템** IS는 세 개의 개체로 구성된다. 

> 시스템 상태 IS 상태(이진 문자열)

> "기술 프로그램 생성 기능한" *SkillProgramGen(ISState → [SkillP rogram, SPState])* 은 확률적일 수 있다.
  \- SkillProgram([Situation, SPState] → [Response, SPState])은 입력 상황을 유효한 응답에 매팡하고(*ResponseSpace*), 일부 작동 메모리를 사용하는(*SPState*) 확률적인 함수이다. 이러한 이유는 이것이 SPState(이항 문자열)를 가지고 있고 SPState는 이것을 생성한 지능형 시스템과 더 이상 통신하지 않고, 연결된 일련의 상황을 자율적으로 처리하는 데 사용되기 때문이다.             
  \- 스킬 프로그램은 주어진 비디오 게임에서 새로운 레벨을 재생할 수 잇는 게임별 프로그램과 같다.            
  \- 그 후의 일을 우리는 "스킬 프로그램"을 *SkillProgram* 기능과 초기 스킬 프로그램 상태 *SPState*의 조합이라고 부른다.             
  \- 기술 프로그램은 시스템의 작업별 능력(작업 내의 새로운 상황에 적응하는 능력 포함)의 동결 버전을 나타낸다. 우리는 주어진 시점에서 에이전트의 작업별 기술 및 작업별 일반화 능력 수준을 공식화하기 위한 개념적 장치로 스킬 프로그램의 개념을 사용한다.
  
> 자체 업데이트 기능인 *ISUpdate([Situation, Response, F eedback, ISState] → ISState)* 는 최신 상황과 그에 상응하는 피드백을 바탕으로 시스템 상태를 
확률적으로 변화시킨다. 

예를 들어 게임을 위한 신경망 생성과 훈련 알고리즘은 "지능형 시스템"이 될 것이다. 그리고 한 게임에서 훈련 실행이 끝날 때 출력되는 추론 모드 게임별 네트워크는 "추론 프로그램"이 될 것이다. 다른 예로는 ARC 작업을 보고 해결 프로그램을 출력할 수 있는 프로그램 합성 엔진은 "지능형 시스템"이 될 것이다. 그리고 이 작업에 대한 미래의 입력 기준선을 처리할 수 있는 결과적인 솔루션 프로그램은 "중요 프로그램"이 될 것이다.

업무, 지능형 시스템, 기술 프로그램 간의 상호 작용은 훈련 단계와 평가 단계의 두 단계로 구성된다. 훈련 단계의 목표는 IS가 미래의 평가 상황에 일반화할 높은 기술력 프로그램을 생성하는 것이다. 평가 단계의 목표는 새로운 상황을 처리할 수 있는 이 기술 프로그램의 능력을 평가하는 것이다.

교육 단계는 다음 단계의 반복으로 구성된다(현재 단계 t에 주목). 이것을 시작하기 전에 우리는 두 개의 개별적인 초기 작업 상태를 고려한다. (*trainTaskState<sub>t=0</sub>, testTaskState<sub>e=0</sub>*)

> 교육 상황을 생성한다.     
  *situation<sub>t</sub> ← SituationGen(trainT askState<sub>t</sub>)*
  
> IS는 현재 상황을 모르는 상태에서 새로운 기술 프로그램을 생성한다.      
  *[skillProgram<sub>t</sub>, spState<sub>t</sub>] ← SkillProgramGen(isState<sub>t</sub>)*            
  \- 암시적으로 IS의 "목표"는 고도로 숙련된 프로그램을 생성하는 것이라고 가정한다. 과거 상황에서 좋은 성과를 거두었던 프로그램은 다음 상황에서도 좋은 성과를 거둘 수 있고, 이 작업에 대해 가능한 모든 상황에서 잘 수행할 것이다(특히, 상당한 새로움과 불확실성을 특징으로 할 수 있는 평가 상황). 우리는 IS가 이 목표를 추구해야 하는 이유를 모델링하려고 시도하지 않는다.              
  \- *spState<sub>t</sub>* 는 시간 t에서 기술 프로그램의 작업 메모리를 나타낸다. 각 교육 단계에서 기술 프로그램이 새로 생성되기 때문에 교육 중에는 *spState*를 통한 상태 유지성 실제로 필요하지 않는다. 그러나 평가 중에 상황 전체에 걸쳐 정보를 유지해야 하는 작업을 처리할 때는 상태 유지성이 중요하다. 많은 게임 또는 실제 작업에서 상황은 모두 독립적이며 기술 프로그램들은 전혀 유지성을 요구하지 않는다

> 기술 프로그램은 상황에 대한 응답을 출력한다.       
  *[response<sub>t</sub>, spState<sub>t+1</sub>] ← skillProgram<sub>t</sub>(Situation<sub>t</sub>, spState<sub>t</sub>)*        
  \- 각 교육 단계에서 지능형 시스템에 의해 기술 프로그램이 새로 생성되기 때문에 *skillProgram<sub>t</sub>* 은 한 번만 호출되고, *spState<sub>t+1</sub>* 은 삭제된다.         
  \- 실제로 연속되는 상황이 서로 가까운 부분 관측이 가능한 게임(예: WarCraft 3의 두 개의 연속 화면 프레임)은 *skillProgram<sub>t</sub>, skillProgram<sub>t+1</sub>* 을 실제로 독립적으로 생성하지 않고도 서로 가깝게 유지된다고 가정할 수 있다. 즉 IS의 업무 이해는 프로그램 공간에서 지속적으로 진화하고 있을 것이다. *skillProgram<sub>t</sub>* 에 의해 생성된 *spState<sub>t+1</sub>* 과 *skillProgramGen*에 의해 생성된 *spState<sub>t+1</sub>* 도 마찬가지로 서로 매우 가까이 있을 것이다.

> 작업 채점 함수는 응답에 점수를 할당하고 피드백을 생성한다.        
  *[score<sub>t</sub>, feedback<sub>t</sub>] ← Scoring(Situation<sub>t</sub>, response<sub>t</sub>, trainTaskState<sub>t</sub>)*     
  \- 스칼라 점수는 반응의 적절한 정도를 인코딩하는 것을 의미하고,  피드백 데이터는 지능형 시스템이 상태를 업데이트하기 위해 사용한다. 완전한 지도 학습과 같은 간단한 경우에서는 피드백 데이터와 스칼라 점수는 동일하다. 이는 지능 에이전트가 응답의 적절성에 대한 완전하고 즉각적인 정보를 가질 수 있다는 의미이다. 피드백 데이터는 부분 정보, 정보 없음, 이전 상황에 대해 생성된 응답과 관련이 있는 정보만 포함할 수 있다.

> IS는 작업에서 받은 피드백을 기반으로 내부 상태를 업데이트한다.     
  *isState<sub>t+1</sub> ← ISUpdate(Situation<sub>t</sub>, response<sub>t</sub>, feedback<sub>t</sub>, isState<sub>t</sub>)*      
  
> 태스크는 다음과 같은 상황에 대한 응답을 기반으로 내부 상태를 업데이트한다.      
  *trainTaskState<sub>t+1</sub> ← TaskUpdate(response<sub>t</sub>, trainTaskState<sub>t</sub>)*

교육 단계는 *SituationGen* 함수의 재량에 따라 끝난다(예: *SituationGen*이 "정지" 상황을 반환). 이 때, *SkillProgramGen*은 초기 상태(초기 작업 메모리) 포함(예: 공백)하는 마지막 기술 프로그램을 생성한다.

평가 단계는 표면적으로 훈련 단계와 유사하고, 더 이상 지능적인 시스템을 포함하지 않는다. 그리고 *testTaskState<sub>e=0</sub>* 을 확률적으로 선택할 수 있음에 유의해야한다.   
> TestTaskState<sub>e=0</sub>에서 시작하여 독립적인 일련의 상황으로 구성된다.       
  testSPState<sub>e=0</sub>의 상태로 시작하는 수정된 단일 *testSkillProgram*만 필요하다.

기술 프로그램과 지능형 시스템의 분리와 같이 평가 단계는 주어진 시점에 시스템이 보여준 직무별 기술 및 직무별 일반화 능력을 정량화하는 데 사용되는 개념적 장치로 이해되어야 한다. 평가 단계는 개념적으로 학교 시험이나 아이큐 시험을 보는 아이와 비슷하다고 보여서는 안 된다. 실제 평가 상황에서 평가는 당면한 과제에 대한 이해도를 동적으로 조정하는 전체 지능 시스템을 포함한다. 실제 평가 상황은 우리의 형식주의에서 훈련 과정의 일부로 표현될 것이다.

평가 단계는 다음 단계의 반복으로 구성된다(현재 단계는 *e*로 기록).

> 테스트 상황을 생성한다.      
  *situation<sub>e</sub> ← SituationGen(testT askState<sub>e</sub>)*

> 고려된 기술 프로그램은 다음과 같은 반응을 생성한다.       
  *[response<sub>e</sub>, testSPState<sub>e+1</sub>] ← testSkillProgram(situation<sub>e</sub>, testSPState<sub>e</sub>)*        
  \- 기술 프로그램 상태를 업데이트하면 기술 프로그램이 평가 단계 내내 작동 메모리를 유지해야한다. 이것은 부분적으로 관찰할 수 있는 게임에 유용하고, 많은 게임(ARC 포함) 및 많은 실제 작업과 무관하다. 여기서 기술 프로그램은 비저장 상태일 수 있다. 

> 작업 점수 기록 함수는 응답에 점수를 할당한다(피드백은 폐기).        
  *score<sub>e</sub> ← Scoring(Situation<sub>e</sub>, response<sub>e</sub>, testTaskState<sub>e</sub>)*        
  
> 태스크는 수신된 응답을 기반으로 내부 상태를 업데이트한다.        
  *testTaskState<sub>e+1</sub> ← TaskUpdate(response<sub>e</sub>, testTaskState<sub>e</sub>)*
  
평가 단계는 *SituationGen* 함수의 재량에 따라 종료됩니다.

단순화를 위해 우리는 IS의 상태가 여러 작업에 걸쳐 이전되지 않는다는 점에 주목해야한다. IS는 각 새로운 작업에 대한 훈련 단계 시작 시(즉, 내장된 사전 작업만 보유) "공백" 상태로 시작한다. 그러나 위의 설정과 아래의 정의는 명확한 경계가 없는 부분적으로 겹치는 다수의 작업에 대해 지속적으로 학습하는 실제 생물학적 지능 시스템에 더 가깝게 만들기 위한 평생 학습을 고려하기 위해 쉽게 확장될 수 있다.

지금까지 설명한 설정을 기반으로 다음과 같은 유용한 개념을 정의할 수 있다.

> **평가결과**      
  평가결과는 작업에 대한 특정 평가 단계 기록에서 고정 스킬 프로그램에 의해 얻은 스칼라 점수의 합계이다. 관련된 모든 개체(기술 프로그램, 상황 생성 프로그램, 작업 업데이트 프로그램, 초기 작업 상태)가 확률적일 수 있으므로 양도 확률적일 수 있다. 마찬가지로 우리는 **훈련 시간 성능**을 주어진 훈련 단계에서 얻은 스칼라 점수의 합계로 정의한다. 훈련 시간 성능은 특정 훈련 상황 순서와 관련이 있다.

> **기술**        
  기술은 가능한 모든 평가 단계 기록에 대한 평가 결과의 확률적 평균이다. 평가 단계를 무한히 여러 번 실행한 후 획득한 평가당 점수 합계의 평균이기도 하다. 그리고 기술은 기술 프로그램의 속성이고, 다른 분포 감소 기능을 사용할 수 있다.
  
> **최적기술**        
  최적기술은 이론적으로 가장 뛰어난 기술 프로그램을 통해 얻을 수 있는 최대 기술이다. 

> **&theta;<sub>T</sub>를 참고한 기술 임계값**        
  &theta;<sub>T</sub>를 참고한 기술 임계값은 작업과 관련된 기술의 주관적 임계값이다.
  
> **직무 및 기술 가치 함수**            
  직무 및 기술 가치 함수는 스칼라 값을 작업에 대한 기술 임계값(&theta;)의 조합에 연결하여 작업 공간에 대한 값 함수를 정의한다(작업 공간은 무한할 수 있음).         
  *TaskValue : Task, θ → ω<sub>T,θ</sub>*      
  값은 양수 또는 0으로 가정되고, 그리고 TaskValue는 θ의 함수로 단조롭다고 가정한다(특정 작업의 경우 높은 기술은 항상 더 높은 가치를 가진다). 이 가치 함수는 각 작업에서 기술의 상대적 중요성을 포착하고 우리의 지능 정의의 주관적 참조 틀을 정의한다(예: 인간과 유사한 지능을 평가하고자 하는 경우, 우리는 인간 관련 작업에서 높은 기술을 달성하는 데 높은 가치를 두고 인간과 무관한 작업에 아무런 가치도 두지 않을 것이다). 한 작업에서 기술 수준의 값 ω<sub>T,θ</sub>는 다른 작업에 걸쳐 ω<sub>T,θ</sub>의 양을 공정하게 비교할 수 있도록 선택된다(즉, 그것은 우리가 T 작업에서 기술 θ를 달성하는 데 사용하는 가치를 포착해야 한다). 이를 통해 각 점수 기능의 규모에 대해 걱정하지 않고 여러 작업에 걸쳐 기술을 균일하게 통합할 수 있다.

> **ω<sub>T</sub>를 참고하는 작업 값**        
  ω<sub>T</sub>를 참고하는 작업 값은 T에서 충분한 기술 수준을 달성하는 가치이다.       
  ω<sub>T</sub> = ω<sub>T</sub>, θ<sub>T</sub>

> **최적의 해결책**       
  최적의 해결책은 작업에서 최적의 기술을 달성할 수 있는 모든 기술 프로그램이다. 마찬가지로 우리는 **훈련 시간 최적 솔루션**을 특정 훈련 상황에서 최적의 훈련 시간 성능을 달성할 수 있는 모든 기술 프로그램으로 정의한다.

> **충분한 해결책**       
  충분한 해결책은 작업에서 충분한 기술 θ<sub>T</sub>를 달성할 수 있는 모든 기술 프로그램이다.
  
> **교육과정**       
  교육과정은 교육 단계에서 태스크와 지능형 시스템 간의 상호 작용 순서(상황, 응답 및 피드백)이다. 업무와 지능형 시스템이 주어진 경우, 기본 프로그램의 확률적 구성요소에 의해 매개 변수화된 교육과정 공간이 존재한다. 교육과정은 시스템과 작업 간의 상호 작용에서 나와 가르침과 능동적인 학습 모두를 모델링할 수 있다.
  
> **최적 교육과정**         
  최적 교육과정은 지능형 시스템이 이 작업에 대해 생성할 수 있는 최상의(최고 기술) 기술 프로그램을 생산하도록 이끄는 교육과정이다. 이것은 업무와 지능적인 시스템에 한정되고, 둘 이상의 최적 교육과정이 있을 수 있다.

> **충분한 교육과정**       
  충분한 교육과정은 지능적인 시스템을 충분한 해결책으로 이끄는 교육과정이다. 이것은 업무와 지능적인 시스템에 한정되고, 두 개 이상의 충분한 교육과정이 있을 수 있다.
  
> **θ<sup>max</sup><sub>T,Is</sub>를 참고하는 작업별 잠재력**           
  θ<sup>max</sup><sub>T,Is</sub>를 참고하는 작업별 잠재력은 (최적 교육과정 이후) 작업에 대해 주어진 지능적 시스템에 의해 생성될 수 있는 최상의 기술 프로그램의 기술이다. 이것은 작업 및 지능형 시스템에 특화된 스칼라 값이다. 
  
> **지능형 시스템 범위**       
  지능형 시스템 범위는 작업 값 ω<sub>T</sub>가 0이 아니고 지능형 시스템이 훈련 단계 후에 충분한 해결책을 생산할 수 있는 모든 작업을 포함하는 작업 공간의 하위 공간이다. 이 공간은 무한할 수 있다. "충분한 해결책을 생산할 수 있다는 것"은 고려된 지능형 시스템과 과제를 위한 충분한 교육과정이 존재함을 의미한다. 범위는 는 지능형 시스템의 속성이다.
  
> **지능형 시스템 잠재력**       
  지능형 시스템 잠재력은 시스템 범위에 있는 모든 태스크에 대한 태스크별 잠재적 값의 집합이다. 잠재력은 지능 시스템의 속성이다.


대부분의 경우 최적의 기술과 최적의 해결책보다는 충분한 기술과 충분한 해결책을 고려하는 것이 더 유용하다. 우리는 응용 프로그램 설정에서 가능한 적은 자원을 사용하여 충분한 성과를 달성하려고 한다. 무제한 리소스를 사용하여 가능한 최대 성능을 달성하려는 경우는 드물고 실용적이지 않습니다.

---

### 알고리즘 정보이론을 이용한 일반화 난이도, 경험, 사전 지식의 정량화

알고리즘 정보 이론(AIT)은 정보 이론의 컴퓨터 과학 확장으로 볼 수 있다. AIT는 복잡성, 무작위성, 정보 및 계산과 관련된 유용하고 직관적인 컴퓨터 과학을 공식화하는 것과 관련이 있다. AIT의 중심은 알고리즘 복잡성의 개념이다. 다른 맥락에서 광범위한 소개를 위해 알고리즘 복잡성(Kolmogorov 복잡성 또는 알고리즘 무작위성 이라고도 함)은 독립적으로 조사되었다.

알고리즘 복잡도(Algorithmic Complexity)는 수학적 객체의 "정보 내용"에 대한 척도로 정보이론의 엔트로피 개념과 매우 흡사하다. 우리는 필요에 따라 이진 문자열의 구체적인 사례만 고려할 것이다. 지금까지 소개한 모든 객체는 모든 프로그램이 이진 문자열로 표시될 수 있기 때문에 스칼라 값(점수, 잠재력) 또는 이진 문자열(상태, 프로그램, 상황 및 응답)이었다.

문자열의 알고리즘 복잡도(H(s))는 고정된 범용 언어에서 문자열의 최단 설명 길이이다. 이는 고정 범용 튜링 기계에서 실행할 때 문자열을 출력하는 최단 프로그램의 길이이다. 모든 범용 튜링 기계가 다른 범용 튜링 기계를 모방할 수 있기 때문에 H(x)는 상수에 대해 기계 독립적이다.

우리는 알고리즘 복잡성을 사용하여 문자열 s<sub>2</sub>가 문자열 s<sub>1</sub>에 대해 가지는 정보 내용을 정의할 수 있다("상대 알고리즘 복잡도" 및 H(s1|s2)라고 한다). 즉 s<sub>2</sub>를 입력으로 사용하는 최단 프로그램의 길이인 s<sub>1</sub>를 생산한다. "s<sub>2</sub>를 입력으로 사용"은 s<sub>2</sub>가 프로그램 설명의 일부임을 의미하지만 프로그램 길이를 계산할 때 s<sub>2</sub>의 길이는 고려되지 않는다.

어떤 프로그램이든 이진 문자열로 표현될 수 있기 때문에 우리는 상대 알고리즘 복잡성을 사용하여 두 프로그램이 얼마나 밀접하게 연관되어 있는지를 설명할 수 있다. 우리는 이러한 관찰을 바탕으로 작업의 "일반화 어려움"이라는 직관적인 개념을 다음과 같이 정의할 것을 제안한다.

#### 고려사항

> **과제 T**          
  ***Sol<sup>θ</sup><sub>T</sub>***         
  임계값 θ(평가 중 최소 기술 θ를 달성하는 가장 짧은 기술 프로그램)의 가능한 모든 해결책 중 가장 짧은 해결책           
  ***훈련 Sol<sup>θ</sup><sub>T</sub>***         
  교육과정이 주어진 최단 시간 훈련 솔루션(교육과정에서의 상황에 대해 최적의 훈련 시간 성과를 달성하는 기술 프로그램)

#### 커리큘럼 C와 기술 임계값θ가 주어진 과제의 일반화 어려움(*GD<sup>θ</sup><sub>T, C</sub>*)

최단 최적 교육 시간 솔루션 *TrainSol<sup>opt</sup><sub>T, C</sub>* 에 의해 *Sol<sup>θ</sup><sub>T</sub>* 의 알고리즘 복잡도 부분이 설명된다. 즉 C 커리큘럼의 상황에 대해 최적으로 수행하는 가능한 최단시간 프로그램을 입력으로 채택하고 해당 기술 프로그램의 길이로 정규화된 평가 중에 최소 θ의 기술 수준에서 수행하는 프로그램을 생성한다. 이 수치는 0과 1 사이의 값이다. 

![2-3](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/figure/2-3.png?raw=true)             

따라서, "일반화 어려움"이 높은 작업은 충분한 기술을 달성하기 위해 평가 시간이 가능한 가장 간단한 최적 훈련 시간과 크게 달라야 하는 작업이다. 상대 알고리즘 복잡성은 이 차이를 정량화하기 위한 측정법을 제공한다. GD는 적절한 평가 시간 솔루션 프로그램이 되기 위해 가장 짧은 훈련 시간 솔루션 프로그램을 얼마나 많이 편집해야 하는지를 측정하는 척도이다. 과제의 일반화 어려움은 없다(즉, 불확실성을 수반하지 않는다). 일반화할 수 있는 기술 프로그램은 상황에 익숙한 정확한 훈련 상황보다 상황 공간에서 "더 많은 근거를 다루는" 기술 프로그램입니다. 이는 미래의 불확실성을 다룰 수 있는 프로그램이다. 

이러한 일반화 어려움의 정의는 직관에 반하는 것처럼 보일 수 있다. Occam의 면도날 원칙은 훈련 상황에서 작동하는 가장 간단한 프로그램도 잘 일반화하는 프로그램이어야 한다고 말한다. 일반화는 과거에 최적화되었을 동작을 압축할 수 있는 능력이 아닌 미래의 불확실성에 대처하는 능력을 설명한다. 미리의 불확실성에 대비하는 것은 비용이 든다.

> *철학적 측면에서, 이것이 아이들의 교육이 게임을 연습하고 그들의 과거 또는 현재의 의사결정 필요와 관련이 없어 보이는 미래의 상황에 대비하는 방법(대개 호기심에 의해 움직이는 과정)을 습득하는 것을 포함하는 이유이다. 0-10세 동안 외부적인 보상(예: 사탕 섭취)을 극대화할 수 있는 가장 단순한 행동 정책을 배운 10세라면 교육을 제대로 받지 못할 것이다. 그리고 미래의 상황에서는 잘 일반화되지 않을 것이다.*

필연적으로 *TrainSol<sup>opt</sup><sub>T, C</sub>* 는 교육 상황에 대한 올바른 대응을 하기 위해 필요하지 않은 정보나 기능을 모두 제공합니다. 이것은 평가 상황을 처리하는 데 유용할 수 있는 정보나 기능을 폐기할 수 있다. 실제로 *TrainSol<sup>opt</sup><sub>T, C</sub>* 가 그러한 정보를 폐기할 필요가 없는 경우(즉, 과거에 최적이었던 가장 단순한 동작은 미래에도 충분함)는 평가가 적응할 필요가 없다는 것을 의미한다(비확실성 새로움이나 불확실성 없음). 따라서 작업은 일반화를 포함하지 않지만 잠재적으로 어떤 시작점(예: 다른 작업의 솔루션)을 주어줄 수 있다.

동일한 아이디어를 표현하는 또 다른 방법은 *일반화가 새로운 데이터가 도착할 때(예: 평가 시) 작업을 재해석해야 한다*는 것이다. 이는 과거의 관점에서 볼 때 쓸모없어 보이지만 미래에 유용하게 사용될 수 있는 과거 데이터의 표현을 저장해야 한다는 것을 의미한다. 예를 들어 선을 따라 다음과 같은 라벨이 붙은 점을 고려해보자(*(x = −0.75, label = False),(x = 0.15, label = True),(x = −0.1, label = True)*). 이러한 점의 처음 두 개에 대한 분류 프로그램을 교육할 때 최단시간 훈련시간 해결책의 일부는 *λ(x) : x > 0 또는 λ(x) : bool(ceil(x))* 일 수 있다. 마지막 점*(x = -0.1, label = True)* 에 적용할 때, 이러한 해결책은 실패할 수 있다. 대신 모든 과거 데이터 점을 저장하고 평가 시 반응을 반환하기 위해 가장 가까운 값을 사용하는 알고리즘이 작동한다. 가장 가까운 이웃 프로그램이 미래의 불확실성에 더 잘 대비할 수 있을 것이다. 하지만 기록을 하려면 휠씬 더 많은 공간이 필요할 것이다. 

일반화 난이도의 이 첫 번째 정의는 시스템의 기존 역량에 관계 없이 훈련 상황과 다른 평가 상황의 처리 난이도를 정량화하는 시스템 중심의 일반화만 포착한다. 개발자 인식 일반화를 포착하려면 훈련이 시작할 때 SkillProgramGen, ISUpdate, isState<sub>t=0</sub>의 초기 상태의 시스템을 고려할 필요가 있다.

#### 교육 과정 C 및 기술 임계값θ가 주어진 지능형 시스템에 대한 작업의 개발자 인식 일반화 어려움(*GD<sup>θ</sup><sub>IS, T, C</sub>*)

이것은 TrainSol<sup>opt</sup><sub>T, C</sub>에 의해 설명되는 Sol<sup>θ</sup><sub>T</sub>의 알고리즘 복잡도 부분 및 시스템 IS<sub>t=0</sub>의 초기 상태이다. 이것은 초기 시스템을 입력으로 채택하고 커리큘럼 C에서 상황에 대해 최적으로 수행하는 가능한 가장 짧은 프로그램을 추가한다. 그리고 평가 중에 θ이상의 기술 수준에서 수행하는 기술 프로그램을 생성하여 기술 프로그램의 길이에 의해 정상화된다. 이 수치는 0과 1 시이의 값이다. 

![2-4](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/figure/2-4.png?raw=true)              

우리는 이 중에서  IS<sub>t=0</sub> = SkillProgramGen, ISUpdate, isState<sub>t=0</sub>에 주목한다.

개발자 인식 일반화는 초기 시스템과 최단 훈련 시간 솔루션 측면에서 (즉, 사용자가 원하는 대로 사용할 수 있다는 점에서) 가장 짧은 평가 시간 솔루션에 대한 불확실성의 양을 나타냅니다. 평가 시간 솔루션을 얻기 위해 가장 짧은 교육 시간 솔루션을 수정해야 하는 양은 초기 시스템의 내용을 활용할 수 있다.

마찬가지로 과제 T<sub>1</sub>에서 과제 T<sub>2</sub>(충분한 경우)까지의 일반화 난이도를 *H(Sol<sup>θ<sub>T<sub>2</sub></sub></sup><sub>T<sub>2</sub></sub>|Sol<sup>θ<sub>T<sub>1</sub></sub></sup><sub>T<sub>1</sub></sub>) / H(Sol<sup>θ<sub>T<sub>2</sub></sub></sup><sub>T<sub>2</sub></sub>)* 로 정의할 수 있다. 또한 이러한 정의를 작업 집합으로 확장할 수 있다(예: 연습 작업 집합에서 테스트 작업 집합으로 일반화 어려움). 이는 전체 테스트 세트의 일반화 난이도를 정량화하는 데 유용할 수 있다. 이러한 개념은 솔루션을 구성하는 데 필요한 노력으로 정의된 본질적인 작업 어려움의 개념(일반화와 무관함)과 관련이 있다.

#### 작업 T 및 기술 임계값 θ에 대한 지능형 시스템의 사전 지식(*P<sup>θ</sup><sub>IS, T</sub>*)

이것은 초기 시스템(교육 단계 시작 시)에 의해 설명되는 기술 임계값 θ의 최단 솔루션의 알고리듬 복잡도의 부분이고, 초기 시스템을 입력(*SkillProgramGen, ISUpdate, isState<sub>t=0</sub>*)으로 사용하는 가능한 가장 짧은 프로그램의 길이(*H(So<sup>θ</sup><sub>T</sub>*)이다. 그리고 평가 중 최소 θ의 기술 수준에서 수행하는 T의 최단 솔루션을 생성한다. 지능형 시스템은 이러한 특정 솔루션을 생성할 필요가 없고, 이 수치는 0과 1 시이의 값이다. 

![2-5](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/figure/2-5.png?raw=true)             

따라서 정의되는 "사전 지식"은 초기 시스템에 내장된 "관련 정보의 양"으로 시스템이 충분하거나 최적의 솔루션으로부터 얼마나 가까운지를 측정하는 것으로 해석할 수 있다. 이것은 초기 시스템에 내장된 "정보의 양"과는 다르다는 점에 유의해야 한다(초기 시스템의 알고리즘 복잡성일 뿐이다). 이와 같이, 우리의 조치는 당면한 작업과 무관한 사전 지식을 포함하는 대형 시스템에 대해 최소한의 불이익을 줄 뿐이다(단 하나 추가된 비용은 지식 인덱싱 및 검색 오버헤드로 인한 비용).

#### 경험(E<sub>IS, T, C</sub>)

더 나아가서 우리는 상대적인 알고리즘 복잡성을 사용하여 커리큘럼 동안 작업에 대해 지능형 시스템에 의해 축적된 경험 *E<sub>IS, T, C</sub>* 를 정의할 수 있다.

학습 중 t번째 단계를 고려해보자
> t 에서 시스템이 일부 새 *데이터*를 이진 문자열 *situation<sub>t</sub>, Responsese<sub>t</sub>, feedback<sub>t</sub>* 형식으로 수신한다. *response<sub>t</sub>* 은 이후 생략될 수 있지만, *IS*가 이전에 생성한 스킬 프로그램의 결과물로서, *situation<sub>t</sub>* 가 알려지면 바로 IS가 알 수 있다고 가정할 수 있다.

> 이 데이터 중 일부만 작업 해결과 관련이 있습니다(데이터가 노이즈가 많거나 그렇지 않으면 정보가 부족할 수 있음).

> 일부 데이터만 지능적 시스템을 위한 새로운 정보를 포함하고 있다(상황과 응답은 반복적일 수 있으며 지능적 시스템은 여러 번 반복하거나 여러 가지 방법으로 제시해야 하는 느린 학습자일 수 있다). 시스템에 참신하게 보일 수 있는 정보를 특징짓기 위해 커리큘럼에 한 번도 나타나지 않았던 정보보다(둘 사이의 차이는 시스템의 학습 효율성에 있다) "소설"이라는 용어를 사용한다는 점에 유의해야한다. 

우리는 비공식적으로 t 단계에서 발생한 경험의 양을 시스템에서 받은 소설 정보의 양으로 정의한다. 이는 현재 상황 데이터와 피드백 데이터(즉, IS가 최적의 지능을 가진 경우 단계 데이터를 사용하여 솔루션에 대한 불확실성을 얼마나 줄일 수 있는지)에서 작업에 의해 이용 가능하게 된 솔루션에 대한 잠재적 불확실성 감소량에 해당한다.

#### t 단계에서 발생한 경험(*E<sup>θ</sup><sub>IS, T, t</sub>*)         

> *E<sup>θ</sup><sub>IS, T, t</sub> = H(Sol<sup>θ</sup><sub>T</sub>|IS<sub>t</sub>) - H(Sol<sup>θ</sup><sub>T</sub>|IS<sub>t</sub>, data<sub>t</sub>)*      

> *IS<sub>t</sub> = SkillProgramGen, ISUpdate, isState<sub>t</sub>*       
  *data<sub>t</sub> = Situation<sub>t</sub>, response<sub>t</sub>, feedback<sub>t</sub>

모든 단계를 요약하면 우리는 총 경험에 대한 다음과 같은 정의를 얻는다(이전처럼 고려된 솔루션의 알고리듬 복잡성에 의해 정상화하는 것에 주목한다).

#### C 커리큘럼을 통한 *E<sup>θ</sup><sub>IS, T, C</sub>*

![2-6](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/figure/2-6.png?raw=true)              

따라서 정의된 "경험"은 커리큘럼의 과정에 대한 과제에 대해 시스템이 받은 관련 정보의 양을 측정하는 것으로 해석할 수 있다. 각 단계에서는 새로운 정보만 설명한다.

이는 커리큘럼(즉, 커리큘럼의 알고리즘 복잡성)에 포함된 "정보의 양"과 다르기 때문이다. 우리의 조치는 시끄러운 커리큘럼을 거치는 시스템에 불이익을 주지 않는다.

게다가 우리는 커리큘럼의 정보 내용을 글로벌하게 모으는 대신에 각 단계에서 관련되고 참신한 정보의 열띤 합을 사용하기 때문에 학습자에게 제공되는 관련 정보를 흡수하는 속도가 느린 학습자에게 불이익을 준다.

우리가 구한 값의 합계가 "모든 단계에 걸쳐 집계된 각 단계에서 관련 정보의 양(확실하거나 그렇지 않은 경우)"과 다르기 때문에 반복적인 교육과정을 거치는 시스템에 불이익을 주지 않는다.

만약 빠른 학습자가 고정된 커리큘럼의 처음 10단계에 걸쳐 충분한 정보를 흡수한다면, 느린 학습자는 같은 것을 성취하기 위해 같은 커리큘럼의 90 단계가 더 필요하다. 우리는 그것이 아무것도 배우지 않았던 지난 90단계의 중복된 학습자를 위한 경험으로 계산하지 않고, 느린 학습자를 위해 100개의 모든 단계를 셀 것이다.

#### 지능의 정의

> 시스템의 지능과 일반화의 어려움 이전의 경험에 대한 작업 범위의 기술-확정 효율성의 척도이다.

우리는 지능적인 시스템이 IS라고 생각한다. 우리는 *Cur<sup>θ<sub>T</sub></sup><sub>T</sub>* 가 IS의 작업 T에 대한 기술 *θ<sub>T</sub>* 의 솔루션을 생성하게 되는 커리큘럼의 공간을 주목한다. 그리고 *Cur<sup>opt</sup><sub>T</sub>* 는 IS가 최고 기술 솔루션(시스템의 잠재력 *θ<sup>max</sup><sub>T, IS</sub>* 에 도달하는 솔루션)을 생성하게 하는 커리큘럼의 공간이다. 시스템이 작업을 최적으로 해결하는 방법을 배울 수 없을 수 있기 때문에 시스템의 잠재력은 작업에 대한 최적의 솔루션보다 낮을 수 있다.

우리는 *θ<sup>max</sup><sub>T, IS</sub>* 를 Θ로 표기할 것이다. 우리는 평균 함수 평균과 PC가 주어진 커리큘럼 C의 확률에 주목한다(작업 공간에 대한 평균화에 사용됨).

작업 범위에 연결된 I의 지능를 다음과 같이 정의한다.

**시스템 IS의 지능이 범위를 벗어남(충분한 경우)**         
![2-7](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/figure/2-7.png?raw=true)          
**시스템 IS의 지능이 범위를 벗어남(최적 사례)**          
![2-8](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/figure/2-8.png?raw=true)           

주의할 점
> P<sub>IS, T</sub> + E<sub>IS, T, C</sub>(사전 지식 및 경험)는 문제의 정보에 대한 시스템의 총 노출을 나타낸다. 그리고 교육을 시작할 때 시작하는 정보를 포함한다.

> 각 커리큘럼의 확률에 따라 가중치를 부여는 커리큘럼 하위 공간에 대한 합계는 훈련 후 예상되는 시스템 결과를 나타낸다. 이러한 합계는 커리큘럼(최소한 특정 기술 수준으로 이어지는 커리큘럼)의 하위 공간에 걸쳐 있기 때문에 확률의 합계는 1보다 더 낮다. 우리는 때때로 충분한 기술이나 최적의 기술에 도달하는 학습자에게 불이익을 주고 있다.

> ω<sub>T</sub> · θ<sub>T</sub>는 T에서 충분한 기술을 달성하는 데 있어 우리가 갖는 주관적인 가치를 나타낸다. 그리고 ω<sub>T, Θ</sub> · Θ는 T에서 시스템의 전체 잠재력 Θ에 해당하는 기술 수준을 달성하는 데 있어 우리가 가지는 주관적인 가치를 나타낸다.

> 도식적으로 각 과제의 기여는 다음과 같다.              
  ![2-9](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/figure/2-9.png?raw=true)           
  이 값은 ω 값에 의해 가중치가 추가되어 각 채점 함수의 규모와 독립적으로 서로 다른 작업에서 기술을 균일하게 비교할 수 있다.

우리는 시스템의 지능을 시스템이 최종 직무별 기술(충분한 기술 또는 가능한 최고 기술)의 평균(해당되는 모든 커리큘럼에 대한 확률론적 평균)을 획득하는 정보 효율성의 측정치와 동일시한다. 그리고 고려된 작업의 개발자 인식 일반화 난이도에 의해 가중치가 부여된다(과제 값 ω에 따라 작업 전반에 걸쳐 대응 가능한 기술을 만든다).

*지능은 불확실성과 적응을 수반하는 중요한 작업에서 학습자가 경험과 사전 지식을 새로운 기술로 바꾸는 속도이다.*

우리의 정의는 알고리즘 정보 이론에 기초한 지능의 첫 번째 공식 정의가 아니라는 것을 주목하라. 우리는 다른 세 가지 AIT 기반 정의(C-Test, AIXI model, Universal Intelligence model)를 기준으로 우리의 접근법이 다른 관점을 나타낸다는 것을 분명히 해야 한다. 

우리는 우리의 형식주의에 대한 많은 주요 관찰에 집중해 볼 것이다(2.2.3 참조). 

> 고지능 시스템은 적은 경험과 사전 지식을 사용하여 높은 일반화 난이도 작업(즉, 미래에 대한 높은 불확실성을 특징으로 하는 작업)을 위한 고기술 솔루션 프로그램을 생성할 수 있는 시스템이다. 이것은 상황 공간의 알려지지 않은 부분에서 가능한 한 많은 지면을 커버하기 위해 이것에 있는 모든 정보를 매우 효율적으로 이용할 수 있는 시스템이다. 지능은 상황 공간의 일부에 대한 정보와 미래 상황 공간의 최대 영역 이상으로 잘 수행할 수 있는 능력 사이의 변환 속도로 새로움과 불확실성을 수반할 것이다(그림 3 참조).

> 지능 측정은 범위의 선택(작업 공간 및 작업에 대한 가치 기능)과 관련이 있다. 또한 선택적으로 범위 작업(충분한 경우)의 충분한 기술 수준을 선택할 수 있다.

> 기술은 지능적인 시스템에 의해 소유되지 않고, 지능 과정의 출력 아티팩트의 속성이다(기술 프로그램). 높은 기술은 높은 지능이 아니다. 이것들은 모두 다른 개념이다.

> 지능은 학습과 적응을 수반해야 한다. 미래의 불확실성을 처리하기 위해 경험에서 추출한 정보를 운영해야 한다. 작업에 대한 평가 상황에서 잘 수행할 수 있는 능력으로 시작하는 시스템은 이 작업에 대한 개발자 인식 일반화 난이도가 매우 낮다. 따라서 지능지수가 낮아질 수 있다. 

> 지능은 곡선에 맞지 않다. 우리들의 정의에 의하면 알려진 데이터 포인트와 일치하는 가장 단순한 기술 프로그램을 생산하는 시스템은 일반화의 어려움 없이 잘 수행할 수 있었다. 지능형 시스템은 미래의 불확실성을 설명하는 행동 프로그램을 생성해야 한다.

> 지능의 척도는 커리큘럼 최적화와 관련이 있다. 더 나은 커리큘럼 공간은 (평균적으로) 더 큰 실제 스킬과 더 큰 표현 지능(더 나은 기술-확정 효율성)으로 이어질 것이다.

![2-10](https://github.com/junsu9637/Study/blob/main/Artificial%20Intelligence/Montreal%20AI%20101%20-%20Cheet%20Sheet/figure/2.10.png?raw=true)

그림 3 : 더 높은 지능은 동일한 정보를 사용하여 미래의 상황 공간에서 "더 많은 영역을 커버"한다.

### 2.2.2 계산 효율성, 시간 효율성, 에너지 효율성 및 위험 효율성

위에서 우리는 지능형 시스템의 정보 효율성(일반화 난이도에 관한 정보 효율성 및 경험 효율성)만 고려했다. 우리는 이것이 오늘날 AI 연구를 발전시키기 위해 가장 실행 가능하고 적절한 방법이라고 믿는다(2.2.3 참조). 그러나 이것이 우리가 고려하고 싶은 유일한 방법는 아니다. 다양한 방식으로(예: 정규화 용어) 정의에 통합될 수 있는 몇 가지 대안은 다음과 같다. 

> **기술 프로그램의 계산 효율성**        
  훈련 데이터는 풍부하지만 추론 시간 계산이 비싼 설정의 경우, 최소한의 계산 자원 소비를 하는 기술 프로그램의 생성해야 한다.

> **지능형 시스템의 계산 효율성**         
  교육 시간 계산이 비싼 설정의 경우, 기술 프로그램을 생성하기 위해 최소한의 계산 자원을 소비해야 한다.

> **시간 효율**              
  시간 제한 설정에서 지능형 시스템이 기술 프로그램을 생성하는 지연 시간을 최소화해야 한다. 
  
> **에너지 효율**          
  생물체계에서 기술 프로그램을 운영하거나 커리큘럼을 거치는 데 있어서 기술 프로그램을 만드는데 소모되는 에너지의 양을 최소화해야 한다. 

> **리스크 효율**        
  교육 과정을 거치는(즉, 경험을 수집하는) 지능적 시스템의 위험을 수반하는 설정의 경우, 자원 효율성 또는 정보 효율성을 희생하여 안전한 커리큘럼을 생성해야 한다. 이것은 에너지 효율과 유사하고, 생물학적 시스템과 자연적 진화에 매우 관련이 있다. 더 빠른 학습으로 이어질 수 있는 어떤 새로운 것을 추구하는 행동은 위험할 수 있다.

정보 효율이 에너지 효율과 위험 효율을 위한 대용으로서 많은 환경에서 작용한다는 점에 유의할 수 있다. 

효율성을 정량화하는 이러한 대안적 방법이 향후 전문화된 AI 애플리케이션 맥락에서 관련될 것으로 예상한다. 그리고 우리는 다른 사람들이 정보 효율성에 더하여 그것들을 통합한 새로운 형태의 지능을 개발하도록 격려하기 위해 이것에 더 집중한다. 

이 프레임워크의 주요 가치는 우리가 유연한 또는 일반적인 인공 지능을 이해하고 평가하는 방법에 대한 실행 가능한 관점 변화를 제공하는 것이다. 

### 2.2.3 실제적 의미

위의 정의는 우리가 지금까지 도입해 온 직관적 개념에 대해 추론할 수 있는 양적 도구뿐만 아니라 공식적인 프레임워크를 제공한다. 특히, "일반화 어려움", "기술 습득 효율성으로서의 지능", "지능을 평가할 때 사전 지식과 경험을 위한 통제"가 무엇을 의미하는지에 대한 개념을 제공한다. 우리는 이러한 관점의 변화가 다음과 같은 실질적인 결과를 가져온다고 주장한다.

#### 유연한 또는 일반적인 AI에 대한 연구 방향의 결과

> 지능적인 시스템을 만드는 과정이 최적화 문제로 다가갈 수 있다는 것은 분명하다. 여기서 목적 함수는 양적 지능 공식의 계산 가능한 근사치이다. 2.2.2에서 지적한 바와 같이 목적적 기능은 다른 형태의 효율성을 고려하는 정규화 용어를 통합하여 더욱 정교해질 수 있다. 

> 기술만을 추구하기 보다는 광범위하거나 범용적인 능력 개발에 초점을 맞추도록 장려하고, 경험이나 사전 지식의 과도한 의존을 처벌하는 목표 측정 기준과 낮은 일반화 난이도를 특징으로 하는 작업을 제안한다.

> 프로그램 합성에 대한 관심을 유도한다. 우리가 감각적 입력을 받아들이고 행동(강화 학습에서 물려받은 비전)을 생성하는 일률적인 블랙박스로 "에이전트"를 생각하는 것을 그만둘 것을 제안한다. 우리의 형식주의는 지능을 소유하는 시스템의 부분("지능형 시스템", 프로그램 제어 엔진)을 기술을 달성하는 부분과 행동을 구현하는 부분(지능 프로세스의 비지능적 출력을 진행하는 "프로그램")으로 명확하게 구분한다. 본 문서에서 우리가 지적했듯이, 우리는 프로세스와 인공물 사이의 이러한 혼란이 AI의 개념화에서 진행 중인 근본적인 문제였다고 믿는다.

> "최적 커리큘럼"의 개념을 활용하고 더 나은 커리큘럼이 학습 시스템에 의해 발현되는 지능을 증가시킨다는 사실에 주목한다. 

> 지능을 평가하는 데 있어 사전 지식은 인간과 유사한 지식(예: 핵심 지식)을 기반으로 시스템을 구축하는 데 관심을 유도한다.

#### 유연한 또는 일반적인 AI 시스템 평가에 대한 결과

> 일반화 난이도 정의 및 정량화는 "지역 일반화", "광범위한 일반화", "극한 일반화"를 수행하는 것이 무엇을 의미하는지 공식적으로 추론할 수 있는 방법을 제공한다. 그리고 일반화의 어려움이 전혀 없는 테스트를 걸러내려고 한다.

> AI와 인간의 지능을 비교하기 위한 구체적인 지침을 제시한다. 이러한 비교는 공유된 작업 범위와 공유된 이전 작업부터 시작해서 특정 수준의 기술을 달성하는 데 경험의 효율성을 비교한다(2.3.1 참조). 

> 과제를 평가하기 위한 테스트 세트를 개발할 때 일반화 난이도를 고려하는 것의 중요성을 보여준다(2.3.2 참조). 이는 일반화하지 않고 바로 가기에 의존하는 솔루션(예: 컴퓨터 비전에서의 글로벌 의미론과는 반대로 지역 텍스처에 의존하는)을 폐기할 수 있는 평가 지표로 이어질 수 있기를 바란다.

> 엄격하게 특성화하기 위해 지능적인 시스템에 대해 질문할 수 있는 일련의 실제 질문을 제공한다.            
  \- 이것의 범위는 무엇인가?           
  \- 이 범위에 대한 "잠재력"은 무엇인가(최대 달성 가능한 기술)?            
  \- 이전 제품은 어떤 것이 있는가?           
  \- 기술 습득 효율성(지능)은 어떠한가?          
  \- 어떤 커리큘럼이 기술 또는 기술 습득 효율성을 극대화하는가?

## 2.3 이러한 관점에서 지능 평가

이 문서의 앞부분에서 우리는 넓은 능력의 발달에 관해서 측정 기술만으로는 우리를 발전시키지 못한다는 것에 대해 상세하게 설명했다. 우리는 AI 평가가 보다 성숙한 심리측정학(정신 측정 AI와 범용심리측정학 논제 채택)에서 배워야 한다고 제안했다. 그리고 우리는 AI 평가를 위한 실제적인 함의를 가진 새로운 형식주의를 제공하여 범위, 잠재력, 일반화 어려움, 경험, 선행 지식 개념의 중요성을 지적했다. 다음 절에서는 AI 평가와 관련된 주요 실무적 결론을 요약한다.

### 2.3.1 지능형 시스템 간의 공정한 비교

우리는 2.2.3에서 우리의 형식주의가 서로 다른 성격의 시스템의 지능을 비교하기 위한 구체적인 지침을 제안한다고 언급했다. 공정하고 엄격한 방식으로 이러한 비교를 할 수 있는 것은 인간과 유사한 일반 AI로 발전하는 데 필수적이다. 여기서 우리는 시스템 간의 이러한 지능 비교가 대상 시스템 범위, 잠재력, 사전 지식과 관련된 특정 요구사항을 어떻게 수반하는지 논한다. 또한 이러한 요구사항이 충족될 경우 이러한 비교가 어떻게 진행되어야 하는지 자세히 설명합니다.

> **범위 및 잠재적 요구사항**

2.1.2에서 우리는 지능은 반드시 적용범위에 묶여있다고 주장했다. 또한 II.2에 *"비교 척도는 대상 시스템이 공유하는 잘 정의된 작업 범위에 연결되어야 한다(모든 대상 시스템은 동일한 작업을 수행하는 방법을 배울 수 있어야 한다)*"같은 도입된 형식주의의 중심적인 생각을 주장했다. 

대상 시스템이 공유 범위에 걸쳐 서로 다른 잠재력(최대 달성 가능한 기술)을 가질 수 있다는 점을 고려해야 한다. 지능 비교는 기술 습득 효율성에 중점을 두어야 하지만 다른 수준의 기술에 도달하는 시스템 간에 기술 습득 효율성을 유의미하게 비교할 수는 없다. 이 기술 임계값은 모든 대상 시스템이 달성할 수 있어야 한다. 비교 척도는 고려된 직무 범위에 걸쳐 고정된 기술 임계값에 연결되어야 한다.

일반적으로 지능적인 시스템과 인간의 지능을 비교하는 것은 시스템에 의해 학습될 수 있는 과제의 범위가 일반적인 인간에 의해 학습될 수 있는 과제의 범위와 같을 경우에만 하는것이 맞다. 그리고 비교는 시스템이 인간 전문가와 동일한 수준의 기술을 달성하는 효율성에 초점을 맞추어야 한다. 실현된 최대 기술을 비교하는 것은 지능 비교로 구성하지 않는다.

> **사전 지식 요구사항**

2.2의 형식주의가 선행 점수를 단일 스칼라 점수로 요약하기 때문에 경험을 정량화하는 데 사용되는 점수와 동질적이다. 따라서 두 시스템을 동일한 사전 지식 시스템을 공유하는 데 엄격하게 비교할 필요는 없다. 두 시스템이 동일한 양의 경험을 사용하여 동일한 기술을 달성한 경우(사용되는 커리큘럼에 의해 결정되는 이 경험의 정확한 특성은 다를 수 있음), 사전 지식이 가장 적은 시스템이 보다 지능적인 것으로 간주될 것이다.

그러나 사전 지식을 완전히 정량화하는 것은 일반적으로 비현실적이다. 우리는 충분히 유사한 사전 지식 집합을 가정하는 시스템의 지능을 비교할 것을 권고한다. 이는 지능의 어떤 척도가 그것이 가정하는 이전의 것들을 명시적이고 완전하게 나열해야 한다는 것을 의미한다(2.3.2 참조). 또한, 이는 인간과 유사한 일반 지능을 구현하려는 시스템이 핵심 지식을 사전에 활용해야 함을 의미한다.

---

위의 조건이 충족되는 경우(공유 범위, 범위에 걸쳐 잘 정의된 기술 임계값, 유사 지식 이전), 공정한 지능 비교는 대상 시스템의 기술-평가 효율성을 대조하는 것으로 구성된다. 더 지능적인 시스템은 평균적인 경우에서 원하는 기술 한계점에 도달하기 위해 최소한의 경험만을 사용하는 시스템일 것이다. 또는 계산 효율성, 에너지 효율성 및 위험 효율성도 고려될 수 있다(2.2.2 참조).

### 2.3.2 이상적인 지능 벤치마크에 대해 기대하는 사항

아래 권고안은 인간과 유사한 일반 지능의 후보 벤치마크가 보유해야 하는 속성에 관한 이 문서의 결론을 종합한다.

> 


# 3. 벤치마크 제안 : ARC 데이터 세트
## 3.1 설명 및 목표
### 3.1.1 ARC가 무엇인가?
### 3.1.2 중심 지식 이전
### 3.1.3 심리측정학 지능 테스트의 주요 차이점
### 3.1.4 ARC에 대한 솔루션이 어떤 모습이며, AI 애플리케이션에 어떤 영향을 미칠 수 있는가
## 3.2 약점 및 향후 개선 사항
## 3.3 가능한 대안
### 3.3.1 광범위한 일반화를 측정하기 위한 기술 벤치마크 용도 변경
### 3.3.2 개방적이고, 적대적 또는 협업적인 접근 방식


