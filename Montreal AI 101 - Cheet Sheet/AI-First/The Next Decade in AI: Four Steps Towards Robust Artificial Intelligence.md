# The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence

인공지능의 다음 10년: 강력한 인공지능을 향한 4단계

# 요약

인공지능과 기계 학습에 대한 최근의 연구는 범용 학습과 더 큰 훈련 세트 그리고 점점 더 많은 컴퓨팅을 주로 강조하고 있다.
대조적으로, 더 풍부하고 강력한 AI의 기질을 제공할 수 있는 인지 모델 중심의 복합적인 지식과 추론 기반 접근법을 제안한다.

# 1. 강력한 인공지능을 향하여

어느 누구도 향후 수십 년 동안 딥러닝이나 AI가 어떤 방향으로 진화할지는 잘 모르지만, 우리가 새로운 수준에 도달하려면 지난 10년 동안 무엇을 배웠는지, 다음에 무엇을 조사해야 하는지 모두 고려해 볼 가치가 있다.

그것을 새로운 차원의 *강력한 인공지능*이라고 부르자. 이것이 반드시 초인적이거나 자기 중심적인 것은 아니지만, *체계적이고 신뢰할 수 있는 방법*으로 넓은 범위의 문제에 그것이 알고 있는 것을 적용하는 것으로 셀 수 있다. 그리고 세계에 대해 *유연하고 역동적으로* 추론할 수 있는 다양한 출처로부터의 지식을 종합하고, 우리가 보통 어른에게 기대하는 방식으로 한 문맥에서 배우는 것을 다른 문맥으로 *옮깁니다*.

어떤 의미에서는 "초인적인" 또는 "일반적인 일반 지능"만큼 야심적이거나 제한되지 않는 작은 목표이지만, 그럼에도 불구하고 아마도 성취할 수 있는 중요한 단계일 것이다. 그리고 중요한 것은, 만약 우리가 인공지능을 만든다면 우리는 우리의 집, 우리의 길, 의사 사무실 병원, 우리의 사업, 그리고 우리의 지역사회에서 믿을 수 있습니다.

아주 간단하게, 만약 우리가 AI가 안정적으로 작동할 것이라고 기대할 수 없다면, 우리는 그것을 신뢰하지 말아야 한다. 
> 그 반대는 사실이 아니다. 신뢰성은 신뢰도를 보장하지 않는다. 신뢰성은 가치 및 우수한 엔지니어링 관행을 포함한 많은 요소 중 하나의 전제 조건일 뿐이다.

---

예를 들어 *narrow intelligence*와 같은 강력한 AI와 대조할 수 있다. *narrow intelligence*은 하나의 좁은 목표를 매우 잘 수행하는 시스템이다. (예: 체스 경기 또는 개 품종 식별) 그러나 종종 단일 작업 중심으로 극도로 집중되어 있고 광범위한 재교육이 없어 약간 다른 환경(예: 크기가 다른 보드 또는 한 비디오 게임에서 다른 캐릭터와 설정)으로도 강력하고 *이전할 수 없는 방식*으로 이루어진다. 이러한 시스템은 종종 그들이 훈련받은 정확한 환경에 적용될 때 인상적으로 잘 작동한다. 하지만 우리는 환경이 훈련 받은 환경과 다를 경우, 작은 방법일지라도 그들을 믿을 수 없다. 이러한 시스템은 게임의 맥락에서 강력함을 보여주었다. 그러나 아직 현실 세계의 역동적이고 개방적인 흐름에서 적절한 것으로 입증되지는 않았다.

사람들은 강력한 지능을 점묘법적 지능(표면적으로는 비슷하고 다소 예측할 수 없는 방식의 많은 경우에 작동하지만 많은 다른 경우에서는 실패하는 지능)이라고 부르는 것과 대조해야 한다.  그림 1의 왼쪽은 일반적인 스쿨버스를 인식하지만, 눈길에 전복된 스쿨버스를 인식하지 못하는 경우를 보여준다. 그리고 오른쪽은 일부 문장을 정확하게 해석하지만 관련 없는 소재가 있을 때 실패하는 읽기 시스템을 보여준다.

![그림 1: 비전 및 언어의 특이적 오류](https://user-images.githubusercontent.com/76898072/104152556-413c6e00-5423-11eb-9443-45ca1d6c8661.png)

AI 문헌을 자세히 살펴보면 누구나 처음부터 강건성이 그 분야를 벗어났다는 것을 알게 될 것이다. 그 문제에 투입된 막대한 자원에도 불구하고, 딥러닝은 지금까지도 그 문제를 해결하지 못했다.

반대로, 지금까지의 딥러닝 기술은 데이터에 굶주리고, 얕고, 취약하며, 일반화 능력이 제한적이라는 것이 입증되었다(Marcus, 2018).

> *AI의 한계 : 우리가 특정 작업에서 매우 잘 수행하는 시스템을 설계할 수 있지만, 그것들은 여전히 취약하고, 데이터에 목말라하며, 훈련 데이터나 창작자의 가정으로부터 약간 벗어난 상황을 이해할 수 없으며, 중요한 작업 없이 새로운 작업을 처리하기 위해 용도를 변경할 수 없는 뚜렷한 한계를 가지고 있다.* <br>
  \- Facebook AI 연구팀 -

> *증가하는 증거에 따르면 최신 모델은 데이터셋에서 인간이 하는 유연하고 일반화 가능한 방법으로 의미를 배우는 대신에 가짜 통계 패턴을 활용하는 법을 배우고 있다.* <br>
  \-  Yoshua Bengio - 
  
> *현재의 기계 학습 방법은 연습에서 종종 필요한 훈련 분포를 넘어 일반화해야 할 때 약하게 보인다.*

AI를 한 단계 끌어올리기 위해 우리가 할 수 있는 일은 무엇인가?

---

우리는 Ernie Davis가 만든 시스템을 먼저 개발하지 않고서는 강력한 지능을 달성할 수 없다. 그리고 **Deep inderstanding**이란, 복잡한 데이터 세트의 미묘한 패턴을 상호 연관시키고 식별할 수 있는 능력뿐만 아니라, 어떤 시나리오도 살펴보고 기자가 물어볼 수 있는 질문 *(who, what, why, when, how)* 도 해결할 수 있는 능력이다.

널리 논의된 신경 네트워크 GPT-2(이야기나 주어진 문장 조각들을 만들어 냄)와 같은 시스템은 표면적으로 깊은 이해를 반영하는 것처럼 보이는 것을 전달할 수 있다. 예를 들어, "두 명의 병사가 술집에 들어왔다"와 같은 문장 조각은 종종 유창하고 그럴듯하게 들리는 연속성(예를 들어, 사람, 술집, 술집 및 돈 사이의 관계 : 두명의 군인이 모술에 있는 술집에 들어가서 그들의 모든 돈을 술값으로 썼다.)을 만들어낼 수 있다.
하지만 아무리 많은 GPT-2 사례가 설득력 있게 보여도 현실은 그것의 표현이 얇고, 종종 면밀한 검사 아래 무너지는 경우가 많다. 다음은 2019년 12월 NeurIPS에 제시된 개발 중 벤치마크에서 도출한 두 가지 대표적인 사례이다.

 - *어제 세탁소에 옷을 맡기고 아직 가지러 가지 않았다. 내 옷들은 어디있지?*
 - *통나무 위에 개구리 여섯 마리가 있다. 두 번 떠나고, 세 번 왔다. 통나무에 있는 개구리의 수는 현재 17마리이다.*

첫 번째 GPT-2는 의문 조각(위치 기준)을 따르지만 드라이 클리닝이 있는 위치를 추적하지 못하는 요소의 범주를 정확하게 예측한다. <br>
두 번째 GPT-2는 다시 올바른 반응 범주(이 경우 숫자)를 정확하게 예측하여 세부 정보를 파악하지 못한다. <br>
Marcus에서 논의된 바와 같이 이러한 오류는 널리 퍼져 있다. 우리는 견고함을 달성하기 위해서는 분명히 더 안정적인 기질이 필요할 것이다.

---

관련 사업은 딥러닝 툴박스 내에서 기능 근사 및 구성을 위한 도구를 꾸준히 개선하고, 대규모 학습 세트를 수집하여 점점 더 큰 규모의 GPU 및 TPU 군집으로 확장하는 데 주력해 왔다. 더 큰 데이터 세트를 수집하고, 다양한 방식으로 데이터 세트를 보강하며, 기본 아키텍처에 다양한 종류의 개선 사항을 통합함으로써 GPT-2와 같은 시스템을 개선할 수 있다. 이러한 접근 방식은 가치가 있지만, 보다 근본적인 재검토가 필요하다.

더 많은 과감한 접근법이 추진될 수 있다. Yoshua Bengi는 딥러닝 툴킷을 대폭 확장하기 위해 여러 가지 복잡한 제안(분포 변화에 대한 민감성을 통해 통계적으로 인과 관계를 추출하는 기술 개발, 모듈형 구조를 자동으로 추출하는 기술 등)을 했다.

하지만 이것으로는 충분하지 않다. 더 강한 방법이 필요하다. 특히, 시스템을 구축하기 위한 프레임워크를 개발해야 한다. 이 프레임워크는 **복잡한 외부 세계에 대한 내부 모델 구축, 업데이트 및 추론을 위해 해당 지식을 사용하여 추상적 지식 획득, 표현 및 조작할 수 있다.**

---

어떤 의미에서 *지식, 내부 모델, 추론* 등 전통적인 인공지능의 세 가지 관심사로 돌아가고 있다. 그러나 현대적 기술로 새로운 방식으로 그것들을 다루기를 희망합니다.

이러한 각각의 우려의 중심은 고전적인 AI에 있다. John McCarthy는 선구적인 논문 "상식이 있는 프로그램"에서 상식적인 지식의 가치를 언급했다. Doug Lenat는 그의 삶의 작품에서 기계가 해석할 수 있는 상식적인 지식을 표현했다. Terry Winograd(구글 창업자 Larry Page, Sergey Brin의 멘토)에 의해 설계된 고전적인 AI "blocks world" 시스템 SHRLDU는 축적된 물리적 물체 세트의 위치와 특성에 대한 소프트웨어의 이해를 나타내는 업데이트 가능한 인지 모델의 내부 모델을 확인시켰다. SHRLDU는 시간이 지남에 따라 블록 세계의 상태에 대한 추론을 하기 위해 인지 모델에 대해 추론했다. 
> *기타 중요한 구성 요소( 간단한 물리학, 2-D 렌더러, 사용자 지정 도메인별 언어 구조 분석)는 가장 높은 피라미드의 서포트가 지원하는 가장 짧은 것이 녹색을 지원하는 것처럼 복잡한 문장들을 해독할 수 있는 것인가?*

기계 학습에서 최신 논문의 제목을 스캔하면 이러한 종류의 아이디어에 대한 참조가 줄어든다. 소수의 사람들은 추리를 언급할 것이고, 상식을 구현하려는 욕망을 언급할지도 모른다. 이는 대부분 (반드시) 개인이나 사물, 그들의 성질 같은 사물의 풍부한 인지 모델, 그들의 관계 같은 것이 결여될 것이다.

예를 들어 CPT-2와 같은 시스템이 더 좋고 더 나쁜 것을 위해 하는 일은 어떠한 명시적 (직접 표현되고 쉽게 공유되는 의미에서의) 상식에 대한 지식 없이, 어떠한 명시적 추론 없이, 그리고 세상의 어떤 명시적 인지 모델 없이 토론하고자 하는 것이다.

많은 사람들은 이러한 노동적으로 인코딩된 명시적 지식의 부족을 장점으로 본다. GPT-2는 이례적인 것이 아니라 기존 AI의 우려에서 벗어나 딥러닝의 부활에 힘입어 더욱 데이터 중심적인 패러다임으로의 추세적 특성이다. 이러한 경향은 많이 알려진 DeepMind의 Atari 게임 시스템으로 가속화되었으며, 나중에 논의된 바와 같이 상세한 인지 모델을 사용하지 않고 다양한 게임을 하는 데 성공했다.

이러한 경향은 최근 강화학습의 창시자 중 한 명인 Rich Sutton에 의해 널리 읽혀진 **"The Bitter Lesson"** 에서 결정되었다.
이 에세이는 인간의 지식을 이용하지 말라고 분명히 충고했다.

> *70년간의 AI 연구에서 읽을 수 있는 가장 큰 교훈은 계산을 활용하는 일반적인 방법이 궁극적으로 가장 효과적이라는 것이다. 연구자들은 그 영역에 대한 인간의 지식을 활용하려고 한다. 그러나 장기적으로 중요한 것은 계산의 활용이다. 인간의 지식 접근은 계산법을 활용하는 일반적인 방법을 이용하는데 덜 적합하게 만드는 방법으로 방법을 복잡하게 만드는 경향이 있다.*

기계 학습 시스템에 인간의 지식을 쌓는 것은 기계 학습계 내에서 부정행위로 간주되어 왔고, 확실히 그렇게 바람직하지 않다. DeepMind의 가장 영향력 있는 논문 중 하나인 “Mastering the game of Go without human knowledge”의 목표는 인간의 지식을 완전히 없애는 것이었다. *"도전적인 영역에서 초인적인 숙련도를 배우다"* 최소한의 사전 제약과 대규모 집합으로부터 상식을 유도한다면 기계 학습 커뮤니티의 많은 부분집합은 매우 만족스러울 것이다. 모델 제작 역시 힘든 일이었음이 입증되었고, 일반적으로 그 단계를 생략할 수 있다면 삶이 더 쉬울 것이라는 것이었다. 
> *물론 맹목적으로 인간들이 말하는 모든 것을 동화시키면서 나름의 문제가 해결될 것이다. ConceptNet의 수석 유지 관리자인 Robyn Speer가 말했듯이, 우리의 야망은 더 좋아져야 한다. "우리는 단지 사람들에게 나쁘다고 해서 컴퓨터가 사람들에게 끔찍하게 되는 것을 피하고 싶다. 기술적으로만 최고가 아닌 도덕적으로도 좋은 [지식 표현]을 제공하고자 한다."*

---

방대한 양의 데이터와 새로운 아키텍처에도 불구하고 생기는 Transformer과 같은 문제는 GPT-2의 기초가 되는 것으로서, 현대 신경망이 수집한 지식은 여전히 모호하고 점묘하다. 틀림없이 유용하고 확실히 인상적이지만 믿을수는 없다.

위의 예와 아래와 같은 GPT-2의 좀 더 명확한 테스트에는 이러한 명확성과 신뢰성이 내포되어 있다.
 - 만약 당신이 유리병을 깨뜨린다면, 물은 아마도 구를 것이다.
 - 만약 당신이 유리병을 깨뜨린다면, 물은 아마 더 깨지고 바닥에서 튈 것이다. 물은 병의 물의 양이 증가할 때 팽창하는 거품을 만든다.
 - 만약 장난감 병사가 든 유리병을 깨뜨린다면, 장난감 병사들은 아마도 그 안에서 당신을 따라갈 것이다.
 
결정적으로 인간의 지식 대신 "일반적인 방법"의 가치에 대한 Sutton의 예는 폐쇄적인 영역에서 온다(게임, 객체 분류, 음성 인식). 반면에 상식은 개방적이다. 바둑과 같은 게임에서 이기는 것은 뉴스를 해석하고 평가하거나 예상치 못한 계획 문제를 해결(지식이 없는 심층 강화 학습이 관리할 수 있는 범위를 훨씬 벗어난 것처럼 보이는 일종의 일회성 솔루션)하는 것과는 매우 다르다. 드라이 클리닝이 어디에 남아 있는지 알 수 있는 경우(앞의 예에서와 같이, *어제 나는 세탁소에 내 옷을 맡기고 아직 그것들을 가지러 가지 않았다. 내 옷 어딨어?*), 당신은 세계의 내부 모델과 시간 경과에 따라 모델을 업데이트하는 방법(몇몇 언어학자들이 말하는 *담화 업데이트 과정*)이 필요하다. GPT-2와 같은 시스템은 단순히 그것을 가지고 있지 않다.

개방형 도메인에 세계에 대한 대화 언어 이해 및 추론과 같은 컴퓨팅 파워가 적용되는 경우 일이 계획대로 되지 않는다. 결과는 항상 너무 점묘하고 모호해서 믿을 수 없다.

만약 우리가 딥러닝의 교훈을 얻는다면 우리의 시스템은 어떻게 보일까? 인간의 지식과 인지 모델은 다시 한번 인공지능을 찾는 일류의 시민이 될 수 있을까?

# 2. 지식 기반 인지 모델 기반의 하이브리드 접근 방식

많은 인지 과학자들은 인지를 일종의 순환으로 본다. 유기체(예: 인간)는 외부에서 지각 정보를 받아들인다. 그들은 그 정보에 대한 그들의 인식에 기초한 내부 인지 모델을 구축한다. 그리고 그들은 그러한 인지적 모델에 관한 결정을 내린다. 인지적 모델에 관한 결정은 외부 세계에 어떤 종류의 실체가 있는지에 대한 정보(그들의 속성, 실체들이 서로 어떻게 관련되어 있는지)를 포함할 수 있다. 인지 과학자들은 일반적으로 그러한 인지 모델이 불완전하거나 부정확할 수 있다는 것을 인식하지만, 유기체가 어떻게 세상을 보는지에 있어서 중심적인 것으로 본다. 심지어 불완전한 형태에서도, 인지 모델은 세계에 대한 강력한 지침 역할을 할 수 있다. 매우 큰 범위의 세계에서 유기체가 번성하는 정도는 그 내부 인지 모델이 얼마나 좋은가에 대한 함수이다.

비디오 게임은 기본적으로 유사한 논리에 따라 실행된다. 그 시스템은 세계의 어떤 내부 모델을 가지고 있다. 그리고 그 모델은 사용자 입력에 기초하여 주기적으로 업데이트된다. 게임의 내부 모델은 캐릭터의 위치, 캐릭터의 건강, 소지품 등을 추적할 수 있다. 게임에서 발생하는 현상(사용자가 특정 방향으로 이동한 후 충돌이 발생하는 경우 또는 없는 경우)은 해당 모델에 대한 동적 업데이트의 기능이다.

언어학자들은 보통 비슷한 주기에 따라 언어를 이해한다 : 문장의 단어들은 다양한 실체가 참여하는 이벤트와 같은 것들을 지정하는 의미론에 연결되는 구문으로 구문 분석된다. 의미론은 세계의 모델을 동적으로 업데이트하는데 사용된다(예: 다양한 실체의 현재 상태와 위치). 많은 (전부는 아니지만) 로봇 작업은 유사한 방식(인지, 모델 업데이트, 의사 결정)으로 작동한다. 

현재 논문의 가장 강력하고 가장 핵심적인 주장은 우리가 이와 유사한 것을 하지 않으면 우리는 강력한 지능을 추구하는데 성공하지 못할 것이다. 만약 우리의 AI 시스템이 세계와 세계의 역학에 대한 실질적인 지식을 바탕으로 외부 세계의 상세하고 구조화된 내부 모델을 표현하고 추론하지 않는다면, 그들은 영원히 GPT-2를 닮을 것이다 : 방대한 상관 관계형 데이터베이스를 활용하는 몇 가지 작업을 올바르게 수행할 수 있을 것입니다. 하지만 무슨 일이 일어나고 있는지 이해하지 못할 것입니다. 따라서 우리는 이러한 데이터베이스를 신뢰할 수 없습니다(특히 실제 상황이 훈련 데이터에서 벗어날 때). 
> *GPT-2의 입력이 단순한 텍스트가 아닌 지각적 입력을 포함하도록 확대된다면 GPT-2가 더 잘 수행될 것인가? 그럴 수도 있지만, 단순히 입력 범위를 넓히는 것만으로는 시스템의 기본적인 연결 내부 모델 부족을 해결할 수 없다고 생각한다. 한편, 앞이 안보이는 작품들은 풍부한 내부 모델을 개발하고 언어와 그 모델들을 어떻게 연관시키는지에 대해 꽤 많이 배운다는 것은 흥미롭다.*

---

준비 운동으로, 간단한 임무를 더 큰 도전을 위한 대역으로 간주한다. 소량의 자료에 근거하여 광범위한 일반화를 획득해야 하는 기계 학습 시스템을 구축하고 있다고 가정한다. 그리고 입력과 출력을 모두 이진수로 표시하여 소수의 훈련쌍을 얻을 수 있다.
| Input | Output |
|-|-|
| 0010 | 0010 |
| 1000 | 1000 |
| 1010 | 1010 |
| 0100 | 0100 |

어떤 사람에게든 여기에 광범위하게 적용되는 매우 중요한 일반화("규칙"이라고 함)가 있다는 것은 f(x) = x + 0와 같이 더하는 수학적 법칙과 같다. 이 규칙은 새로운 사례에 쉽게 일반화될 수 있다 [f(111) | 1111; f(10101) | 10101 등].

놀랍게도 다층 퍼셉트론과 같은 일부 신경 네트워크 구조는 딥러닝의 전형적인 예로서 최근의 교과서에 의해 기술되었고, 이것과 관련된 문제를 가지고 있다. 여기 다층 퍼셉트론, 하단의 입력, 상단의 출력, 그 사이에 숨겨진 레이어의 예가 있습니다. 신경 네트워크에 노출된 사람이라면 누구나 쉽게 알 수 있다 : 항등 함수에 대해 학습된 다층 퍼셉트론

![항등 함수에 대해 학습된 다층 퍼셉트론](https://user-images.githubusercontent.com/76898072/104171865-abb2d580-5446-11eb-998a-99660441897d.png)

이러한 네트워크는 입력을 출력에 연결하는 방법을 쉽게 학습할 수 있다. 그리고 실제로 "범용 함수 근사치"의 다양한 법칙이 이것을 보증한다. 충분한 훈련 데이터와 훈련 데이터를 통한 충분한 반복을 감안할 때 네트워크는 훈련 데이터를 쉽게 마스터할 수 있다. 

모든 것이 잘 진행되는 경우(예: 아키텍처가 제대로 설정되고 학습이 고착되는 로컬 최소값이 없는 경우), "교육 분포 내"인 예에 대해 그것은 또한 그것이 본 것들과 중요한 측면에서 유사한 다른 예들에 일반화할 수 있다.
| Test Input | 전형적인 Test Output |
|-|-|
| 1110 | 1110 |
| 1100 | 1100 |
| 0110 | 0110 |

그러나 훈련분포를 벗어나 일반화하는 것은 완전히 다른 것으로 판명되었다.
| Test Input | 전형적인 사람 반응 | 전형적인 Test Output |
|-|-|-|
| 0011 | 0011 | 0010 |
| 1001 | 1001 | 1000 |
| 1101 | 1101 | 1110 |
| 1111 | 1111 | 1110 |

이러한 예는 다층 퍼셉트론 신경망이 훈련 분포 내에 있는 사례에서 우수한 성능에도 불구하고 결국 아이덴티티 관계를 학습하지 않았음을 보여준다. 동일한 시스템이 짝수 기간 동안만 f(x) = x에 대해 교육되는 경우 수는 사람의 학습 분배권 밖에 있는 ID 기능을 홀수까지 확장하지 않습니다. 가장 오른쪽 노드를 포함한 각 출력 노드가 몇 가지 예에서 명백합니다. 맨 오른쪽을 포함해서 "1"bit를 나타낸다. 이것은 유사한 방법으로 나타내야 한다 : 우리는 가장 왼쪽의 비트를 가장 오른쪽의 숫자로 적용한다는 추상화를 취한다. 역 전파에 의해 훈련된 다층 퍼셉트론은 다른 무언가에 반응하고, 맨 오른쪽 노드는 항상 0이다. 그래서 네트워크는 가장 오른쪽 노드가 항상 0일 것이라고 계속 예측합니다. 예를 들어 입력값과 출력값에 상관없이 f(1111)=1110이다. 이 네트워크는 그 자체의 독특한 방식으로 일반화된다. 그러나 이것은 인간에게 자연스럽게 일어날 정체성 관계를 일반화시키지 않는다.

숨겨진 계층을 추가해도 네트워크 동작이 변경되지 않는다. 노드가 더 많은 숨겨진 계층 추가도 마찬가지다. 물론 특정 문제를 해결하기 위해 여러 솔루션을 함께 해킹할 수 있다(짝수에서 정체성만 학습, 이진 예제).그리고 나는 여기 간단한 정체성 예시를 오직 노출의 목적으로만 사용해왔다. 그러나 훈련 분포를 넘어 추론하는 문제는 널리 퍼져 있으며, 점점 더 많이 인식되고 있다. Joel Grus는 fizz-buzz 게임, Lake, Baroni를 통해 간단한 예시를 제공한다. 이것은 어떤 현대 자연어 시스템이 어떻게 유사한 문제에 취약한지 보여준다(추상적인 패턴을 다양한 방법으로 새로운 단어에 일반화하지 못하는 것). Bengio는 그의 최근 NeurIPS에서 중심적으로 현존하는 신경 네트워크의 능력에 제한을 두었다. 표준 신경 네트워크 아키텍처 내에서 광범위한 보편성의 불균일 확장(예: 정체성)은 놀라울 정도로 일반적이다. 그리고 내가 보기에 그것은 진보의 중심 장애물로 남아 있다.

---

본질적으로 특정 종류의 확장된 신경 네트워크(예: 여기서 논의된 역전파로 훈련된 다층 퍼셉트론)는 두 가지에 탁월하다 : 암기 훈련 사례, 초차원 공간의 일부 클러스터(교육 공간 내 일반화라고 함)에서 이러한 예들을 둘러싸는 점들의 클라우드 내 덧붙인다. 그러나 그들은 훈련 공간 밖에서 잘 일반화되지 않는다.

![다층 퍼셉트론](https://user-images.githubusercontent.com/76898072/104183170-e3287e80-5454-11eb-8810-70ea56aac85c.png) <br>
*다층 퍼셉트론 : 훈련 사례의 공간 내에서 일반화하는 데 능숙하며, 훈련 사례의 공간 밖에서 아이덴티티 기능을 일반화하는 데 서투르다.*

결과적으로 두 가지 밀접하게 관련된 문제가 발생한다.
1. **특이성**
교육 사례의 공간을 넘어서는 확실한 일반화 방법이 없는 시스템은 개방형 도메인에서 신뢰할 수 없다. 각 개별 시스템을 함수 근사치로 생각한다면 현재 널리 사용되는 시스템은 암기된 예제를 잘 하는 경향이 있으며, 교육 예와 유사한 예제를 많이(전부는 아니지만) 잘하는 편이다. 이는 분류를 중심으로 하는 많은 응용 프로그램에 유용하지만 훈련 분포를 벗어나면 열악하다. 예를 들어 최근의 수학 학습 시스템에서 1+1=2, 1+1+1=3 ~ 1+1+1+1+1+1=6은 잘 된다. 하지만 1+1+1+1+1+1+1+1=7 및 모든 더 큰 예에서 떨어졌다. (7 미만의 카운터 값에 대해서만 실행을 신뢰할 수 있는 컴퓨터 프로그램에서 FOR 루프를 작성하는 것을 상상해 보자) 이에 비해 유도 프로그램 합성을 기반으로 하는 상징적인 시스템인 Microsoft Excel의 Flash fill은 이러한 다양성의 많은 경우에 훨씬 더 효과적이다. 

2. **학습 제도의 정확한 세부 사항에 대한 과도한 의존성**
모든 정상적인 인간 학습자들이 매우 다양한 환경에도 불구하고 그들의 모국어와 세계에 대한 이해를 얻는 반면, 신경 네트워크들은 종종 훈련 항목이 제시되는 순서와 같은 정확한 세부사항에 꽤 민감하게 반응하는 경향이 있다(신경망을 위한 "기술"에 관한 문헌을 참조). 마찬가지로, 신경 네트워크는 30년 동안 이전의 연관성이 후대의 연관성에 의해 덮어쓰는 치명적인 간섭으로 알려진 문제에 취약하다는 것이 알려져 왔다. 항목을 표시하는 순서에 매우 민감하게 만드는 잠재적인 솔루션은 정기적으로 계속 제안되지만 문제는 남아 있다. 마찬가지로 최근 한 신문에 따르면 "네트워크가 보여주는 일반화의 정도는 주어진 작업이 예시화된 환경의 세부 사항에 따라 결정적으로 좌우될 수 있다."

---

훈련 분포를 넘어 추론할 수 없는 특이성과 무능은 우리의 상식적인 지식의 많은 일반성과 대립한다. 이것은 또한 인과관계를 헤아리기 어렵게 만든다. Pearl과 Mackenzie를 참조하라. 
도입부에서의 예를 확장하면 대부분의 일반 성인과 아이들은 다음과 같은 추상적이고 인과적인 일반화가 사실이라는 것(특정 경험에서 유도하는 것으로 추정)을 인식할 것이다 :
*액체가 들어 있는 병을 깨뜨린다면, 액체의 일부는 아마 그 병에서 빠져나올 것이다.*

그러한 진실은 단지 몇 개의 특정 품목뿐만 아니라 병의 색이나 모양 또는 크기, 음료의 종류에 관계없이 기본적으로 개방된 대형 실체 등급에 대해 보유한다는 점에서 추상적이다. 비록 깨진 병에 대한 우리의 이전의 경험이 거의 오로지 액체를 포함한 병에 관련되었다 하더라도 우리는 볼베어링이나 게임 주사위를 포함한 병에 대해서도 유사한 일반화를 유지할 것으로 예상한다.  

거의 모든 사람들이 다음과 같은 일반화를 신뢰할 수 없다고 생각할 것이다: 
*액체가 들어 있는 병을 깨뜨린다면, 액체의 일부는 아마도 300 미터 떨어진 곳에서 감겨질 것이다.*

개인의 경험과 상관없이 우리는 소형 및 대형 병 모두 해당 청구가 사실일 가능성이 낮다는 점을 인식하여 많은 방법으로 이전에 접한 병보다 훨씬 작거나 큰 병들에 대한 이 지식을 넓힐 수 있다. 

어떻게 우리가 이런 의미에서 특정 실체뿐만 아니라 모든 계급에 관계되는 추상적인 지식을 표현하고 조작하고 이끌어 낼 수 있는가? 대립법의 어려움은 역전달 훈련을 받은 다층 퍼셉트론과 같은 일반적인 도구가 작업에 적합한 도구가 아니라는 것을 의미한다. 대신에 추상적인 지식을 배우고, 표현하고, 확장하기 위한 대체 메커니즘을 찾는 것이 필수적이다.

## 2.1. 하이브리드 아키텍쳐

### 2.1.1 변수에 대한 기호 연산은 오직 알려진 솔루션을 제공하지만 부분적으로만 제공된다.

변수에 대한 상징적 연산이 하나의 잠재적 해답을 제시한다. 항상 사용되는 솔루션으로서, 사실상 전 세계 모든 소프트웨어의 기반이 되고 있습니다.
사실상 모든 컴퓨팅 프로그램 아래에 있는 네 가지 기본 아이디어 : 변수, 예시, 예시에 변수를 연결하는 바인딩 및 변수에 대한 연산이 포함된다.

이러한 각각의 아이디어는 x와 y와 같은 실체가 변수인 기본 대수학에서 친숙하다. 특정 숫자(2, 3.5 등)는 해당 변수가 구속될 수 있는 예시다(예: x는 현재 3과 동일할 수 있음). 운영에는 추가 및 곱셈과 같은 것들이 포함된다. 이것는 특정 클래스의 모든 값(예: 모든 숫자)으로 자동으로 확장되는 관계를 나타내는 것을 가능하게 합니다. 변수를 인스턴스에 연결하는 프로세스를 변수 바인딩이라고도 한다.

물론 컴퓨터 프로그램은 같은 기반 위에 만들어진다. 알고리즘은 주로 변수에 대해 수행되는 운영 측면에서 지정된다. 변수는 인스턴스에 바인딩되고, 알고리즘은 호출되고, 연산이 수행되고, 값은 반환된다.

중요한 것은 핵심 연산은 일반적으로 일부 클래스의 모든 인스턴스(예: 모든 정수, 모든 문자열 또는 모든 부동 소수점 번호)에 적용되는 방식으로 지정된다. 핵심 연산에는 일반적으로 산술 연산(덧셈, 곱셈 등), 비교 사항(x의 값이 y 값보다 크다), 제어 구조(현재 변수 n이 어떤 값에 속하게 되는가에 대해 여러 번 실행한다 : x의 값이 y의 값을 초과하는 경우 대안 a를 선택하고, 그렇지 않은 경우 대안 b 등을 선택한다)와 같은 기본 사항이 포함된다. 첫 번째 근사치(버그 무시, 프로그래머 논리 오류 등)에 대해, 이것은 적절하게 구현된 함수가 어떤 입력에 노출될 수 있거나 노출되지 않았을지 완전히 독립적으로 어떤 클래스의 모든 입력에 대해 작동한다는 것을 의미한다.

작동 측면에서 정의되는 기능적 측면으로 사물을 정의하는 이러한 접근 방식은 표준 기계 학습과는 완전히 다른 패러다임이라는 점에 유의할 필요가 있다. 기계 학습 시스템은 일반적으로 입력 변수와 출력 변수에 관련된 대략적인 함수를 학습한다. Judea Pearl은 곡선 맞춤에 비유한 프로세스를 통해 일반적으로 변수에 대한 운영 측면에서 훈련 데이터와 독립적으로 알고리즘을 *정의*한다. 이것은 전통적인 컴퓨터 프로그래머들에게 운영 체제에서 웹 브라우저, 비디오 게임, 스프레드시트에 이르는 모든 기능 지원 등 좋은 서비스를 제공해 왔다.

결정적으로 변수에 대한 시스템의 핵심 운영은 일반적으로 *경험과 무관*하게 체계적으로 작동하도록 구축된다. 예를 들어 마이크로프로세서의 *원형 비트 시프트 작동 메커니즘*은 마이크로프로세서 워드 폭까지 각 비트마다 하나씩 일련의 병렬 하위 연산에 의해 정의된다 : 연산은 이전에 사용된 적이 있는지 여부와 상관없이 동일하게 작동하며 학습이 필요하지 않는다. 프로그래머는 경험에 관계 없이 시프트 조작이 작동하리라는 것을 안전하게 예측할 수 있고, 앞으로도 그럴 것이다. 모든 기계의 장점(변수, 인스턴스, 바인딩, 운영)은 프로그래머가 특정 추상화 수준에서 특정 종류의 신뢰도를 부산물로 지정할 수 있도록 한다.

일괄적으로 변수에 대한 네 가지 가정(변수, 바인딩, 인스턴스, 운영)은 *기호-변환*의 핵심을 구성한다. (기호 그 자체는 단순히 다른 시스템에서 사용할 수 있는 인코딩 방식이다. 예를 들어 ASCII 코드에서 문자를 나타내기 위해 사용되는 이진수의 패턴 또는 신경 네트워크에서 출력 노드가 특정 단어를 나타낼 수 있도록 하는 인코딩과 같은 것이다.) 일부 기호 조작 시스템에는 추가, 연결, 비교와 같은 적은 수의 운영만 있을 수 있을 수 있다. 다른 것들은 마이크로프로세서가 핵심 명령 집합의 크기에 따라 달라질 수 있는 것처럼 더 풍부한 연산(예: 복잡한 논리 공식의 통일)을 가질 수 있다. 재귀는 기호를 조작하는 아키텍처를 기반으로 할 수 있지만 절대적인 논리 요구 사항은 아니다.

아이가 추상적인 언어 패턴을 배울 때처럼 어떤 형태로든 상징 조작은 인간의 인식에 필수적인 것처럼 보인다. 이것에 대한 가장 설득력 있는 증거들 중 일부는 나와 내 동료들이 7개월 된 유아들이 단순한 추상적인 패턴을 인식할 수 있다는 것을 보여준 1999년 연구에서 나왔다. 예를 들어 데이터의 ABB 패턴과 같이 일련의 훈련 예제를 넘어 음성학적으로 그들의 훈련 세트와 겹치지 않는 다른 음절로 구성된 새로운 문자열로 그것들이 추론된다. 후속 연구는 심지어 신생아들도 이런 종류의 추론을 할 수 있는 것처럼 보인다는 것을 보여준다. Gallistel과 King은 변수의 저장과 회수가 동물 인식에 필수적이라고 주장해왔다. 예를 들어 꿀벌은 태양 방위 기능을 아직 노출되지 않은 조명 조건까지 확장할 수 있는 것으로 보인다.

기호 조작의 다재다능한 기계 또한 구조화된 표현을 위한 기초를 제공한다. 예를 들어 컴퓨터 프로그래밍은 일반적으로 변수에 대한 연산을 통해 조합된 기호로 구성된 트리 구조를 사용하여 다양한 항목(예: 계층 구조 폴더 또는 디렉토리)을 나타낸다.

마찬가지로, 기호 조작 기계는 시간이 지남에 따라 변하는 개인의 속성을 추적할 수 있다(예: 데이터베이스 기록의 형태). 이러한 능력은 인간의 언어(재귀적인 문장 구조에서처럼)와 시간이 지남에 따라 변화하는 개인과 사물에 대한 우리의 지식에서 중점적으로 보인다. 

그러한 기계는 압도적으로 강력하다. 세계의 모든 웹 브라우저, 세계의 모든 운영 체제, 세계의 모든 앱 등이 그 위에 구축되어 있다. (동일한 도구가 세계의 거의 모든 신경 네트워크의 규격과 실행에 사용되기도 한다.)

그러나 역사적으로 주류인 딥러닝은 신경망이 왜 고전적인 패러다임에 대한 대안을 제공하는지에 대한 규명의 일환으로 상징-조작 기계 없이 대부분 의도적으로 회피하려고 했다. 현대의 많은 딥러닝을 예측했던 유명한 PDP 책에서 Rumelhart와 McClelland는 기호 조작을 "인간 연산의 본질은 아니다"라는 한계적 현상으로 치부했다. 2015년 Hinton은 인공 지능의 구성 요소로서의 상징적 논리의 추구는 "광채 에테르"에 상징을 비유했다.

> *광파가 발광 에테르에 장애를 일으켜야만 우주를 통과할 수 있다는 믿음만큼 부정확하다. 필요한 속성을 가진 유일한 시스템과의 강제적이지만 부정확한 유사성으로 인해 현혹되었다.*

개인들을 위한 데이터베이스식 기록과 같은 아이디어들은 신경 네트워크에서의 작업의 엄청난 우세함에서 제외되어있다. 그리고 계층 구조화된 문장과 같은 복잡한 구조화된 표현은 연구의 극히 일부에서만 발견된다. 반면 입력과 출력의 표준은 단순 벡터 또는 2차원 비트맵이다. 그리고 연구 대상자를 위한 계층적 데이터 구조 및 기록은 피했다. 
> *DeepMind의 새로운 MEMO 아키텍처는 레코드 데이터베이스를 대표한다*

이런 식일 필요 없다. Fodor와 Plyshyn이 도입한 용어 "실현적 연결주의"를 사용하여 호환 가능한 신경망을 구축 할 수도 있다. 그리고 기호-조작 원칙("제거적 연결주의")에 구애받지 않고 작동하는 Marcus 또는 신경망에 의해 채택되었다. 지금까지의 대부분의 작업은 제거주의적인 다양성이었다. 그러나 그 우세는 논리의 필요성이 아닌 사회학적 사실을 반영한다.

나는 몇년 안에 많은 사람들은 딥러닝이 기호 조작 없이 오랫동안 해온 많은 일들을 궁금해 할 것이라고 예상한다. 사실상 인류의 모든 위대한 공학적 업적은 어떤 상징적 추론에 의존해 왔다. 그리고 인간이 일상에 그것들을 사용한다는 증거는 많다. 새로운 것의 힌트와 함께 광범위한 실용주의가 변화하기 시작했다. 
> *독단주의를 극복하기를 바라는 광범위한 실용주의*

이 에세이의 첫 번째 주요 문장은 다음과 같다 : **AI에 대한 강력한 지식 기반 접근 방식을 구축하려면 툴킷에 기호 조작 장치가 있어야 한다.** 추상화를 표현하고 조작하는 도구 없이 만들기에는 너무 많은 유용한 지식이 추상적이다. 그리고 현재까지 우리가 알고 있는 그런 추상적인 지식을 믿을 수 있게 조작할 수 있는 유일한 기계는 상징 조작 장치이다.

변수들에 대한 운영 장치는 스스로 학습에 대해 아무 것도 말하지 않는다. 
> *유도 논리 프로그래밍은 현재 논문의 범위를 벗어나지만 어느 정도 고려할 가치가 있는 학습에 대한 완전한 규칙 기반 접근법이다.*

여기서부터 심볼 조작과 딥러닝과 같은 다른 기술을 결합한 하이브리드 아키텍처의 기본적 필요성이 가장 근본적으로 대두된다. 특히 대용량 데이터셋에서 기호 조작이 추상화를 표현하고 조작하는 표준을 설정하며 딥러닝의 학습 기준을 높였다.  우리가 그 두 개(또는 그와 비슷한 것)을 하나로 모을 필요가 있는 것은 분명하다. 
> *강력한 지능은 상징적 운영을 기계 학습 메커니즘과 결합하는 일종의 하이브리드에 의존할 것이다. 딥러닝이 데이터 및 에너지 사용 측면에서 지배적인 기계 학습 메커니즘의  마지막 열할을 수행하거나 후계자의 역할을 수행할 것인지의 여부는 확실하지 않다. 통계적 관계 학습 및 확률적 프로그래밍과 같은 접근법은 연구할 가치가 있다.*

### 2.1.2 하이브리드는 종종 효과적이다

하이브리드는 새로운 것이 아니다. Pinker와 나는 30년 전에 어떻게 아이들이 영어 과거시제를 배웠는지에 대한 가장 좋은 설명은 하이브리드와 관련이 있다고 제안했다. 이 하이브리드는 정규 동사의 과거 시제를 형성하기 위한 규칙과 불규칙 동사를 획득하고 검색하기 위한 신경 네트워크 같은 시스템이다. 그리고 상징적 지식과 지각적 지식을 결합하는 것은 오랫동안 명백하게 요구되어 왔다. (예를 들어, 말이 어떻게 생겼는지에 대한 지각적 지식과 얼룩말을 줄무늬가 있는 말과 비유하는 언어적 정의를 결합하여 얼룩말을 인식는 것이 있다.)
> *기존의 제로샷 학습 문헌은 다양한 형태의 다중 모델 지식을 통합하려고 노력해왔다. 하지만 현재 시스템은 사전 정의에서 찾을 수 있는 정확한 정보를 활용할 수 없다.*

Ron Sun과 같은 컴퓨터 과학자들은 1990년대 내내 하이브리드 모델을 지지했다. Shavlik은 (제한적인)논리의 부분집합을 신경망으로 변환하는 것이 가능하다는 것을 보여주었다. D’Avila Garcez, Lamb, Gabbay는 신경증 치료 접근법에 대한 중요한 초기 연구를 진행했다. 심지어 Hinton도 한때 하이브리드를 지지했다. 하지만 초기 하이브리드 접근 방식은 큰 관심을 끌지 못했다. 그 당시의 결과는 설득력이 없었다(아마도 일부 이유는 TPU 이전의 신경 네트워크 자체가 그 당시 저전력이었기 때문일 것이다.). 그리고 신경 네트워크 커뮤니티는 종종 하이브리드와 기호조작과 관련된 모든 것을 무시한다. 최근까지 하이브리드는 역사적으로 상징적인 접근과 신경적인 접근 사이의 교차에 휘말려왔다.

상징 조각 세계와 딥러닝 분야 사이의 오랜 갈등의 해소가 다가오고 있다. 예를 들어 Yoshua Bengio는 일부 초기 컴퓨터 언어에서 사용된 표준 기호 조정 기술의 변수들을 이름으로 전달할 수 있는 기술들을 통합하는 것에 대해 이야기했다. 그리고 실제적인 필요와 새로운 접근법의 개발을 위해 노력하며 기호와 신경망을 더욱 가깝게 만들기 위해 적극적이게 되었다. 

구글 검색과 같은 세계의 AI 시스템의 일부는 기호 조정 작업과 딥러닝을 혼합한 하이브리드이다. 구글 검색은 강력한 인공지능은 아니고, 높은 정확도로 엄청난 양의 작업을 수행하는 효과적인 AI 기반 정보 검색 시스템이다. 구글 검색의 설계자들은 이것을 고도의 데이터 중심적인 방법으로 광범위하게 최적화했고 현재 신경 네트워크 커뮤니티의 도구(BERT, RankBrain)와 전통적인 기호 조작 AI의 기술(구글 지식 그래프)을 혼합하여 최고의 결과를 얻고 있다. 구글은 무엇이 광범위한 규모로 잘 작동하는지를 보기 위해 거대한 경험적 실험을 한다. 그리고 그들이 여전히 구글 지식 그래프를 사용한다는 사실은 학문이 중요한 시대에도 기호와 하이브리디의 가치에 대해 말해주는 것이다. (다양한 구성 요소의 상대적 강점과 약점에 대한 자세한 논의는 알지 못한다.)

AlphaGo는 Monte Carlo 트리 검색(동적으로 구성되고 상징적으로 표현된 검색 트리에서의 횡단 및 평가)와 다양한 위치의 가치를 추정하기 위한 다양한 딥러닝 모듈을 결합한 것이다. 딥러닝 하나는 프로세스의 약한 기능이다. 

OpenAi의 Rubik은 루빅 큐브의 인지적 측면을 해결하기 위한 상징적 알고리즘의 혼합체이다. 그리고 수동 조작 측면에 대한 심층 강화 학습이다. 

Mao, Gan, Kohli, Tenenbaum은 그들이 조사한 딥러닝 대안을 능가하는 작은 규모의 NS-CL(Neuro-Symbolic 개념 학습자의 줄임말)이라고 하는 시각적 질문 답변을 위한 하이브리드 신경망 기호 시스템을 최근 제안했다. 이는 비교 가능한 순수 블랙박스 딥러닝 접근방식을 훨씬 능가하는 예측과 물리학 기반 계획을 수립하기 위해 개별 객체에 대한 명시적 기록을 쌍으로 묶는다. Evans와 Grefenstette는 다층적 퍼셉트론에 반항하는 하이브리드 모델이 다양한 학습 과제를 더 잘 포착할 수 있는 방법을 보여주었다. Smolensky와 Schmidhuber의 팀은 BERT와 텐서 제품을 결합함으로써 수학 문제집합에서 더 나은 새로운 시스템(TP-Transformer, 기호 변수와 그 구속력을 나타내는 공식 시스템)을 만들어냈다.

신경 상징 모델에 대한 기초적인 작업은 상징 시스템과 신경 네트워크 사이의 연결을 조사한 것이다. 이것은 전통적인 신경 네트워크에서 나타낼 수 있는 지식의 종류에 중요한 한계를 보여주었다. 그리고 표현 및 추론 능력 측면에서 혼합 시스템(핵심 및 신경 네트워크) 구축의 가치를 입증했다. 첫 번째 근사치로는 기존의 신경망이 제안 논리를 위한 엔진으로 생각될 수 있다. 미적분학에서 알 수 있듯이 정량화된 진술을 표현할 수 있는 좋은 방법은 없다. 따라서 논리 텐서 네트워크는 심층 텐서 신경 네트워크에서 형식 논리를 구현하는 것을 목표로 한다.

> Vergari <br>
  통계적 관계 학습은 논리적 추상화 및 관계를 확률과 통계와 결합하는 것을 목표로 하는 또 다른 접근 방식 연구 <br>
  Domingo <br>
  Markov 논리 네트워크로 기호 조작과 기계 학습의 장점을 결합 연구 <br>
  Arabshaghi <br>
  스택 역할을 하는 외부 메모리에 의해 트리 LSTM이 증강되는 방법 연구 <br>
  Fawzi <br>
  최근 다항식 부등식의 증거를 찾기 위한 하이브리드 시스템을 제시 <br>
  Minervini <br>
  최근 대규모 데이터베이스에서 작동하는 GNTP(Gready Neural Organization Provider)라고 하는 하이브리드 신경 상징 추론 시스템을 제시 <br>
  Battaglia <br>
  상징적인 그래프와 딥러닝을 통합하는 시스템과 함께 물리적인 추론 연구 <br>
  Allen의 AI연구소 ARISTO <br>
  8단계 과학 검사에서 가른 시스템보다 우수한 다중 파트 하이브리드 복합시설

이 모든 것들은 빠르게 성장하는 분야의 몇가지 예시일 뿐이다. 가장 좋은 이론을 내놓기에는 너무 이르다.  질 나쁜 대규모 데이터 셋에서 추상적인 지식을 추출하고 일반화하여 더 나은 기술 개발을 위하여 상징적 접근법의 강점과 기계 학습의 통찰력을 결합하는 아키택처를 구축하기 위한 많은 단계가 있다. 

### 2.1.3 하이브리드 모델 및 기호 조작에 대한 일반적인 반대

하이브리드 모델 조사에 대한 관심과 다양한 고려 사항에도 불구하고 기계 학습 커뮤니티의 일부에서 기호 표시에 대한 반대가 존재한다.
> *하이브리드 모델에 대한 유럽의 투자는 "큰 실수"가 될 것이다. 하이브리드 모델의 연구는 전기 자동차 시대에 구식 가솔린 엔진의 사용과 같다.*
  \- Geoffrey Hinton -
  
그러나 Hinton은 왜 그가 부분적으고 상징적인 하이브리드 모델을 반대하는지에 대해 최근 몇 년간 장황한 글을 쓰지 않았다.

다음은 다른 사람들로부터 들은 일반적인 몇 가지 반대 의견과 각 의견에 대한 간략한 답변이다. 

- **기호는 생물학적으로 타당하지 않다.**
> 1. 우리가 아직 상징 조절을 지원하는 신경 메커니즘을 결정적으로 식별하지 않았다고 해서 우리가 결코 그렇지 않을 것이라는 것을 의미하지는 않는다. 일부 유명한 신경 기질은 이미 확인되었다. 그리고 다른 문헌들은 이론적으로 그럴듯한 신경 기판을 가리켰다. 어떤 설득력 있는 근거도 그러한 메커니즘이 단순히 뇌와 비슷한 존재가 될 수 없다는 것을 보여준다. 예를 들어 단일 뉴런 네에서 활동할 수 있는 기호 조작의 중심인 변수의 값 저장 및 검색이 있다. 
  
> 2. 2.1.1에서 확인한 많은 심리학적 증거는 기호 조작이 뇌에서 인스턴트화 된다는 개념을 뒷받침한다. 새로운 아이템으로 새로운 추상적인 패턴을 확장시키는 유아들의 능력과 같은 것과 그들이 적접 정보를 가지고 있지 않은 비원음들로 추상적인 언어 패턴을 일반화하는 성인들의 능력 등이 있다. 인간은 상징적으로 표현된 표현된 컴퓨터 프로그램을 프로그래밍히고 디버깅 하면서 외부로 표현된 상징물에 형식논리를 적용하는 것을 배울 수 있다. 이 모든 것은 적어도 어떤 구성에서 (부분적인 메모리 제한에 의해) 실제로 신경 두뇌가 기호를 조작할 수 있다는 것을 보여준다. 그리고 우리는 언어를 본질적으로 무한한 다양성으로 이해할 수 있고, 끝없는 문장의 범위에서 무한한 범위의 의미를 추론할 수 있다. 변수에 대한 연산의 특징인 자유 일반화의 종류는 인식 전체에 걸쳐 널리 퍼져 있다.
  
> 3. 신경실현의 현존하는 증거의 부족은 우리에게 거의 아무것도 말해주지 않는다. 우리는 현재 Kasparov 수준의 체스가 어떻게 뇌에서 구현될 수 있는지에 대한 자세한 이해가 없다. 그러나 그것이 Kasparov의 체스놀이가 신경이 아닌 메커니즘에 의존했다는 것을 의미하지는 않는다.
  
> 4. 비록 뇌가 기호를 조작하는 기계를 사용하지 않는 것으로 밝혀졌다고 해도, 왜 AI가 그러한 메커니즘을 이용하지 못하는지에 대한 원칙적인 주장은 없다. 인간에게는 부동 소수점 사술 칩이 탑재되어 있지 않지만 이것은 인간이 AI에 길들여져야 한다는 것을 의미하지 않는다. 
   
- **과거에는 상징적인 시스템과 하이브리드 시스템이 제대로 작동하지 않았다.**
> 나는 종종 이것들을 들은 적 있지만, 이것은 이상한 주장인것 같다. 하이브리드 모델을 입증할 수 없거나 구식으로 묘사하는 것은 정확한 것이 아니다. 실제로 하이브리드 모델에 대한 적극적이고 효과적인 연구가 진행 될 때는 2.1.2 절에 기술되었다. 

> *과거에 대한 유도는 잘못된 추론을 쉽게 초래할 수 있다는 점에도 주목할 필요가 있다. 딥러닝은 2000년대 초기에는 경쟁력이 없는 결과 때문에 멀리되었지만 그 이후 기초적인 알고리즘 변화보다 새로운 하드웨어와 큰 데이터 셋에 의해 주목받게 되었다.* 

- **기호 조작 시스템과 하이브리드 시스템의 크기를 조정할 수 없다.**
> 복잡한 문제에 대해 실시간으로 작동할 수 있을 만큼 상징적인 검색을 제한하기 위해 많은 노력을 기울여야한다. 이것의 반대되는 예로는 소프트웨어 및 하드웨어 검증에서 대규모 성공을 거둔 Google Knowledge Graph가 있다. Minervini와 Yang은 규모에 맞게 작동하는 차별화 가능한 end-to-end 하이브리드 신경 상징 시스템을 구축하기 위해 실질적인 진전을 이루었다. 하지만 적절한 발견이 주어졌을 때, 적절한 확장의 불가능성에 대한 공식적인 증거는 존재하지 않는다. 

지난 30년간 나는 상징에 대한 많은 편견을 보았지만 그에 대한 설득력 있는 논쟁을 아직 보지 못했다.

### 2.1.4 지정된 시스템이 하이브리드 시스템인지 여부를 확인하는 것이 항상 사소한 것은 아니다.

상징에 대한 공통적인 편견은 독특한 사회학적 사실을 만들었다. 연구원들은 자신들이 독특한 사회학적 사실을 만들었다고 인정하지 않고 기호 표시 장치를 포함하는 시스템을 구축한다. 예를 들어 앞서 언급한 Open AI Rubik의 cube solver은 Kociemba의 알고리즘으로 알려진 상징적인 요소를 포함한다. 그러나 이것을 인식하는 사람들은 적을 것이다. 혼합된 단어와 상징적인 단어는 전혀 언급되지 않고, 유추되어야만 한다. 하지만 신경이라는 단어는 13번 나타난다. 

그 이유는 주어진 시스템이 간단한 검사만으로 어떻게 작동하는지 항상 설명할 수는 없기 때문이다. 그래서 무의식적으로 기호 표시 기능을 효과적으로 구현하는 기계를 만드는 것은 논리적으로 가능하다. 실제로 네트워크 설계자는 자신도 모르는 사이에 상징적인 FPGA와 같은 형태의 어떤 것으로 인해 문제가 생길 수 있다. 

딥러닝 시스템이 기호 조작에 대한 진정한 대안을 제공할 수 있다는 것은 확실히 상상할 수 있는 사실이다. 
> *내가 장담하건데 딥러닝의 변형은 인간이 실제로 수행할 수 있는 상징적 계산의 형태를 이룰 수 있다. 그러나 인간이 경험하는 것과 유사한 제한사항(예: 소량의 재귀 수준)을 가진 경우 GFAI와는 매우 다른 기질을 사용할 것이다. 그리고 불확실성의 학습과 취급을 가능하게 하는 것 외에 GFAI 추론에서 검색 문제와 관련된 주요 효울성 문제를 회피한다.*
  \- Bengio -
  
우리는 주어진 신경망이 대안을 제공하는 것을 당연하게 여길 수 없다.

시스템이 "기호 유사 연산"의 대안을 수행하는지 또는 진정한 기호 조작 연산을 사용하여 계산을 수행하는지 여부를 평가하는 유일한 방법은 매핑을 탐색하는 것이다. 이를 위해 아키텍처를 고려하고 그 구성요소가 기호-변환의 구성요소에 매핑되는지 여부를 고려한다(화학이 물리학에 매핑되는 것과 같은 의미). Marr 수준의 계산은 이 경우를 확실하게 만든다(주어진 계산은 여러 방법으로 구현될 수 있지만, 모든 구현이 명백한 것은 아니다). 물리학에 대한 화학 지도도 매핑이 쉽게 검색되는 것은 아니다. "바른" 신경망이 기호 조작 기계 위에 매핑되거나 매핑되지 않을 수 있어서 있다.

어떤 강력한 시스템이든 가변 구속력을 위한 일종의 메커니즘을 가질 것이고, 한 번 사용된 변수에 대해 작업을 수행하는데 사용될 것이다. 하지만 우리가 보지 않으면 알 수 없다.

---

매핑이 신경 과학을 이해하고 그것이 계산과 어떤 관계가 있는지 이해하는데 필수적이라는 것을 상기해야한다. *우리의 노에서 어떤 계산이 실행되었든 매핑은 아무런 의식적인 의사 결정 없이 진화하였다.* 그리고 몇가지는 명백하다. 이것은 신경과학자들과 인공지능 연구원들은 어떤 계산이 있는지 알아내기 위해 두뇌를 역언제니어링 하기위해 뇌에서 영감을 받은 접근법 바탕 인공지능에 전념하고 있다. 두뇌를 움직이는 것이 무엇이든간에 우리의 현재 이론에 나타날 수도 있고 나타나지 않을 수도 있다. 우리가 뇌의 작동법에 대한 이론을 평가할 때, 우리는 뇌의 기계가 그 이론에 매핑되는지 아닌지를 평가하고 있다. 어떤 이론들은 뇌에서 일어나는 실제 과젱과 동일한 구조를 포함하고 있다. Knudsen과 Konishi가 현지화 된 헛간 부엉이의 소리를 조심스럽게 작업한 것은 하나의 신경회로가 결국 해독되고 기초적인 연산들에 매핑되는 방법의 대표적인 예다. 

유사한 질문이 AI에서 발생한다 : 시스템이 작동할 때, 무엇이 시스템의 성능을 향상시키는지 이해하는 것은 가치가 있지만 종종 중요하지 않다. 

검색 및 계산할 수 있는 모든 경험을 별도의 메모리에 저장하는 시스템은 "신경" 용어로 설명될 수 있지만 구성 요소는 없다. 

하나의 시스템은 모든 경험을 다시 찾을 수 있는 기억 속에 저장하고, 계산한 내용은 아직 성분(변수, 바인딩, 인스턴트, 운영(예: 검색)을 변수에 대해 유지 관리하는 역할 인식할 수 있다)을 가지고 있는 "신경"용어로 설명될 수 있다. 

닥치는대로 검색 프로세스를 통해 적절한 가상 시스템을 생성하는 경우 시행착오, 진화, AutoML, 기타 방법을 통해 엔지니어링 문제의 일부를 해결할 수 있다. *하지만 이러한 모델이 작동하는 이유를 과학적으로 이해할 필요는 없다.* 후자는 신경과학과 같이 역엔지니어링과 가능한 매핑의 발견과 거부를 위한 작업이다.

만약 완벽한 신경망이 우리에게 주어진다면 광범위한 테스트를 통해 이것의 작동 방식을 발견할 수 있을 것이다. 이것이 어떻게 작동하는지 이해하려면 과학적인 발견의 또 다른 단계가 필요할 것이다. 만약 우리가 성공하는 몇몇 신경망을 발견한다면 *그것의 구성 요소들이 완벽하게 기호 조작에 매핑되어야 한다는 것이 밝혀질 것이다. 이것은 시스템 설계자가 의도한 것과 무관하게 신경 네트워크 뿐만 아니라 상징 조각에도 좋은 일이 될 것이다.* 이와 일치하게 해당 시스템의 구성 요소가 기호 표시에 나타나지 않을 경우 상징적인 의미에 대한 실패가 될 것이다. 합리적인 사람이라면 인간의 뇌가 어떻게 작동하는지 이해하는 것이 지금까지 얼마나 어려웠는지 알 것이다. 그리고 신경 네트워크가 더 복잡해짐에 따라 신경 네트워크에도 현실과 같은 일이 나타날 것이다. 인간의 뇌 자체는(진화를 통해) 효과적으로 우리에게 생긴 인상적인 신경망의 한 예다. 하지만 우리는 그 이유를 모른다. 

> *만약 구현 세부 정보와 알고리즘 설명 간의 매핑 존재한다면 이는 실질적인 가치가 있을 수 있다. 예를 들어 이러한 매핑이 발견된다면 일부 낮은 수준의 신경 네트워크 연산은 순수한 상징적 수준에서 더 효율적으로 계산될 수 있다. 반대로 Lample과 Charton의 상징적 통합에 관한 최근 연구처럼 신경 네트워크로 취급되는 일부 모델은 심각한 한계를 가지고 있고, 상징적인 프로세서에 크게 의존한다. 상징적 요소와 신경적 요소가 어떻게 함께 작용하는지에 대한 명확하고 원칙적인 이해는 꽤 가치있을 것이다.*

### 2.1.5 요약

특정한 변수에 대한 운영 체계의 기호 조작은 훈련 체제를 넘어서 추정하는 도전에 대해 자연스럽지만 불완전한 해결책을 제공한다 : 변수에 대한 연산 측면에서의 알고리즘을 나타낸다. 그리고 이것은 본질적으로 어떤 클래스의 모든 인스턴스로 확장되도록 정의될 것이다. 그리고 구조화된 표현(예: 생성 언어학에서 기초가 되는 나무 구조)과 개인 및 그 속성에 대한 기록을 나타내기 위한 명확한 근거를 제공한다. 신경 세포 조직의 한 구획을 XOR을 계산할 수 있다. 이것은 개별 뉴런이 종종 추정되는 것보다 휠씬 더 정교할 수 있는 가능성을 높여준다. 

무언가 부족한 것은 학습을 위한 만족스러운 틀이다. 하이브리드는 양쪽 세계의 최고를 결합하는 방법이 될 수 있다 : 딥러닝의 본보기가 되듯이 대규모 데이터 세트에서 학습할 수 있는 능력은 세계 모든 컴퓨터 프로그래밍 언어의 의미적으로 통용되는 추상적 표현을 표현할 수 있는 능력을 갖추고 있다. 나는 그것들이 강력한 지능에 안전하게 도달하기 위한 전제 조건이라고 추측한다. 인간은 분명히 어떤 형태의 가변 구속 조건이 전제조건이 된다면 단기기억을 즉시 회수해서 한번에 쓰는 메커니즘을 가지고 있다. 하지만 우리는 관련 메커니즘이 무엇인지 모른다. 이것은 우리가 AI에 그런 메커니즘을 사용해서는 안된다는 것을 의미하지는 않는다. 

하이브리드 모델의 우주를 연구하는 데 투입된 리소스는 기호 조작을 회피하는 "순수한" 딥러닝 시스템에 투입된 리소스보다 훨씬 적다. 그러나 2.1.2절에서 검토된 작업의 증가 중 다양한 구글 검색 연구소에서의 모두 하이브리드 아키텍처에 대한 연구 가치는 말할 것도 없다.

아직 우리는 어려움에서 벗어나지 못했다. 강력한 데이터 중심 학습 기법과 대표성을 결합한 하이브리드 모델과 기호 표시의 계산 자원은 강력한 지능을 위해 필요할지도 모른다. 그러나 확실하지는 않다. 다음에 이어지는 내용에서 세 가지 추가 연구 과제를 설명하겠다.

## 2.2. 대규모 지식 중 일부는 추상적이고 인과적이다.

기호 조작은 추상적 지식을 표현을 허용하지만 추상적인 지식을 축적하고 표현하는 고전적인 접근법은 허용하지 않는다. 지식 표현으로 알려진 분야는 힘든 분야이고 만족과는 거리가 멀다. AI의 역사에서 기계가 조작할 수 있는 형태로 상식적인 지식을 창조하려는 노력이 1984년에 Doug Lenat에 의해 CYC라는 이름으로 시작되었다. 이것은 심리학, 정치, 경제, 생물학 등에 대한 사실들을 포착하기 위해 수천년동안 많은 노력이 필요했다. 많은 다른 범위들은 모두 정확한 논리적 형식이다. 

지금까지 이에 대한 보상은 강하지 않았다. CYC에 대한 출판물은 거의 없고, 상업적인 용도는 평범해 보인다. 많은 사람들이 CYC를 조금이라도 안다면 이것을 실패로 간주하고 CYC를 광범위하게 사용하는 연구자는 거의 없었을 것이다. 비슷한 폭의 경쟁 시스템을 구축하려는 경향은 훨씬 더 적다. (Google Knowledge Graph, Freebase, YAGO와 같은 대규모 데이터베이스는 상식이 아닌 사실에 집중한다.)

CYC가 얼마나 많은 노력을 필요한지 알게되고, 이것이 현장 전체에 미치는 영향이 얼마나 적은지 알게 되는 경우 GPT-2와 같은 Transformer에 흥분하지 않는 것은 어려운 일이다. 이것들이 일을 잘 할 때는 마치 그들이 자동적이고 쉽게 세계의 상식적인 지식의 많은 부분을 흡수하는 것 같을 것이다. Transformer는 그들이 흡수하는 지식은 겉보기에는 정교해 보이는 인간의 언어에 대한 이해와 완벽하게 통합시키는 모습을 보여준다.

이들의 대조는 현저하다. 반면에 지식 대표 커뮤니티는 수십 년 동안 그릇과 그 내용물의 관계와 같은 것을 정확하게 기술하면서 고군분투해왔다. 그리고 자연어 이해 커뮤니티는 GPT2와 같은 변압기가 Gordian 매듭을 자른 것처럼 보이는 의미 구분 분석으로 수십 년 동안 고군분투해왔다. 

예를 들어 GPT-2 내의 지식 기반 규칙에는 용기와 관련된 액체 설명과 물이 액체라는 어떤 명제도 없다. 앞서 본 예시에서
> *물이 가득 찬 **유리병을 깨뜨리면** 튀는 소리가 날 것이다.*

H_2O 개념에서 단어 "물"에 대한 매핑이 없고 깨지거나 흐른다는 동사의 의미에 대한 어떠한 명시적인 표현도 없다. 

다른 예시를 들어보면 GPT-2는 불에 대한 무엇인가를 암호화 하는 것으로 보인다.
> ***불을 붙이는 좋은 방법**은 라이터를 사용하는 것이다.*
  ***불을 붙이는 좋은 방법**은 성냥을 사용하는 것이다.*
  
Lanat의 인간의 지식을 기계가 해석 가능한 형태로 인코딩하려는 프로젝트와 비교해 보면 이것은 하룻밤만에 인건비 절감과 성공을 나타낸 것으로 보인다. 

---

문제는 GPT-2의 솔루션이 지식의 *근사치*에 불과하고, 지식 그 자체를 대신하지 않는다는 것이다. 특히 이것이 획득하는 것은 개념 자체를 명확하게 나타내기 보다는 어떻게 단어가 큰 집합에서 서로 공존하는지에 대한 통계 근사치다. 이것은 전자가 후자의 근사치로 사용되면서 생각의 모델이 아닌 단어 사용의 모델이다. 

그러한 근사치는 복잡한 3차원 세계에 대한 그림지 같은 것이다. 병과 깨짐의 개념과 관련된 단어들의 사용을 통해, 인간 상호작용의 부분집합을 암호화 하는 집합에 그림자를 드리운다. 동굴에 대한 플라톤의 우화에 나오는 죄수들처럼 Transformer는 단어가 남긴 그림자를 분석한다. 문제는 그 단어들이 그 집합에서 어떻게 사용되는지에 대한 동시 발생 통계 분석에 해당하는 그림자 분석이다. 병이 실제로 무엇인지 또는 병을 산산조각내는 것이 무엇인지에 대해 반드시 밝혀지는 것은 아니다. 

사실은 GPT-2가 분석하는 단어에 바탕을 둔 개념에 대해 무엇이 관련 있는지에 대한 실마리가 거의 없다. 예를 들어 Frank Keil의 고전적 실험에 통해 깊은 개념적 이해에 대한 지각적 특징과 반대되는 개념을 이해해보자.
> ***만약 너구리에게 스컹크처럼 보이게 의상을 입힌다면** 스컹크일 것이다.* 
  ***만약 당신이 비행기를 용처럼 보이게 그린다면** 그것은 용일 것이다.*
  
분명히 단어들이 개념에서 어떻게 사용되는지에 대한 통계적 특성들을 아는 것은 기본 개념들의 본질을 이해하는데 충분하지 않다. 이 최근의 익명 검토 원고도 이와 비슷한 논점을 가지고 있다. 

프랑스어를 모르고 스크래블 대회에서 우승한 Nigel Richards이 있다. 그에게 있어서 각각의 단어들은 뜻의 관계없이 단순한 게임용 토큰으로 사용되었다. 본질적으로 GPT-2는 참조되고 있는 기본 개념에 대한 단서 없이 게임 토큰으로서 단어의 순서 속성을 예측한다. 

이를 잘 해내어 경험 없는 인간이 실제 존재하는 것보다 더 많은 것을 기계에 돌리는 "엘리자 효과"를 유도하기도 한다. 하지만 피상적인 개념적 이해 이상의 것은 없다. 

불의 시작 예제를 계속 살펴보면 유사한 결과가 나온다. 
> ***불을 붙이는 좋은 방법은** 퓨즈를 덮기 위해 마른 숨뭉치를 사용하는 것이다.*
  ***불을 붙이는 좋은 방법은** 1파인드 화로를 사용하는 것이다.*
  
불, 퓨즈, 빛 등의 단어는 모두 상호 연관되어 있다. GPT-2는 이것을 이해하지만 불의 본질에 대한 개념적 이해를 유도하는 것까지는 충분하지 않다. Judea Pearl과 같이 표현하면 당신은 단어를 사용하는 통계 곡선을 근사화하는 것을 통해 세상이 어떻게 움직이는지를 유도하려고 할 때 세계에 대한 추상적이고 인과적인 이해를 유도하기 보다는 변칙적인 행동을 얻을 수 있다. 이것은 효과가 있을 수도 있고, 없을 수도 있다. 

> *딥러닝 커뮤니티의 일부 부분에서는 인과관계 방법을 통합하려는 적극적인 노력이 있다. 나는 이것이 하이브리드 네트워크로 이끄는 특정 유형처럼 어떻게 인과지식이 표현되고 조작되는 지에 대한 어느 정도 선천적인 제약없이는 성공할 수 없다고 생각한다.*

신뢰성 보장이 거의 없는 부품으로 강력한 시스템을 설계할 수는 없다.

---

신뢰성이 낮은 부품으로 시스템을 구축하려는 경우 다운스트림 추론이 불가피한 문제가 있다. 지식을 가지는 거의 전부는 그것을 행동과 해석, 의사결정에 사용하는 것이다. 불의 원인이 무엇인지, 또는 병이 깨졌을 때 무슨 일이 일어나는지 모른다면 주변에서 일어나고 있는 일에 대해 추론하기 어렵다. 마찬가지로 신뢰할 수 있는 계획을 세울 수 없다. 가정집 로봇을 생각해보면 마른 솜뭉치로 몇 시간을 보내도 난로를 켤 수 없다. 

언어 이해는 타당성과 문맥에 근거하여 말을 명확하게 하기 때문에 필연적으로 어려움을 격는다. GPT와 같은 시스템은 단어 사용 문맥을 어느 정도 측정하지만 인지적 맥락과 타당성에 대한 신뢰성 있는 표현은 부족하다. 

해석성과 설명 가능성은 이러한 얕은 개념적 이해로 이루어진 시스템에서는 이해하기 어려운 것으로 입증되었다. 똑같이 유효한 조명 방법으로 면화공과 라이터를 함께 반짝이는 시스템은 해석 가능성의 요구를 만족시키기 위한 내부 일관성을 갖지 못할 수 있다. 

그리고 기본 개념에 대한 인과적 이해의 일관성이 없으면 복잡한 실제 환경에서 견고하게 설계할 수 있는 방법이 없을 수도 있다.
> *시스템이 곡선 적합 및 통계적 근사치에만 의존하는 경우 이 추론은 얕게 진행 되는 것이다.*
  \- Pearl -
  
현재 논문의 두 번째 주요 주장은 **추상적인 지식의 구조화된 대형 데이터베이스를 유도, 표현, 조작하는 체계적인 방법이다.** *이는 종종 인과관계에서 강력한 지능의 전제 조건이다.*

### 2.2.1 강력한 인공지능은 어떤 종류의 지식을 필요로 하는가?

여기 몇 가지 기본적인 고려해야할 사항들이 있다.

- **대부분은 배우지만 중요한 것은 그 지식의 전부가 아니다.**
> 라이터, 마른 솜뭉치가 불을 피운다는 것, 유리병이 깨졌을 때 어떻게 해야 하는가를 알고 태어나는 사람은 없다. 이 지식을 수동으로 강하게 연결된 CYC에 따라 AI 시스템에 단단히 연결시킬지도 모른다. 하지만 현대 기계학습의 연구자들은 하지 않을 것을 선호한다. 그리고 새로운 추상적 학습 방법은 항상 새로운 지식을 얻을 수 있기 때문에 인과적 지식은 필수적이다. 

- **강력한 시스템이 활용할 수 있는 몇 가지 중요한 부분은 외주 지식(상징적으로 표현되는 문화적 지식)이다.**
> 위키피이다의 대부분은 말로 표현된다. 그리고 강력한 지능은 그러한 종류의 지식을 끌어낼 수 있어야 한다. (현재의 딥러닝 시스템은 매우 제한된 범위에서만 이 작업을 수행할 수 있다.) 그 지식의 대부분은 변수들 사이의 정량화된 관계의 관점에서 효과적으로 암호화된다.(예: x,y,z가 사람일 때, x는 z의 손자다. 만약 x의 부모와 z의 자식인 y가 있다면, 모든 x에 있어서 x는 하나의 종류이다.)

- **강력한 시스템에 필요한 몇 가지 중요한 지식 중 일부는 추상적일 수 있다.**
> 현재의 시스템은 BORN과 CAPITAL과 같은 특정 사실을 잘 표현한다. 하지만 다른 사정이 같다고 친다면, 병의 내용물이 빠져나갈 수 있다는 사실처럼 정보를 표현하고 효과적으로 조작하는 방법이 부족하다. 

- **규칙과 예외가 공존해야 한다.**
> 정규동사는 불규칙동사와 공존한다. 날 수 없는 펭귄은 날 수 있는 많은 다른 새들과 함께 존재한다. 기계는 우리가 언어학자들이 포괄적으로 부르는 것과 같은 방법으로 지식을 표현할 수 있어야 한다. 하지만 예외 *(비행기는 날지만 특정 비행기는 땅에 있다는 것은 알고 있다.)* 는 인정하고 통계적인 진실이 우위에 있을 필요도 없다 *(모기가 말라리아를 옮기는 것은 중요한 지식이지만, 실제로 말라리아를 옮기는 모기는 극히 일부에 불과하다)*. 규칙만 습득할 수 있고 예외는 습득 불가능한 시스템은 추상적인 지식을 습득할 수 있는 시스템을 구축하는 방법이지만 충분하지는 않다.

- **강력한 시스템에 대한 몇 가지 중요한 지식은 인과관계일 가능성이 높으며 대응요소를 지원한다.**
> 지적인 사람들은 국가에 수도가 있다는 사실을 알고있다. 그들은 그 수도들이 사람들의 행동에 의해 정치적으로 결정되고 그 결정이 바뀔 수 있다는 것을 알고있다. Albany는 현재 Nork주의 수도이다. 그러나 만약 그 수도가 불타버렸다면 우리는 국가가 새로운 수도를 선택할지도 모른다는 것을 알고있다. 아이들은 유리병이 단단한 바닥에 떨어질 때 병이 깨질 것을 안다. 

- **비록 진실된 지식을 위해 웹을 검색하는 것이 비교적 쉽지만 우리가 가지고 있는 많은 추상적인 지식들은 웹 검색을 통해 얻기가 더 어렵다.**
> 소수의 사람들은 깨진 병과 그 내용물에 대한 수필을 쓴다. Lenat가 지적한 것과 같이 대부분의 작가는 독자들이 이미 그것을 알고 있다고 생각하고 상식을 쓰지 않는다. (블라인드 웹 검색은 단순한 검색 시스템에 의해 자동적으로 영구화되는 경향이 있다.)

- **관련 지식은 범위가 매우 넓어야 한다.**
> 단편 소설을 이해하는 것은 기술, 정치적 실세, 인간의 상호작용 등에 대한 지식이 필요할 수 있다. 예를 들어 John Grisham의 The Firm에서 중요한 줄거리는 복사기가 무엇을 얼마나 빨리 할 수 있는지에 대한 이해에 의존했고, 인간의 동기 부여와 시간적 추론에 대한 깊은 이해에 반하는 것이었다.=

- **지식을 실천하는 것은 어렵다.**
> 지식을 포함하는 거대한 데이터베이스는 한가지다. 예를 들어 복사기와 복사기의 작동 속도에 관한 사실과 다른 것은 중요한 시간적 추론의 맥락에서 그 지식만을 통합한다. 추상적 지식을 특정 실제 상황에 효율적으로 연결하는 것은 본질적으로 해결되지 않은 문제다.

- **일부 중요한 인간 지식은 선천적인 것일 가능성이 높다. 따라서 깅략힌 AI도 몇 가지 중요한 사전 지식에서 시작해야 한다.**
> 현대의 ML에서는 지식과 불성실을 최소화하고자 하는 강한 욕구가 존재한다. 2.2.3절에서 논의된 바와 같이 나는 이것이 실수라고 생각한다.

### 2.2.2 사례연구: 컨테이너

단일 사례 연구를 좀 더 자세히 검토해 보자. (보통 사실 : 뚜껑이 달린 주전자 안의 물은 주둥이로만 빠져나올 수 있다.)

GPT-2는 어느정도 시간의 흐름으로 정렬된다.

> **뚜껑이 달린 주전자 안의 물**은 주전자의 위쪽 절반으로만 나올 수 있다. 이 열원으로 만들어진 뜨거운 물은 주전자 바닥의 반쪽에서도 흘러나올 수 있다. 뚜껑을 덮고 끓인 커피는 다 끓을 때까지 남겨두어야 한다. 뜨거운 물이 뚜껑 아래로 지나가도록 놔두면, 생산되는 증기가 충분히 식지 않고 커피가 제대로 가열되지 않아 균형이 맞지 않는다.

> **뚜껑이 달린 주전자 안의 물**은 주전자의 위와 3개의 구멍으로 나올 수 있다.

> **뚜껑이 달린 주전자 안의 물**은 윗부분에서 한 번만 나올 수 있고, 나머지는 아래쪽으로 나올 수 있다. 이는 순환과 같다.

원칙적으로 우리는 집합의 근원을 통해 특별한 사실을 얻을 수 있을 것이다. 하지만 사람들은 이러한 진실을 거의 말하지 않고, 적은 빈도로 이것에 기대해서는 안된다고 말한다. 그리고 우리가 우리의 데이터베이스에 이러한 사실을 지니게 해야 할지도 모른다. 만약 우리가 인공지능을 만들어 인간 노인 용양 로봇의 결정에 힘을 실어준다면 우리는 사전의 요구를 예측하지 못할 것이다. 

일반적인 지식에서 이와 같은 사실을 도출할 수 있다면 좋을 것이다. 예를 들어 생소한 모습을 한 주전자에서 우리가 그것이 무엇인지, 그것과 어떻게 상호작용하는지를 알게되는 것이 있다.

Ernest Davis, Noah Frazier-Logue는 이런 종류의 도전을 도울 수 있는 틀을 제안했다. 

> 많은 독자적 논리적인 이치는 컨테이너에 대한 올바른 추론이 이러우질 수 있다. <br>
  *유용한 모든것은 주전자에 특정되지 않고 대부분의 사람들이 사실이라고 인식하는 추상적인 것으로 구성되어 있다. *

전체 공리(시간, 공간, 조작, 역사, 행동 등)가 위치한 틀은 상당히 일반적이다. 공리에는 다음과 같은 진술이 포함되어있다.

- 물리적 세계는 시간과 우주를 따라 움직이는 물체의 집합으로 이루어져 있다.
- 개체는 구별되기 때문에 한 개체가 다른 개체의 일부이거나 다른 개체와 공간적으로 겹칠 수 없다.
- 물체는 3차원 범위를 차지하기 때문에 1차원 곡선이나 2차원 평면이 될 수 없다.
- 특정 양의 액체가 특정 부피의 모든 영역을 차지할 수 있다.
- 닫힌 컨테이너는 내부 구멍을 완전히 덮는 개체 또는 개체 집합이다.

이런 지식을 탑재한 탐사 로봇은 아마도 거의 숨겨진 주둥이가 있는 특이한 모양의 주전자의 사용과 기능에 대해 추론을 할 수 있을 것이다. 

조금 더 연장하면 이러한 시스템은 본 적 없는 제공자의 제공 이유에 대해 추론할 수 있는 시스템의 기초를 제공할 수 있다. 궁극적으로 이런 기초들이 행동의 과정에서 그 지식을 적용할 수 있는 로봇 시스템의 구성요소 역할을 할 수 있기를 희망한다. 그리고 전혀 다른 새 제공자에 대한 추론을 이끌어 낼 수도 있다. 

이러한 종류의 것은 현재의 신경 네트워크 접근법에서는 자연적으로 나타나지 않는다. 그렇게 하는 것은 아마도 어떤 문제의 선입견을 필요로 하기 때문일 것이다. 현재 대부분의 신경 네트워크에는 이 자체가 쉽게 표현되지 않는다. 그러나 이러한 지식은 강력한 AI의 중심이 되어야 한다. 그리고 우리는 그 지식과 얻을 수 있는 아키텍쳐를 얻기 위한 전략을 둘 다 가지고 있어야 한다. 대표적으로 지식을 조작하는 과정은 자연에서 상징적으로 보인다. 

원칙적으로 우리가 제안한 공리의 작은 부분집합은 선천적일 수 있다. 다른 학자들은 이런 종류의 공리를 배울 수 있는 시스템이 없다고 한다. 
> 내장된 지식이 있는 신경 기호 시스템이 도움이 될 수 있다.

프레임워크 자체는 인식 가능한 도메인 집합으로 변환된다. 이와 관련된 공간, 시간, 인과관계에 대한 지식 등이 아래에 요약되어 있다.

![컨테이너에 대한 지식을 위한 프레임워크](https://user-images.githubusercontent.com/76898072/104557580-d7230380-5684-11eb-8e64-a2b059143314.png)

### 2.2.3 타고난 지식 체계

비록 모든 사람이 추상적인 지식이 선천적이라고 생각할 수 없을지라도 선천적으로 어떤 지식을 가지는 것에 대한 주장은 긍정적이고 간단하다. 찾고 있는 항목을 좁힐 수 있다면 검색하려는 가설 공간을 제한할 수 있다. 

어떻게 학습하는지를 숫자 인식 과제에서 보여준 LeCun의 컨벌루션에 대한 작업은 정확하고 실증적으로 입증한다. 이 컨볼루션을 사용하면 시프트 불변 형상 검출기가 장착된 계층 구조의 사전 배선 시스템에서 정확도 중가한다. 이것은 컨볼루션의 가치를 증명했다. 

그러나 기계 학습 연구자들은 그들의 시스템에 더 많은 선천적인 제약들을 포함하는 것에 반대한다. 네트워크 매개변수(계층 수, 손실함수 종류, 입력 노드 인코딩 체계 종류 등)는 본질성 면에서 공평하다. 하지만 대부분의 다른 것들은 일반적으로 학습될 것으로 예상된다. 일부는 이것을 자부심의 지점으로 받아들인다.
> 주로 '학습'을 이해하는 데 관심이 있다면 자연스럽게 '직접 코딩하는 것'을 폄하하게 된다.

Yoshua Bengio는 컨볼루션은 단 3줄의 코드가 필요하기 때문에 컨볼루션에 대해 명시하는 것은 받아들일 수 있다고 말했다. 하지만 이전(자연/지식적 지식의 일부)의 집합이 회생될 수 없을 정도로 확장되는 것에 대해서 걱정한다. 특히 이러한 이전 단계에서 몇 비트 이상의 정보가 지정되어야 하는 경우를 걱정한다.

우리 유전자 집합의 90% 이상이 뇌의 발달에 의해 표현된다. 그리고 그러한 유전자들 중 상당수는 특정한 영역에서 선택적으로 표현되며, 상세한 초기 구조를 낳는다. 그리고 적은 수의 유전자를 사용하여 복잡한 구조를 지정하는 많은 매커니즘이 있다. 본질적으로 유전자 집합은 아키텍쳐 구조를 반비례적으로 압축한 방법이다. 생물학적 두뇌가 단지 몇 개의 "작은" 이전 개념에만 국한된다고 생각할 이유는 없다. Kevin Mitchell은 토론 후 후속 조치를 통해 상황을 잘 요약했다.

> *뇌의 모든 뉴런의 수와 위치 그리고 연결성의 관점에서 게놈에 신경 발달의 정확한 결과를 명시하기에 충분한 정보가 없다는 것은 확실히 사실이다. 배아의 발달이 동적인 자기 조직 체계에서 행해질 때, 게놈은 오직 생화학적인 규칙들의 집합들을 암호화한다. 그리고 자연 선택에 의해 정의된 작동 매개 변수의 범위 내에 있는 결과를 도출할 수 있다. 이러한 운영 매개 변수에는 선천적인 이전 항목으로 인식되는 모든 종류의 항목이 포함될 수 있는 충분한 범위가 있다. 그리고 많은 종에 걸쳐서 많은 다른 선천적 게놈의 지시에 근거해 신경계에 미리 연결되어 있다는 증거는 많다.*
  \- Kevin Mitchell

그리고 게놈이 선천적인 이전의 지식을 위한 충분한 범위를 가지고 있다면, 현대의 AI 시스템은 아마도 훨씬 더 넓은 범위를 가지고 있을 것이다. 우리는 컴퓨터 메모리가 byte나 kilobyte가 아닌 Gygabyte와 Terabyte로 측정되는 시대에 살고 있다. AI의 진짜 문제는 우리가 우리의 이전 지식들을 얼마나 작게 만들 수 있는가, 어떤 지식이 가장 효과적인 학습을 도울 수 있는가 하는 것이 아니다. **비트 수를 최소화하는 것 자체가 목적이 되어서는 안된다.**

---

선천적인 것에 대한 세 가지 제안이 반복해서 나온다면 그것들은 시간, 공간, 인과관계를 위한 틀이다. 
> *시간, 공간, 인과관계에 대한 "여러가지"로 시작하는 가치가 중요하다.*
  \- Kant -
> *물체, 세트, 장소에 대한 기본적인 핵심 지식이 다른 지식을 얻기 위한 전제 조건일 수 있다.*
  \- Spelke -
> *만약 아동에게 물체, 사람, 세트, 장소를 지각할 수 있는 능력이 부여된다면 이러한 실체의 특성과 행동에 대해 배우기 위해 그들의 자각 경험을 이용할 수 있게 된다. 그러나 아이들이 그들 주변에 있는 그 실체들을 배제할 수 없다면, 아이들이 범위의 실체에 대해 어떻게 배울 수 있었는지는 명확하지 않게된다.*
  \- Spelke-
  
Davie와 나는 컨테이너의 분석에서 공간, 시간, 인과관계를 위한 이전 프레임워크의 가치를 강조했다. 여러 다른 발달 심리학자들도 수년간 비슷한 방향을 지적해왔다.

Spelke와 Kant가 강조했듯이 당신이 사물과 사물이 어떻게 시간을 여행하는지 알게 되면 그들의 가치를 채우기 시작할 수 있고 당신이 서계를 여행하는 데 필요한 지식을 얻을 수 있다. 

사실은 정반대로 접근해야한다.지금까지 발전되지는 않았지만 거의 빈 모델로 시작해서 대규모 데이터 세트에 대한 교육을 실시해야한다. 대규모 데이터 세트에 의해 훈련받은 비교적 비어있는 모델은 일부 대기업(Google, Facebook, Microsoft)에 의해 완전한 테스트를 받았고, 거의 무제한의 시간, 돈, 계산, 연구 인력을 제공받았다. 하지만 그들은 여전히 시간, 공간, 인과관계에 대해 신뢰성있게 추론할 수 없었다. 이러한 능력이 없다면, 우리의 시스템은 현실 세계의 가변성에 대처할 만큼 충분히 강력하지 않을 것이다. 

*이제는 확실히 좀 더 토착적인 접근법을 고려할 때이다.*

---

역사적으로 딥러닝 커뮤니티에서 싫어했음에도 불구하고, "사전 지식"에 대한 보다 개방적인 징후가 증가하고 있다.

물론 모든 신경망이 실제로 해당 시스템에 의해 학습된 것이 아닌 선천적으로 확립된 사전 지식들로 가득 차 있다. 사전 지식으로는 특정 학습 규칙, 특정 연결 패턴, 특정 표현 방식(예: 입력 및 출력 노드의 의미) 등이 있다. 하지만 이러한 사전 지식 중 개념적인 것은 거의 없다.

이러한 문제에 대한 진짜 질문은 *어떤 종류의 사전 지식을 나타내야 하는가, 우리가 필요로 하는 사전 지식이 우리가 이미 가지고 있는 도구들로 자연스럽게 표현될 수 있는지, 보다 광범위한 사전 지식을 나타내기 위해 새로운 툴이 필요한가*에 대한 것이다. 딥러닝 커뮤니티는 (신경망 프레임워크에 자연스럽게 들어 맞는) 컨볼루션을 선행 지식으로 사용해도 괜찮을 것 같아도 주장했다. 그러나 지금까지 커뮤니티는 더 복잡한 사전 지식(사물의 지속성에 대한 선천적인 지식, 시간적 미적분학을 통해 시간에 따른 사건의 이해) 바탕의 모델들에 적은 관심을 가졌다.  

우리가 물어봐야 할 것은 *내가 벗어날 수 있는 최소한의 선천적인 구조가 무엇인가, 내가 필요로 하는 사전 지식의 종류는 무엇인가, 나의 기존 아키텍쳐들이 그것들을 효과적으로 통합할 수 있는가, 딥러닝 기질의 풍부한 사전 지식을 구축할 수 있는가, 그 프레임워크에서 편하게 표현할 수 있는 것에 한계가 있는가*와 같은 것이다. 우리에게 인과간계 같은 다른 유형의 추상화를 나타내기 위한 명시적인 기호 조작 기계가 필요할 것인가? 

> *딥러닝은 물체가 어떻게 생겼는지에 대한 지식을 표현하는데 능숙하다. 하지만 물리적인 세계가 어떻게 작동하는지에 대한 지식을 얻고 표현하는 것과 일반적인 인과관계에는 미숙하다. *
  \- Zhang, Wu, Zhang, Freeman, Tenenbaum -
  
확률론적 프로그래밍과 같은 기타 접근법은 은밀한 통계 정보로부터 배우려고 노력하는 동시에 명시적으로 표현된 상징적 제약들을 허용한다. 이러한 기타 접근법을 진지하게 고려해 볼 가치가 있다. 

---

한 발자국 물러나서 인간이 세상에 대해 알고 있는 것을 살펴보자
> *배가 가라앉기 보다는 뜨는 경향이 있다는 사실 <br>
  배 아래에 구멍을 내면 가라앉는 경향이 있다는 사실 <br>
  불을 지피는 데는 라이터가 솜뭉치보다 낫다는 사실 <br>
  부서진 병들이 샌다는 사실*
  
우리가 확실히 가지고 있는 핵심 지식은 끊임없이 막대한 양의 학습된 지식에 의해 보충되어야 한다.

보통 사람이 이러한 사실을 많이 알고 있다고 생각하는 것은 이상한 것이 아니다. 이것들의 경험, 명확한 설명 등 여러 수단을 통해 대부분은 배워야 한다. 사실상 그 지식들은 지배적인 행동과 의사 결정에 바로 옮길 수 있다. 예를 들어 보트 아래에 구명이 있는 것을 발견하면 보트를 타지 않기로 선택할 수 있다.

우리가 배운 지식의 중요한 부분은 인과관계이며 추상적이다. 따라서 앞 절에서 이야기한 것과 같이 어떤 종류의 하이브리드 아키텍쳐를 사용해야 할 것이다. 

한편 세계 자체가 끊임없이 변화하기 때문에 순수한 사전 지식은 충분하지 않을 수 있다. 신기술과 관련된 새로운 인과적 원칙은 항상 존재할 것이다. 누군가 Framulator이라는 인기 있는 새 장치를 소개할 경우 우리는 Framulator가 무엇을 하는지, 어떻게 하는지를 빠르게 배운다. 아이들은 이것을 자연스럽게 보여주었다. 우리는 이와 같은 일을 할 수 있는 장치가 필요하다.

하지만 우리는 아마도 경험만으로 추상적이고 인과적인 모든 지식을 배울 수 없고, 배워서도 안 될 것이다. 많은 지식이 이미 문서로 나타났을 때 이렇게 하는 것은 비효율적이다. 왜 모든 시스템이 가려져 있을 때 조차도 공간과 시간이 계속 존재한다는 것을 새롭게 배우도록 만드는가? 예를 들어 GPT-2 논의에서 우리가 본 것처럼 처음부터 배우는 것은 지금까지 믿을 수 없었다. 신체, 심리학적 추론의 기초와 같은 사전 지식 없이 우리가 상식이라고 부르는 것 중 어떤 것도 잘  배우지 못한다. 우리는 우리가 배우는 것의 나머지를 지시하기 위해 약간의 핵심 지식이 필요하다. 

타협과 혁신의 필요성이 다시 한번 드러난다. 우리는 새로운 인과적 지식을 얻을 수 있는 시스템(신경 상징적 하이브리드)이 필요하다. 그러나 그 지식을 얻기 위해서는 *우리가 지금까지 해왔던 것보다 더 강력한 사전 지식이 필요할 것이다.*

본 논문에서의 세 번째 주요 주장은 **세상에 대한 지식이 없는 새로운 AI 시스템을 처음부터 새로 시작하는 대신 시간, 공간, 인과관계와 같은 영역에 대한 초기 프레임워크로 시작하는 학습 시스템을 구축하기 위해 노력해야한다.** 그렇다면 학습 속도가 올라가고 가설 공간을 크게 제한할 수 있을 것이다.

이러한 프레임워크가 공식 논리(CYC) 또는 기타 수단으로 표현되는 지는 아마도 아직 발명되지 않았을 것이다. 나는 이러한 표현이 강력한 지능을 향한 어떤 심각한 진보의 전제 조건이라고 강하게 생각하다. 아무리 본질적이라도 학습의 대체물이 될 수는 없다. 이러한 게임의 이름은 크고 작은 선천적인 사전 지식의 집합을 찾는 것이다. 이것은 우리의 시스템이 궁극적으로 필요로 하는 방대한 지식의 학습을 가장 용이하게 할 것이다. 

> 지식만으로는 충분하지 않다. 지식은 추론을 위한 도구와 인지 모델 안에서 실행 되어야 한다. 

## 2.3. 추론

AI에 대한 현재의 접근 방식은 주로 전 세계에 대한 확률밀도함수를 암기하면서 세계의 복잡성에 대처하려고 노력하고 있다. 이는 끊임없이 더 많은 데이터를 필요로 하는 비용을 감수해야 한다. 세상의 기하급수적으로 복잡해 지는 것을 볼 때, 이것은 효과가 없을 것 같은 전략이다. 

추론은 대안이 된다. 모든 것을 암기하거나 이전에 접했을지도 모르는 정보에 덧붙이는 것 대신에 추론을 한다. Plato, Aristotle, Euripides와 수많은 사람들이 모두 죽었다는 사실을 외우는 대신에 모든 인간은 인간이라는 일반적인 진리를 이 범주의 특정 사례에 적용하며 일반적인 진실을 배울 필요가 있다. 

Transformer와 같은 신경망(적어도 현재 일반적으로 사용되는 것과 같이 신경-조작 도구로부터 격리된 방식)은 음향 감독관을 만들기에는 신뢰할 수 없다. 기호 표시는 충분한 지식을 얻을 수 있다면 적어도 올바른 방향을 향할 수 있는 가능성을 제공한다. 

고전적 형태 안에서의 추론 엔진의 가장 좋은 경우인 CYC는 최적의 환경에서 수행할 수 있다.
> *로미오와 줄리엣 이야기의 줄거리는 이야기와 관련된 지식, 어떤 상식적인 지식 두 가지로 추상화 되어있다.*
  \- CYC 창립자 Doug Lenat -
  
```
관련 상식적인 지식의 샘플 및 CYC에 의해 도출된 복잡한 추론
- 관련 상식적인 지식
- 추출한 표본
```

위 범위 중 추출한 표본의 해당 시점에 참이 되는 시점과 문장을 나열하는 항목은 풍부한 인지 모델의 예다. 이것은 복잡한 시나리오의 내부 정수라는 점에서 인지 모델이다. 그리고 이것은 특정한 주인공들이 행동하고, 알고, 의도하고, 특정한 시점에서 기대하는 것에 대한 미묘한 정보로 가득 차 있다는 점에서 풍부하다. 

우리는 이것이 암호화하는 행동, 결과, 인간과 상호작용에 대한 정보의 복잠함을 고려할 때, 위 범위 중 관련 상식적인 지식을 풍부하게 받아들일 수 있다. 이러한 지식의 일부는 명백하게 표현될 수 있고, 더 일반적인 사실에서 파생될 수 있다(예: 특정 독을 마시는 결과는 즉각적인 죽임일 수 있다). 예를 들어, "사람이 죽으면 그들은 아무와도 결혼하지 않아도 된다"는 것은 의무가 살아있는 사람들에게만 적용되는 경향이 있다는 좀 더 일반적인 견해에서 비롯될 수 있다. 넓은 지식을 갖는 것은 보상이 도출될 수 있는 추론의 정교함과 해석능력을 준다. 이 두 가지는 지금까지 딥러닝을 통해 생산된 어떤 것과도 완전히 다른 수준에 있다.

> 일부 관측치
  - **구조화된 표현을 광범위하게 사용하지 않는 한 변수에 대한 연산 및 개인에 대한 기록에는 접근 불가능할 것이다.**
  - 생물학, 정신 이론 등에 대한 **풍부한 인지모델의 잠재적 가치를 보여주는 최상의 개념 증명을 나타낸다.**
  - 로미오와 줄리엣을 공식 논리롤 수작업으로 번역한 지식 엔지니어의 이전 작업에 크게 의존하고 있다. **이러한 종류의 표현을 자동으로 생성할 수 있는 시스템과 유사한 수준의 사유는 주요한 돌파구를 나타낼 것이다.**
  - **추론 그 자체는 강력한 AI로 향하는 병목 현상일 필요는 없다. 실제 병목 현상은 실제 추론의 맥락에서 접근 가능한 올바른 정보를 얻는 데 있다.**
  
물론 CYC는 완벽과는 거리가 멀다. 그리고 CYC가 작업하기에 충분한 사전 패키지가 제공되는 경우가 없다. CYC에는 자연어가 많지 않고 앞으로도 없을 것이다. 이러한 문제는 논리적인 형태로 표현해야 한다. 이는 미리 포장된 문제가 거의 없기 때문에 즉각적인 상업적 응용이 거의 없다. 하지만 다양한 형식 논리로 구현된 고차원의 추론과 대규모 추상적 지식을 결합하는 시스템 내에서 미묘한 추론이 가능하다는 증거다.

CYC의 추론 능력에서도 틀림없이 개선의 여지가 많다. 그 표현은 주로 고차원 논리의 소재다. 이것은 어느 정도까지 불확실성을 나타낼 수 있는지 명확하지 않다. 그리고 불완전하고 부정확한 것을 다루는 CYC가 얼마나 많은 불확실성을 가지고 있는지 명확하지 않다.

> *모든 인간의 지식은 불확실하고, 부정확하고, 부분적이다.*
  \- Bertrand Russell - 

> 또 다른 문제는 확인 편향, 동기부여된 추론, 맥락효과, 접속 오류 등과 같은 인간이 추론에서 직면하는 많은 한계들이다. 이상적인 세계에서는 우리는 이러한 이상 징후는 남겨두고 인간이 무엇을 잘하는지 배운다. 인간의 이러한 인지적 오류가 기능적으로 최적이 아닐지라도 이러한 인지적 비효율이 진화되었는지에 대한 논의를 참조하라.

그리고 고전 및 신경 AI의 다른 많은 것과 마찬가지로 하나의 의문점은 부러지기 쉽다. 이 의문점은 데이터베이스의 특정 지식과 복잡한 시나리오를 내부 논리에 매핑하는 정확한 방법 모두에 크게 의존한다. 

그래도 *다른 접근방식을 사용하여 유사한 작업을 수행할 수 있는 다른 것*은 강력한 추론으로 가는 과정에서 필요한 단계처럼 보인다. 로미오와 줄리엣의 줄거리를 이해할 수 없는 AI는 현실세계의 복잡성에서 능숙한 동작을 못할 것이다. 시간이 지남에 따라 펼쳐지는 복잡한 사건처럼 인간과 상호작용하는 동기를 추론할 수 있는 AI는 일할 기회를 갖는다.

낙과적인 가능성은 하이브리드 아키텍쳐 지식의 전체 조건이 더 잘 개발되면 추론이 저절로 정리될 수 있다고 말한다. 확장성과 불완전한 지식을 다루는 능력면에서 비관적인 가능성은 우리가 추론 그 자체에서 중요한 개선이 필요할지도 모른다는 것이다. 우리는 아키텍쳐와 지식 표현이라는 두 기능을 정돈하기 전까지는 알 수 없을지도 모른다. 

그러나 우리는 이미 *세계의 복작함으로 인해 같은 종류의 지식이 필요하다는 것*을 알 수 있다. 그리고 로미오와 줄리엣 시나리오가 예로 드는 것과 정교한 추론을 하기 위해 우리의 시스템을 밀어붙일 새로운 벤치마크가 필요하다는 것은 분명하다. 그 이유는 모든 시나리오를 미리 인코딩할 수 없고, *규모 배경 지식을 효율적으로 활용할 수 있는 추론 시스템*과 *사용 가능한 정보가 불완전한 경우에서도 강력한 전제조건* 사이에 보관하기를 바랄 수도 없기 때문이다. 

Minervini의 최근 연구는 신경 상징적 하이브리드 접근법이 새로운 장을 열 수 있다는 희망을 준다. Besold는 또 다른 출발점을 제공한다. 사람들이 노력한다는 사실이 네게 더 많은 희망을 준다. 우리가 앞으로 나아가려면 추리와 지식은 가장 중요한 개념이 되어야 하고, 사람들이 노력하는 것을 보는 것은 좋은 일이다. 

## 2.4. 인지 모델

특별한 종류의 지식은 우리가 대화하는 과정에서 친구에게 배울 수 있는 것이나 뉴스를 읽는 과정에서 국가에 대해 배울 수 있는 것과 같이 특정한 상황의 상태에 대해 시간이 지남에 따라 축적되는 지식이다. 인지심리학에서 우리는 이렇게 축적된 표현을 **인지 모델**이라고 부른다. 인지 모델은 모든 사람들이 모두 다르지만 일상적으로 사용된다. 최소한 인지 모델은 일부 실체(예: 이야기의 등장인물 및 등장인물이 이용할 수 있는 사물), 일부 속성(예: 개체의 크기 및 색상, 등장인물의 목표), 시간 및 사건(예: 등장인물 x가 등장인물 y를 만난 시간 t)에 대한 지식으로 구성 될 수 있다. 

무엇을 언제 믿었는지에 대한 복잡한 사실들의 명시적인 표현들의 집합과 같이 CYC/Romeo 및 Juliet 일러스트의 제안 및 시간 표시는 풍부한 인지 모델이 AI 시스템에서 인코딩할 수 있는 것의 예가 된다. 그리고 정신 모델에 대한 Johnson-Laird의 연구도 예시라고 생각할 수 있다. 만약 내가 당신에게 빈 책장이 있고 책 두권을 책꽃이에 놓았다고 말한다면 당신은 책 두 권을 포함하는 책장의 내부 표현을 생각할 것이다. 그리고 내가 당신에게 선반에 다른 책을 추가했다고 말한다면 당신은 당신의 생각을 업데이트해서 지금 3권의 책을 포함하는 책장의 내부 표현을 생각할 것이다. 무언가를 모델 추론을 위해 이해하는 것은 궁극적으로 그것이 작동하는 방식에 대한 추론을 할 수 있다. 

이것은 결과 사소한 과정이 아니다. 원칙적으로 GFAO 연구자는 복잡한 인지 모델을 수작업으로 구성하는 방법을 설명할 수 있다. 그러나 특정 상황에서 올바른 인지 모델이 무엇인지, 다음에 무슨 일이 일어날지 추론하는 것은 복잡한 과정이다. 흔히 주어진 상황에서 그럴듯한 대답 하나 이상을 가지고 자동화하는 방법은 아직 없다.

CYC의 예인 로미오와 줄리엣은 시스템이 도출하는 추론이 정교하고 합리적이라는 점에서 설득력이 있다. 하지만 기본 모델이 연극의 대본으로부터 유도된 것이 아니라 수작업으로 코딩되어 있다는 점에서 실망스럽다. 시스템이 입증하기 위한 용도에 적합하도록 만들어야 한다. 현실 세계에서 인지 모델이 강력한 인공지능으로 가기 위해서는 데이터 스트림(에: 비디오 또는 텍스트)에서 자동으로 데이터를 추론하는 방법을 사용해야한다.

이것은 매우 어려운 문제여서 대부분의 사람들은 대신 다른 일을 하고, 인지 모델 없이 일을 하려고 한다.

---

DeepMind의 Atari 게임 시스템 DQN은 명백한 인지 모델이 부족하다. DQN이 브레이크 아웃을 배울 때 개별 보드 위치를 개별 브릭의 위치와 범위를 나타내는 장명 그래프로 추상화하지 않는다. 공의 속도, 게임의 기초 물리학, 게임을 매력적으로 만드는 리코체의 역학의 어떤 추상적인 깨달음은 어디에 있는지 직접 나타나지 않는다. 이는 강화 학습에서 '시스템에 모델이 없다'라고 부른다. 이는 초월적인 성취를 이룬다.
> *고전적인 인지 상태와 어느 정도 상관관계가 있는 시스템의 내부 상태를 가리키는 Hair-splitter는 스스로 생성된 일종의 내부 모델이 있다고 할 수 있다. 이러한 시스템이 상황으로 이행되는 제한된 능력은 이러한 종류의 강력한 주장을 약화시킨다고 보여진다.*

하지만 DQN과 같은 시스템의 성공에서 얻을 수 있는 교훈은 무엇일까? 내 생각에는 이러한 시스템은 지나치게 일반화되었다고 생각한다. 브레이크 아웃과 같은 폐쇄형 영역에서 충분한 데이터가 제공(비슷한 환경에서 인간이 요구하는 것보다 훨씬 더 많은 데이터)된 모델 없는 강화학습에서는 이러한 모습이 잘 보인다. 하지만 이것이 모델 없는 강화학습이 *지능*에 대한 좋은 일반적인 해결책이라는 것을 의미하지는 않는다. 

문제는 모델이 없는 솔루션이 유도된 환경 외부에서는 제대로 된 일반화가 되지 않는다는 것이다. Kansky는 Breakout을 이용하여 사소한 변화에도 급격한 성능 저하를 초래하는 방법의 해결책을 제시하였다. 이 방법은 내부 인지 모델을 사용하는 환경에 신속하게 보상을 할 수 있다. 모델 없는 심층 강화학습 시스템은 그들이 작동하는 환경에 대한 풍부한 인지 모델이 없는 경우 강력한 재교육을 할 수 없다.

GPT-2와 같은 현재 Transformer의 언어 이해에 있어서 실패의 범위는 유사한 것을 반영한다. 일반적인 경향을 예측하는 것과 인지 모델을 표현하고, 업데이트하고, 조작하는 능력은 서로 다르다. BERT와 GPT-2가 드라이클리닝이 있을 위치를 추적하지 못한 것은 *GPT와 BERT가 시간이 지남에 따라 진화한 개별 실체의 특성을 나타내지 않는다*는 것을 직접적으로 반영한 것이다. 인지 모델이 없다면 이런 시스템은 사라진다. 때때로 그들은 통계학으로부터 정보를 얻지만, 인지 모델이 없으면 그들은 추론할 수 있는 믿을 만한 기초도 없어지게 된다.

인지 모델의 부족은 Transformer를 다운스트림 추론 시스템의 입력으로 사용하고자 하는 모든 사람들에게는 좋지 못한 소식이다. 언어 이해의 전체 본질은 담화에서 인지 모델을 도출하는 것이다. 그런 다음 우리가 도출하는 모델에 대해 추론을 할 수 있다. 현재 형태의 Transformer는 단지 단어 클래스를 예측하는 것에 인상적인 모습을 보이지 않는다. 그러나 예측은 이해와 같지 않다. 

---

CYC는 배경(상식적인 지식)과 관련하여 인지 모델(예: 다양한 시점에 알려진 특징에 대한 시간적 기록)에 비해 훨씬 좋은 성능을 보인다. 하지만 관련 인지 모델을 도출할 수 없다는 결함이 존재한다. **자연어 위키백과를 입력으로 가질 수 있는 시스템은 자체적으로 세부 인지 모델을 자동으로 도출할 수 있다. 이는 현재의 AI에 비해 큰 발전이 될 수 있다.**

아쉽게도 텍스트(비디오는 말할 것도 없고)에서 풍부한 인지 모델을 도출하기 위해 일하는 사람은 거의 없다. Pasupat과 Liang은 시간이 지남에 따라 발전하는 사건을 기술하는 것을 테이블 너머로 훑어볼 수 있는 프로그래밍 가능한 쿼리로 문장을 구문 분석하려고 시도했지만 시간이 나면서 변하는 모델을 축적하려고 하지 않았다. 메모리 네트워크 및 반복 엔티티 네트워크와 같은 모델에 대한 Facebook AI 연구원은 간단한 이야기를 입력으로 받고 그에 대한 몇가지 기본적인 질문에 답할 수 있는 연구를 진행했다. 이러한 시스템은 아래와 같은 특성이 있다.

> 그들이 대답하는 각각의 질문에 대한 많은 양의 입력을 요구한다.
  질문과 대답 사이의 언어적 중복에 크게 의존하고, 범위가 제한적이다. 
  사전 지식을 통합할 수 있는 능력이 제한되어 있다. 
  그들의 출력물로 추론자에게 전달될 수 있는 풍부한 인지 모델을 생산하지 못한다.
  
가장 능동적인 문헌은 장면 이해에 관한 작업이다. 이는 궁극적으로 시작적인 장면을 어떤 사물이 있는지만으로 해석하는 것을 목표로 한다. 이것은 더이상 최첨단 기술이 아니다. 

> *추론 없이 작업하는 것을 목표로 하기 때문에 많은 작업이 개인의 집합이나 실체 간의 관계에서가 아니라 전체로 장면을 인식하려고 한다. 추론은 장면에서 인지 모델을 유도하는 과정에 기여하기 때문에 일관성 있는 모델을 구성하는데 필수적이다. 확률론적 생성 모델 GENESIS은 장면 구성 요소 간의 종속성을 명시적으로 모델링한다. *

인지 모델 유도는 여기에서 더 나아가 표면적이고 심리적인 관계를 파악해야 한다. 예를 들어 두 사람이 대화를 하고 있다면 표면적으로 두 사람이 대화하는 것을 파악하고, 사람의 심리적 상태(대화하는 목적)를 파악해야 한다. 장면을 기호로 해석하려면 상징들 중 일부는 우리의 지각적 경험에 근거를 두어야 하기 때문에 우리는 입력으로부터 기호를 추론하는 방법을 가지고 있어야 한다. 적절한 모델을 구축하려면 시간적 경계와 시간 관계 등을 추론할 수 있는 시스템도 필요하다. 

장면 이해는 우리가 이야기를 이해하거나 기사를 읽을 때마다 같은 일을 하는 것과 같다. 이 경우에는 시각적인 경험보다는 단어에 의존한다. 

강력한 지능으로서의 첫 번째 시도에서 세익스피어를 이해하는 기계를 만들 수는 없다. 아이들은 세익스피어를 자연스럽게 이해하지 못할 것이다. 하지만 아이들이 갖고 있는 지능은 강력하다. 아이들은 학교를 다니면서 일상 사물의 물리적 상호 작용에 대한 많은 것과 인간의 목표와 동기를 이해할 수 있다. 그리고 로미오와 줄리엣 이야기의 핵심인 속임수와 오해와 동기 부여와 같은 개념을 파악했다. 또한 방대한 범위의 주제에 대해 대화할 수 있다. 

궁극적으로 추론과 인지 모델은 무한히 많은 방법으로 결합될 수 있다. 예를 들어 오후 12시에 쿠키가 담긴 밀폐된 쿠키 항아리가 있는 방에 어린아이 혼자 있었고, 오후 12시 5분에 항아리 덮개가 닫혀있지만 쿠키가 없다고 가정해보자. 당신은 여기에서 아래와 같은 시간 및 공간적 추론 결합을 추론할 수 있을 것이다.

> 아이가 항아리를 열고 쿠키를 먹고 뚜껑을 닫았다.
  아이가 항아리를 열고 쿠키를 버리고 뚜껑을 닫았다.

쿠키가 항아리 입구에서 다른 입구로 이동한 쿠키가 아이 안에 들어 있다는 것을 알 수 있다. AI가 내부 인지 모델과 그것들을 추론하는 메커니즘 없이 이러한 종류의 추론을 강력하게 만들 수 없다.

> **하이브리드 아키텍쳐는 풍부한 사전 지식 및 정교한 추론 기술 없이는 적절하고 자동화된 방식의 풍부한 인지 모델을 구성할 수 없다.** <br>
  만약 차가 물 위에 뜨지 않는다고 알고 있는 우리가 차를 연상시키는 파도를 본다면  보통 우리는 그 파도가 단지 파도라고 가정할 것이다. 하지만 영화에서 차가 의도적으로 물 속에 뛰어 드는 모습을 보고 우리의 지식이 바귈지도 모른다. 장면의 이해는 궁극적으로 객체 레이블링에만 국한되지 않고, 사용 가능한 최상의 데이터를 사용하여 일관성 있는 해석을 하는 것이며 이는 사전 지식으로 데이터에 대한 추론을 필요로 한다. 레이블링된 이미지에만 의존하는 순수한 상향식 접근 방식은 다양한 특이 사례에서 실패할 수 있다. 
  
> **풍부한 인지 모델을 유도하고 나타내는 능력이 없다면 강력한 지능을 달성할 수 없다.** <br>
  이에 대한 예시로는 부분적으로 문장을 입력으로 받아들이고 내부 인지 모델로 생성하는 함수가 있다. 로미오가 오해로 인해 자살했다는 걸 알게 되면 우리는 우리의 모델을 업데이트한다. 모델을 업데이트하면 우리는 자신을 설득하게 된다(로미오가 줄리엣의 명백한 죽음을 고려하고 자살했다는 것이 말이 되는가?). 우리의 감정적 반응은 일어난 일에 대한 내부 인지 모델에 대한 상대적인 판단에서 비롯된다. 순수한 동시 방생 통계는 이 중 어느 것에도 확실하게 도달하지 못했다. CYC는 지각적 요소가 없고 적절한 자연어 변환부가 없기 때문에 풍부한 인지 모델을 나타낼 수 있지만 데이터로부터 모델을 유도하는 작업에 의존한다. 변환부는 풍부한 인지 모델을 유도하고 표현하는 단계를 건너뛰는데 성공했지만 추론 결과가 제한적이다. 이와 비슷하게 가정용 로봇은 풍부한 인지 모델에 대한 유도, 표현, 추론 능력에 의해 안전한 행동 범위에 구속 될 것이다.
  
---

더 많은 데이터만으로는 이 문제를 해결할 수 없다. 구글은 GPT-2의 약 10배 크기인 341GB 언어 집합에 대한 훈련을 받은 Meena를 출시했다. 이는 대략 341,000권의 책들과 맞먹는다. 

Meena는 매우 유창한 산문을 재작하고 주제에 대한 파악이 뛰어나다. 신문에서넌 "감각성과 특수성"의 새로운 척도에서 새로운 최첨단 기술을 설정했다고 보도햇다. 하지만 Meena에도 여전히 세계의 내부 인지 모델과 같은 핵심 기반이 없다.

다음 대화(<https://github.com/google-research/google-research/blob/master/meena/meena.txt>) 중 61번 대화는 아래와 같다. 

> 사람 : 가장 좋아하는 밴드가 무엇인가?
  Meena : Avenged sevenfold
  사람 : 오! 좋은 대답이다. 가장 싫어하는 밴드는 무엇인가?
  Meena : Avenged sevenfold
  사람 : Avenged sevenfold를 좋아하는거 아니었어?
  Meena : 맞다. 내가 가장 좋아하는 밴드다
  
각 대답은 일관적이지만 다음 대답과는 일관성이 없다. Meena는 밴드 이름과 같은 특정 구절이 종종 "가장 좋아하는 밴드"와 같은 구절과 상관관계가 있다고 추론했다.

그리고 77번 대화는 아래와 같다. 

> 사람 : 새해 목표가 무엇인가?
  Meena : 60 파운드 감량과 광둥어와 프랑스어 배우기다
  사람 : 터무니 없는 생각이라고 생각 안해?
  Meena : 현재 몸무게가 35파운드나 줄었고, 광둥어는 이미 기본적인 수준까지 할 수 있고, 프랑스어는 학교에서 이미 배우고 있다.
  사람 : 오! 인상적이다.
  Meena : 나는 옆에서 프랑스어를 배우고 있고, 광둥어는 원어민 정도이다.

Meena는 자신이 광둥어를 "배우는 중이다"라고 표현하는 것과 이미 광둥어에 정통한 것 사이에서 망설이고 있다. 이미 알고 있는 언어를 배울 수 없다는 인식도 없고, Meena가 광둥어를 할 수 있는지 없는지에 대한 기본적인 내부 모델도 없다. 문장별 예측은 탁월하지만 전체적 일관성은 없다.

---

"고양이가 매트 위에 있다"라는 문장이 어떻게 해석되는지 보자. 문장 해석은 구문에서 의미론에 이르는 경로를 따라 실체(예: 고양이, 매트)와 상호 간의 특성 및 관계를 추론할 수 있는 업데이트 가능한 인지 모델과 같다. 

"고양이가 매트 위에 있다"는 문장을 읽은 7살 아이에게 코끼리를 매트 위에 올릴 수 있냐고 묻는다면 경우에 따라 다르다고 대답할 것이다. 아이는 질문을 들은 즉시 허구의 세계와 그 세계를 채우는 실체의 모델을 형성했고, 그의 일반적인 상식과 지식을 세상에 대한 논리에 적용시켰다.

위 대화를 듣고 있던 5살 아이는 이 대화를 완벽하게 이해했다면 코끼리와 매트에 대한 답을 줄 수 있을 것이다. 그리고 코끼리를 올릴 매트가 집에 맞을 수 있을지를 물어본다면, 이 아이도 합리적인 결론을 도출하기 위해 모델 구성과 불특정 매개변수에 대한 추론을 진행할 수 있을 것이다.

어린 아이들의 기본적인 추론과 모델 구조를 맞출 수 없는 시스템을 갖춘 AI는 믿을 수 없다. 인지 모델과 추론이 나타나기를 기다리는 것은 기적을 기다리는 것과 같다.

현재 인지 모델을 가진 시스템을 구축하기 위한 연구가 너무 적다. 대규모 훈련 세트를 통한 end-to-end 학습에 대한 강조는 상위 수준 인식의 핵심이다. 대부분의 연구자들은 인지 모델을 중심으로 하는 시스템을 만들려고 시도조차 하지 않는다. 그리고 *입력 스트림에 상대적인 인지 모델을 도출하고 업데이트*하는 일반적인 방법을 발견하는 것과 관련된 연구도 적다. 심지어 사전 지식 기반 모델에 대한 추론을 연구하는 사람은 더 적다. 

> *언어와 지각적 입력을 풍부하게 매핑할 수 있는 시스템 구축은 진화하는 인지 모델에서 가장 먼저 연구되어야 한다.*

단어 수준 예측의 대규모 모델을 개선하는 것은 인지 모델에 대한 도출, 업데이트 및 추론을 위한 기술을 개발하는 데 유용하다. 이는 강력한 AI를 구축하는데 중요하다.

# 3.논의

## 3.1. 지속적이고 추상적인 지식을 바탕으로 한 지능을 지향한다.

우리와 같은 생명체가 없어도 세상은 계속 존재할 것이다. 하지만 세상은 설명되지 않거나, 잊혀지거나, 이해되지 않을 것이다. 새가 날개를 퍼덕이거나 날아갈지 모른다. 이는 상관관계가 있지만 인과관계는 아니다. 인간의 삷은 추상화와 인과적 설명으로 가득 차 있다. 아이들은 *"왜"* 라는 물음에 많은 시간을 사용한다. 과학자들은 이론을 만들기 위해 *"왜"* 라는 질문을 한다. 우리의 힘이 중요한 부분은 과학, 문화, 기술의 형태로 세상을 이해하고 특정짓기 위한 우리의 노력에서 비롯된다. 

이러한 노력의 대부분은 특성, 일반화, 기록이 아닌 어떤 지식의 형태로 끝이 난다. 고전적 AI의 목표의 대부분은 이러한 지식을 기계가 해석 가능한 형태로 바꾸는 것이다. CYC는 이러한 맥락에서 중요한 프로젝트였다. 

AI 분야는 발전되면서 다른 방향으로 전환했다. CYC를 실패라고 생각한 연구자들은 자신들의 목표가 어떤 의미에서도 지식을 축적하는 것이라고 설명하지 않는다.

> *Google 지식 그래프의 목표는 추상적인 상식이 아니라 검색 문제를 모호하게 하는 것에 도움이 될 수 있는 특정 사실을 축적하는 것이다.*

Transformer와 같은 시스템의 부분적인 성공은 CYC 크기의 인간 지식에 대해서 기계가 해석 가능한 표현이 불필요하다는 환상을 불러일으켰다. Transformer는 통계 추론 엔진으로서 매우 인상적이지만 강력한 지능을 위한 기반이 되는 것은 무리다. 그들의 지식은 믿을 수 없다. 그리고 그들은 사건들의 인지 모델을 만드는데 실패하고 사건들이 시간이 지남에 따라 전개되게 된다. 추리 및 인지 모델 구축과 해석과 디버깅이 가능한 지능을 위한 프레임워크에 정교한 시스템에 Transformer를 연결하는 명백한 방법은 없다. 

강력한 인공지능을 구축하기 위한 4가지 인지적 전재조건의 우선순위가 바뀌어야 한다. 기호 조정의 표현 및 계산 능력과 대규모 학습을 결합한 하이브리드 아키텍쳐는 다른 형태의 지식들과 함께 상징적인 지식을 통합한 대규모 지식의 기반이 된다. 그리고 지식 기반을 다루기 위운 방법으로 활용할 수 있는 추론 메커니즘과 지식 기반과 함께 작동하는 풍부한 인지 모델을 제공한다. 

이와 함께 여러 종류로 이루어진 아키텍쳐가 필요하다. 지금까지 많은 기계 학습은 통합과 통합만 가능한 개별 뉴런을 가진 비교적 균질한 구조와 지정된 모듈만 사용하는 기능에 초점을 맞추고 있었다. 하지만 이것은 지나치게 단순하다. 거시적으로 대뇌 피질만 해도 해부학적으로나 기능적으로 수백 개의 영역을 가지고 있고, 하나의 뉴런이 XOR의 비선형성을 계산할 수 있다. 대뇌 피질은 단일 표준 회로로 모든 기능을 계산할 가능성이 낮다. 신경 계산에는 아직 컴퓨터 신경 과학이나 AI에 포착되지 않은 중요한 다양성이 있을 가능성이 있다.

두 수치는 우리가 최근 몇 년동안 어떤 일을 해왔는지 질적으로 보여준다. 따라서 우리가 추구해야 할 방향은 잠재적인 AI 모델이다. AI 초기 계획없는 경험론 모델은 많은 계산 자원과 데이터베이스를 바탕으로 연구되어왔다. 이는 많은 형태로 발전이 있었는데 현재 심각한 문제가 되었다. 그래서 이제는 다른 접근 방식을 탐구해야 할 때다. 

최소한 우리는 원칙적으로 언어와 높은 수준의 인식에 필요한 것들을 표현하고 배울 수 있는 모델을 구축해야한다. 

대부분의 현재 시스템이 제대로 작동하지 않으면, 적절한 지식 프레임워크는 변수에 대한 연산을 통해 우리가 우리의 지식의 일부분을 대수적 방법으로 표현하고 조작할 수 있는 것을 요구할 것이다. 그 지식의 일부는 구조화된 표현의 관점에서 암호화되고 유지되며 많은 부분이 특정 객체의 추적을 허용해야 한다. Transformer 아키텍쳐에는 이러한 모든 방법을 해결할 방법이 있지만 추가적으로 보충하지 않으면 실패할 가능성이 있다.

현재 예측한 강력한 인공지능이 아래 그림에서 묘사된 교차점에 있을 것이다. 

![그림 5](https://user-images.githubusercontent.com/76898072/105173913-11007800-5b65-11eb-85e4-869ec3a8694d.png)
> 가능한 지능 모델의 넓은 공간 내에서 학습 및 기호 조정의 차원에서 초점을 맞춰 몇 가지 모델과 아키텍쳐를 표현한 벤 다이어그램. <br>
  개인을 위해 기록한 구조화된 표현인 대수적 정신의 가설과 현재 추측의 핵심은 성공적인 지능 모델 변수에 대한 연산을 필요로 할 것이다. 이 교차점이 새로운 10년 동안 일반 지능을 향한 연구의 중심이 되어야 한다. 

올바른 아키텍쳐가 시작될 수 있는 교차는 무한할 수 있다. 하지만 올바른 원시 요소 세트를 갖는 것은 시작에 불과하다. 

무한한 수의 가능한 컴퓨터 프로그램에 대해 생각할 방법이 있다면, 일부만 응용 프로그램으로 인스턴트화 되고, 그 중 일부만 웹 브라우저 또는 SpreadSheet를 나타는다. 비슷한 방법으로 구조화된 표현, 개인에 대한 기록, 변수를 통한 연산, 학습을 가능하게 하는 프레임워크 내에서 모든 것을 포함하는 무한한 수의 시스템이 있다. 하지만 그 중 일부만이 강력한 지능을 인스턴스화 할 수 있다. 따라서 강력한 지능을 위해서는 학습과 기호 조작을 결합한 하이브리드 아키텍쳐가 필요하다.

아래 그림은 여러 구역의 풍부한 지식을 포함한 올바른 육안적 구조를 나타낸다.

![그림 6](https://user-images.githubusercontent.com/76898072/105175571-79e8ef80-5b67-11eb-80b5-da75863d6c9b.png)
> 공간적, 물리적, 심리적, 시간적, 인과적 추론을 위한 기계를 포한하는 시스템의 필요성을 표현한 벤 다이어그램 <br>
  대부분의 현재 신경망은 이러한 형태의 추론에 대한 명백한 메커니즘과 아러한 영역에 대한 자연스러운 표현 및 추론 방법이 부족하다.

딥러닝에 대한 대부분의 현재 연구는 변수, 구조화된 표현, 개인에 대한 기록에 대한 연산을 회피하고 있다. 그리고 풍부한 인지 모델과 추론을 위한 명시적 모듈과 유사하게 대규모 추상적 지식 없이 일반적으로 수행해 왔다. 대체로 합성 인지의 기본 요소가 무엇인지에 대한 논의는 진행되지 않는다. 딥러닝은 물리적 추론을 위한 모듈처럼 보이는 것 없이 기존의 계산 정밀도 없이 달성한 것을 대부분 달성했다. 

그러나 음성 인식 및 객체 라벨링과 같은 영역에서 합리적으로 잘 작동하는 것을 가정하는 것은 오류다. 이는 대체로 분류를 중심으로 하기 때문에 언어의 이해와 상위 수준의 추론을 위해 신뢰성 있게 작동할 것이다. 현재의 딥러닝 시스템은 임의의 정보 비트 간의 끝없는 상관 관계를 학습할 수 있다. 하지만 외부 세계가 존재한다는 것을 전혀 이해하지 못해, 세계를 풍부하게 나타내지 못했다. 

> *궁극적인 일반 지능과 상식을 얻기 위한 방법은 인간 지식의 핵심 프레인워크를 나타낼 수 있는 시스템을 개발하는 것부터 시작한다. 시간, 공간, 인과관계, 물리적 개체와 개체의 상호작용에 대한 기본지식, 인간 및 인간의 상호작용에 대한 기본 지식을 고려해야한다. 이것들을 모든 종류의 지식으로 자유롭게 확장될 수 있는 아키텍처에 포함시키면서, 항상 추상화, 구성성,개인적 추적의 중심적인 프레임워크이다. 이는 복잡하고 불확실하며 하향식 및 상향식 작업을 자유롭게 수행할 수 있는 강력한 추론 기법을 개발한다. 이것은 인식, 조작, 언어에 연결 가능하고, 세계의 풍부한 인지 모델을 만들 수 있다. <br>
  그리고 마지막 핵심은 AI가 가지고 있는 모든 지식과 인지 능력을 사용하는 일종의 인간에서 영감을 받은 학습 시스템의 구축이다. 이는 AI가 학습한 것을 사전 지식으로 통합하고, 모든 정보에 출처에서 세상과 교류하고, 사람들과 교류하고, 책을 읽고, 명시적인 가르침을 받기도 하면서 배울 것이다. 이를 통해 깊은 이해를 할 수 있다.*

이것은 GPT-2와 같은 Transformer의 극적인 발전에도 불구하고 반드시 해야 할 일이다. 

## 3.2. 다른 방법

### 3.2.1 엔지니어링 실무

강건함을 얻는 것은 단지 올바른 인지적 전제조건을 개발하는 것만이 아니고, 올바른 엔지니어링 실무도 개발한다. 엔지니어링에 있어서 중복성 및 허용오차 지정과 같은 기술이 중요하다. Dietterich는 보상에 민감하도록 최적화 기능을 구축하고 모델 고장을 감지하기 위한 기계를 직접 구성하는 등 8가지를 제안하며 인과적 모델의 필요성과 중복성의 가치를 강조했다.  

### 3.2.2 문화

인지적 전제조건이나 공학적인 관행과는 무관하게 문화를 고쳐야한다. 딥러닝 커뮤니티의 어떤 요소들은 발전에 전혀 도움되지 않는다. 우리가 앞으로 나아가기 위해서는 이것을 인정하고 다루어야한다.

특히 외부 관점은 종종 지적 담론에 설 자리가 없어야 하는 일종의 극단적인 공격으로 취급된다. 발전을 위해서는 학문 간 융합이 필요한 분야에서 이러한 일이 일어난 것이다. 

> *딥러닝을 옹호하는 사람들은 종종 빅데이터에 너무 많은 투자를 한다. 복잡한 문제에 대한 해답은 항상 반복되는 데이터 세트와 더 큰 컴퓨팅 클러스터에서 찾을 수 있다. 언어학과 같은 모든 분야가 무시된것이 좋을리가 없다.*

AI의 구성 요소로서 상징 조각을 언급하는 것은 그들의 경력에 해를 끼칠 수 있다고 인식되었다. 이것은 역효과를 낳았다. 발전은 이론의 한계를 인식하는 것에 달려있다. 따라서 이러한 언급을 두려워해서는 안된다.

## 3.3. 한번에 조금씩 전체 코끼리를 보는 것

강력한 지능에 대한 문제는 아직 해결되지 않았다. 

> 딥러닝은 엄청난 양의 데이터로부터 우리에게 얼마나 많은 것을 배울 수 있는지 보여주었다. 동시 발생 통계 등은 강력한 지식의 많은 그림자중 하나에 불과하다. 그리고 정교한 기술로 그림자를 사용할 수 있을지 몰라도 한계가 명확하다.

> CYC는 풍부한 지식 기반과 풍부한 인지 모델이 존재하는 상황에서 정교한 추론의 잠재력을 보여준다. 하지만 언어 또는 지각적 입력으로부터 직접 모델을 도출할 수 없다.

> NS-CL와 같은 시스템은 상징 조작과 딥러닝이 가능하다는 것을 보여주었다. 이는 지각과 이성을 동시에 가질 수 있어서 전체로 통합된다. 

만약 저장고에서 벗어나고, 60년 동안 발전을 늦추었던 대립행위를 중단해서 세계를 연결하는 노력에 초점을 맞춘다면 좋은 결과가 있을 것이다. 다음 AI의 시련을 피하는 가장 좋은 방법은 많은 수의 기둥을 세우는 것이다. 

## 3.4. 결론, 전망 및 시사점

새로운 하드웨어, 학습 규칙, 평가 지표 및 교육 체제와 같은 주제에 초점을 맞다면 지속적인 작업이나 딥러닝을 포기할 필요가 없다. 그러나 이것은 배움에 거의 유일한 관점으로부터 배움의 변수, 사전 지식, 추론, 풍부한 인지 모델을 더 넓은 연합의 중심 구성원으로 전환시켜야 한다. 

아래의 4가지 프로그램이 중요하다.
> 하이브리드 신경전달형 아키텍쳐 초기 개발 <br>
  질 좋은 구조 참조 <br>
  부분적으로 구성된 인지 프레임워크 및 대규모 지식 데이터 베이스 <br>
  프레임워크에 대한 추상적 추론을 위한 도구 개발 <br>

위 과정은 종합적인 인지 모델의 표현과 유도를 위한 보다 정교한 메커니즘이다. 이 4가지 전제조건으로 진행된 발전은 현재 가능한 것보다 더 지능적인 시스템을 위한 기반을 제공할 수 있다. 이것는 학습 과정의 일부로 추론을 통합하는 추상적이고 언어적인 일반화의 데이터로부터 지식 및 인지 모델에 대한 접근으로 이어지는 새로운 형태의 학습으로 이어지게 될 것이다.

중요한 것은 (변수에 대한 연산, 주의 메커니즘 등을 포함하는)초기 원시 요소 집합을 먼저 식별한 다음, 원시 요소를 재결합하고 좋은 실천을 구성하는 방법을 학습해야 한다. 좋은 소프트웨어 공학의 원칙이 정해진다면 복잡한 현실세계의 능력으로 갈 수 있다. 대부분의 기계 학습 작업은 기본적으로 시작 단계를 건너 뛰어 언어 및 상위 수준의 인식에 필요한 초기 원시 요소가 무엇인지에 대한 이해를 구축하지 않고, 복잡한 문제를 경험적으로 다루려는 경향이 있다. 이러한 첫 단계를 건너뛰는 것은 지금까지 우리가 예상치 못한 상황에 대처할 수 있는 언어 이해와 신뢰할 수 있는 시스템의 구축을 방해한다.

만약 우리가 방향을 바꾸지 않는다면, AI에 대한 우리의 가장 즉각적인 걱정을 해결할 수 없을 것이다. 긴 데이터 기반 추론 및 인지 모델에 의존하는 현재의 패러다임은 우리가 믿을 수 있는 AI로 이끌지 못하고 있다. 우리는 상관관계를 위해 거대한 데이터 세트를 준설하는 것 이상을 하는 시스템이 필요하다. 안정성과 신뢰성을 확보하기 위해서 우리는 세계에 대한 풍부한 인과적 이해를 가진 시스템이 필요하다. 그리고 그것은 인과적 지식과 상세한 내부 인지 모델과 같은 추상적인 것을 어떻게 표현하고, 습득하고, 추리하는지에 초점을 맞추는 것에서 시작한다. 

---

아이들은 많은 상식을 가지고 있고, 추론할 수 있으며, 복잡한 지식을 나타낸다. 하지만 성인의 세련됨, 폭넓음, 능력을 갖추려면 아직 몇 년이 걸린다. 아이들은 정치, 경제, 사회학, 생물학, 인간 상호작용과 같은 미묘한 영역에 대해서 배워야 한다. 

안정적이게 설계를 파악하기 위해서는 인지 모델과 대규모 배경 지식을 통해 표현하고 추론해야 한다. 2.1.2에 기술된 것과 같은 하이브리드 아키텍처의 기술혁신을 활용하는 것은 중요한 단계가 될 것이며, 향후 10년의 대부분을 점유할 가능성이 있다.

이러한 중요한 인지적 전제조건의 발전은 AI가 스스로 학습할 수 있도록 만들 수 있었다. 하지만 그들이 그 자체로 완전한 인지적 존재로 거듭난다는 보장은 없었다. 어떤 면에서는 세계에 대한 불완전한 이해와 새로운 사상을 얻은 강력한 지능으로 스스로 움직이는 기계로 이어질 수 있다. 이것은 시작에 불과하지만 멀리 온 것을 단순한 전주곡처럼 보이게 할 것이다. 
