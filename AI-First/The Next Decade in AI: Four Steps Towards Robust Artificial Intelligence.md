# The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence

인공지능의 다음 10년: 강력한 인공지능을 향한 4단계

## 요약

인공지능과 기계 학습에 대한 최근의 연구는 범용 학습과 더 큰 훈련 세트 그리고 점점 더 많은 컴퓨팅을 주로 강조하고 있다.
대조적으로, 더 풍부하고 강력한 AI의 기질을 제공할 수 있는 인지 모델 중심의 복합적인 지식과 추론 기반 접근법을 제안한다.

## 1. 강력한 인공지능을 향하여

어느 누구도 향후 수십 년 동안 딥러닝이나 AI가 어떤 방향으로 진화할지는 잘 모르지만, 우리가 새로운 수준에 도달하려면 지난 10년 동안 무엇을 배웠는지, 다음에 무엇을 조사해야 하는지 모두 고려해 볼 가치가 있다.

그것을 새로운 차원의 *강력한 인공지능*이라고 부르자. 이것이 반드시 초인적이거나 자기 중심적인 것은 아니지만, *체계적이고 신뢰할 수 있는 방법*으로 넓은 범위의 문제에 그것이 알고 있는 것을 적용하는 것으로 셀 수 있다. 그리고 세계에 대해 *유연하고 역동적으로* 추론할 수 있는 다양한 출처로부터의 지식을 종합하고, 우리가 보통 어른에게 기대하는 방식으로 한 문맥에서 배우는 것을 다른 문맥으로 *옮깁니다*.

어떤 의미에서는 "초인적인" 또는 "일반적인 일반 지능"만큼 야심적이거나 제한되지 않는 작은 목표이지만, 그럼에도 불구하고 아마도 성취할 수 있는 중요한 단계일 것이다. 그리고 중요한 것은, 만약 우리가 인공지능을 만든다면 우리는 우리의 집, 우리의 길, 의사 사무실 병원, 우리의 사업, 그리고 우리의 지역사회에서 믿을 수 있습니다.

아주 간단하게, 만약 우리가 AI가 안정적으로 작동할 것이라고 기대할 수 없다면, 우리는 그것을 신뢰하지 말아야 한다. <br>
~~그 반대는 사실이 아니다. 신뢰성은 신뢰도를 보장하지 않는다. 신뢰성은 가치 및 우수한 엔지니어링 관행을 포함한 많은 요소 중 하나의 전제 조건일 뿐이다.~~

예를 들어 *narrow intelligence*와 같은 강력한 AI와 대조할 수 있다. *narrow intelligence*은 하나의 좁은 목표를 매우 잘 수행하는 시스템이다. (예: 체스 경기 또는 개 품종 식별) 그러나 종종 단일 작업 중심으로 극도로 집중되어 있고 광범위한 재교육이 없어 약간 다른 환경(예: 크기가 다른 보드 또는 한 비디오 게임에서 다른 캐릭터와 설정)으로도 강력하고 *이전할 수 없는 방식*으로 이루어진다. 이러한 시스템은 종종 그들이 훈련받은 정확한 환경에 적용될 때 인상적으로 잘 작동한다. 하지만 우리는 환경이 훈련 받은 환경과 다를 경우, 작은 방법일지라도 그들을 믿을 수 없다. 이러한 시스템은 게임의 맥락에서 강력함을 보여주었다. 그러나 아직 현실 세계의 역동적이고 개방적인 흐름에서 적절한 것으로 입증되지는 않았다.

사람들은 강력한 지능을 점묘법적 지능(표면적으로는 비슷하고 다소 예측할 수 없는 방식의 많은 경우에 작동하지만 많은 다른 경우에서는 실패하는 지능)이라고 부르는 것과 대조해야 한다.  그림 1의 왼쪽은 일반적인 스쿨버스를 인식하지만, 눈길에 전복된 스쿨버스를 인식하지 못하는 경우를 보여준다. 그리고 오른쪽은 일부 문장을 정확하게 해석하지만 관련 없는 소재가 있을 때 실패하는 읽기 시스템을 보여준다.

![그림 1: 비전 및 언어의 특이적 오류](https://user-images.githubusercontent.com/76898072/104152556-413c6e00-5423-11eb-9443-45ca1d6c8661.png)

AI 문헌을 자세히 살펴보면 누구나 처음부터 강건성이 그 분야를 벗어났다는 것을 알게 될 것이다. 그 문제에 투입된 막대한 자원에도 불구하고, 딥러닝은 지금까지도 그 문제를 해결하지 못했다.

반대로, 지금까지의 딥러닝 기술은 데이터에 굶주리고, 얕고, 취약하며, 일반화 능력이 제한적이라는 것이 입증되었다(Marcus, 2018).

> *AI의 한계 : 우리가 특정 작업에서 매우 잘 수행하는 시스템을 설계할 수 있지만, 그것들은 여전히 취약하고, 데이터에 목말라하며, 훈련 데이터나 창작자의 가정으로부터 약간 벗어난 상황을 이해할 수 없으며, 중요한 작업 없이 새로운 작업을 처리하기 위해 용도를 변경할 수 없는 뚜렷한 한계를 가지고 있다.* <br>
  \- Facebook AI 연구팀 -

> *증가하는 증거에 따르면 최신 모델은 데이터셋에서 인간이 하는 유연하고 일반화 가능한 방법으로 의미를 배우는 대신에 가짜 통계 패턴을 활용하는 법을 배우고 있다.* <br>
  \-  Yoshua Bengio - 
  
> *현재의 기계 학습 방법은 연습에서 종종 필요한 훈련 분포를 넘어 일반화해야 할 때 약하게 보인다.*

AI를 한 단계 끌어올리기 위해 우리가 할 수 있는 일은 무엇인가?

우리는 Ernie Davis가 만든 시스템을 먼저 개발하지 않고서는 강력한 지능을 달성할 수 없다. 그리고 **Deep inderstanding**이란, 복잡한 데이터 세트의 미묘한 패턴을 상호 연관시키고 식별할 수 있는 능력뿐만 아니라, 어떤 시나리오도 살펴보고 기자가 물어볼 수 있는 질문*(who, what, why, when, how)*도 해결할 수 있는 능력이다.

널리 논의된 신경 네트워크 GPT-2(이야기나 주어진 문장 조각들을 만들어 냄)와 같은 시스템은 표면적으로 깊은 이해를 반영하는 것처럼 보이는 것을 전달할 수 있다. 예를 들어, "두 명의 병사가 술집에 들어왔다"와 같은 문장 조각은 종종 유창하고 그럴듯하게 들리는 연속성(예를 들어, 사람, 술집, 술집 및 돈 사이의 관계 : 두명의 군인이 모술에 있는 술집에 들어가서 그들의 모든 돈을 술값으로 썼다.)을 만들어낼 수 있다.
하지만 아무리 많은 GPT-2 사례가 설득력 있게 보여도 현실은 그것의 표현이 얇고, 종종 면밀한 검사 아래 무너지는 경우가 많다. 다음은 2019년 12월 NeurIPS에 제시된 개발 중 벤치마크에서 도출한 두 가지 대표적인 사례이다.

 - *어제 세탁소에 옷을 맡기고 아직 가지러 가지 않았다. 내 옷들은 어디있지?*
 - *통나무 위에 개구리 여섯 마리가 있다. 두 번 떠나고, 세 번 왔다. 통나무에 있는 개구리의 수는 현재 17마리이다.*

첫 번째 GPT-2는 의문 조각(위치 기준)을 따르지만 드라이 클리닝이 있는 위치를 추적하지 못하는 요소의 범주를 정확하게 예측한다. <br>
두 번째 GPT-2는 다시 올바른 반응 범주(이 경우 숫자)를 정확하게 예측하여 세부 정보를 파악하지 못한다. <br>
Marcus에서 논의된 바와 같이 이러한 오류는 널리 퍼져 있다. 우리는 견고함을 달성하기 위해서는 분명히 더 안정적인 기질이 필요할 것이다.

관련 사업은 딥러닝 툴박스 내에서 기능 근사 및 구성을 위한 도구를 꾸준히 개선하고, 대규모 학습 세트를 수집하여 점점 더 큰 규모의 GPU 및 TPU 군집으로 확장하는 데 주력해 왔다. 더 큰 데이터 세트를 수집하고, 다양한 방식으로 데이터 세트를 보강하며, 기본 아키텍처에 다양한 종류의 개선 사항을 통합함으로써 GPT-2와 같은 시스템을 개선할 수 있다. 이러한 접근 방식은 가치가 있지만, 보다 근본적인 재검토가 필요하다.

더 많은 과감한 접근법이 추진될 수 있다. Yoshua Bengi는 딥러닝 툴킷을 대폭 확장하기 위해 여러 가지 복잡한 제안(분포 변화에 대한 민감성을 통해 통계적으로 인과 관계를 추출하는 기술 개발, 모듈형 구조를 자동으로 추출하는 기술 등)을 했다.

하지만 이것으로는 충분하지 않다. 더 강한 방법이 필요하다. 특히, 시스템을 구축하기 위한 프레임워크를 개발해야 한다. 이 프레임워크는 **복잡한 외부 세계에 대한 내부 모델 구축, 업데이트 및 추론을 위해 해당 지식을 사용하여 추상적 지식 획득, 표현 및 조작할 수 있다.**

어떤 의미에서 *지식, 내부 모델, 추론* 등 전통적인 인공지능의 세 가지 관심사로 돌아가고 있다. 그러나 현대적 기술로 새로운 방식으로 그것들을 다루기를 희망합니다.

이러한 각각의 우려의 중심은 고전적인 AI에 있다. John McCarthy는 선구적인 논문 "상식이 있는 프로그램"에서 상식적인 지식의 가치를 언급했다. Doug Lenat는 그의 삶의 작품에서 기계가 해석할 수 있는 상식적인 지식을 표현했다. Terry Winograd(구글 창업자 Larry Page, Sergey Brin의 멘토)에 의해 설계된 고전적인 AI "blocks world" 시스템 SHRLDU는 축적된 물리적 물체 세트의 위치와 특성에 대한 소프트웨어의 이해를 나타내는 업데이트 가능한 인지 모델의 내부 모델을 확인시켰다. SHRLDU는 시간이 지남에 따라 블록 세계의 상태에 대한 추론을 하기 위해 인지 모델에 대해 추론했다. <br>
~~기타 중요한 구성 요소( 간단한 물리학, 2-D 렌더러, 사용자 지정 도메인별 언어 구조 분석)는 가장 높은 피라미드의 서포트가 지원하는 가장 짧은 것이 녹색을 지원하는 것처럼 복잡한 문장들을 해독할 수 있는 것인가?~~

기계 학습에서 최신 논문의 제목을 스캔하면 이러한 종류의 아이디어에 대한 참조가 줄어든다. 소수의 사람들은 추리를 언급할 것이고, 상식을 구현하려는 욕망을 언급할지도 모른다. 이는 대부분 (반드시) 개인이나 사물, 그들의 성질 같은 사물의 풍부한 인지 모델, 그들의 관계 같은 것이 결여될 것이다.

예를 들어 CPT-2와 같은 시스템이 더 좋고 더 나쁜 것을 위해 하는 일은 어떠한 명시적 (직접 표현되고 쉽게 공유되는 의미에서의) 상식에 대한 지식 없이, 어떠한 명시적 추론 없이, 그리고 세상의 어떤 명시적 인지 모델 없이 토론하고자 하는 것이다.

많은 사람들은 이러한 노동적으로 인코딩된 명시적 지식의 부족을 장점으로 본다. GPT-2는 이례적인 것이 아니라 기존 AI의 우려에서 벗어나 딥러닝의 부활에 힘입어 더욱 데이터 중심적인 패러다임으로의 추세적 특성이다. 이러한 경향은 많이 알려진 DeepMind의 Atari 게임 시스템으로 가속화되었으며, 나중에 논의된 바와 같이 상세한 인지 모델을 사용하지 않고 다양한 게임을 하는 데 성공했다.

이러한 경향은 최근 강화학습의 창시자 중 한 명인 Rich Sutton에 의해 널리 읽혀진 **"The Bitter Lesson"** 에서 결정되었다.
이 에세이는 인간의 지식을 이용하지 말라고 분명히 충고했다.

> *70년간의 AI 연구에서 읽을 수 있는 가장 큰 교훈은 계산을 활용하는 일반적인 방법이 궁극적으로 가장 효과적이라는 것이다. 연구자들은 그 영역에 대한 인간의 지식을 활용하려고 한다. 그러나 장기적으로 중요한 것은 계산의 활용이다. 인간의 지식 접근은 계산법을 활용하는 일반적인 방법을 이용하는데 덜 적합하게 만드는 방법으로 방법을 복잡하게 만드는 경향이 있다.*

기계 학습 시스템에 인간의 지식을 쌓는 것은 기계 학습계 내에서 부정행위로 간주되어 왔고, 확실히 그렇게 바람직하지 않다. DeepMind의 가장 영향력 있는 논문 중 하나인 “Mastering the game of Go without human knowledge”의 목표는 인간의 지식을 완전히 없애는 것이었다. *"도전적인 영역에서 초인적인 숙련도를 배우다"* 최소한의 사전 제약과 대규모 집합으로부터 상식을 유도한다면 기계 학습 커뮤니티의 많은 부분집합은 매우 만족스러울 것이다. 모델 제작 역시 힘든 일이었음이 입증되었고, 일반적으로 그 단계를 생략할 수 있다면 삶이 더 쉬울 것이라는 것이었다. <br>
~~물론 맹목적으로 인간들이 말하는 모든 것을 동화시키면서 나름의 문제가 해결될 것이다. ConceptNet의 수석 유지 관리자인 Robyn Speer가 말했듯이, 우리의 야망은 더 좋아져야 한다. "우리는 단지 사람들에게 나쁘다고 해서 컴퓨터가 사람들에게 끔찍하게 되는 것을 피하고 싶다. 기술적으로만 최고가 아닌 도덕적으로도 좋은 [지식 표현]을 제공하고자 한다."~~

