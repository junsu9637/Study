# The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence

인공지능의 다음 10년: 강력한 인공지능을 향한 4단계

# 요약

인공지능과 기계 학습에 대한 최근의 연구는 범용 학습과 더 큰 훈련 세트 그리고 점점 더 많은 컴퓨팅을 주로 강조하고 있다.
대조적으로, 더 풍부하고 강력한 AI의 기질을 제공할 수 있는 인지 모델 중심의 복합적인 지식과 추론 기반 접근법을 제안한다.

# 1. 강력한 인공지능을 향하여

어느 누구도 향후 수십 년 동안 딥러닝이나 AI가 어떤 방향으로 진화할지는 잘 모르지만, 우리가 새로운 수준에 도달하려면 지난 10년 동안 무엇을 배웠는지, 다음에 무엇을 조사해야 하는지 모두 고려해 볼 가치가 있다.

그것을 새로운 차원의 *강력한 인공지능*이라고 부르자. 이것이 반드시 초인적이거나 자기 중심적인 것은 아니지만, *체계적이고 신뢰할 수 있는 방법*으로 넓은 범위의 문제에 그것이 알고 있는 것을 적용하는 것으로 셀 수 있다. 그리고 세계에 대해 *유연하고 역동적으로* 추론할 수 있는 다양한 출처로부터의 지식을 종합하고, 우리가 보통 어른에게 기대하는 방식으로 한 문맥에서 배우는 것을 다른 문맥으로 *옮깁니다*.

어떤 의미에서는 "초인적인" 또는 "일반적인 일반 지능"만큼 야심적이거나 제한되지 않는 작은 목표이지만, 그럼에도 불구하고 아마도 성취할 수 있는 중요한 단계일 것이다. 그리고 중요한 것은, 만약 우리가 인공지능을 만든다면 우리는 우리의 집, 우리의 길, 의사 사무실 병원, 우리의 사업, 그리고 우리의 지역사회에서 믿을 수 있습니다.

아주 간단하게, 만약 우리가 AI가 안정적으로 작동할 것이라고 기대할 수 없다면, 우리는 그것을 신뢰하지 말아야 한다. 
> 그 반대는 사실이 아니다. 신뢰성은 신뢰도를 보장하지 않는다. 신뢰성은 가치 및 우수한 엔지니어링 관행을 포함한 많은 요소 중 하나의 전제 조건일 뿐이다.

예를 들어 *narrow intelligence*와 같은 강력한 AI와 대조할 수 있다. *narrow intelligence*은 하나의 좁은 목표를 매우 잘 수행하는 시스템이다. (예: 체스 경기 또는 개 품종 식별) 그러나 종종 단일 작업 중심으로 극도로 집중되어 있고 광범위한 재교육이 없어 약간 다른 환경(예: 크기가 다른 보드 또는 한 비디오 게임에서 다른 캐릭터와 설정)으로도 강력하고 *이전할 수 없는 방식*으로 이루어진다. 이러한 시스템은 종종 그들이 훈련받은 정확한 환경에 적용될 때 인상적으로 잘 작동한다. 하지만 우리는 환경이 훈련 받은 환경과 다를 경우, 작은 방법일지라도 그들을 믿을 수 없다. 이러한 시스템은 게임의 맥락에서 강력함을 보여주었다. 그러나 아직 현실 세계의 역동적이고 개방적인 흐름에서 적절한 것으로 입증되지는 않았다.

사람들은 강력한 지능을 점묘법적 지능(표면적으로는 비슷하고 다소 예측할 수 없는 방식의 많은 경우에 작동하지만 많은 다른 경우에서는 실패하는 지능)이라고 부르는 것과 대조해야 한다.  그림 1의 왼쪽은 일반적인 스쿨버스를 인식하지만, 눈길에 전복된 스쿨버스를 인식하지 못하는 경우를 보여준다. 그리고 오른쪽은 일부 문장을 정확하게 해석하지만 관련 없는 소재가 있을 때 실패하는 읽기 시스템을 보여준다.

![그림 1: 비전 및 언어의 특이적 오류](https://user-images.githubusercontent.com/76898072/104152556-413c6e00-5423-11eb-9443-45ca1d6c8661.png)

AI 문헌을 자세히 살펴보면 누구나 처음부터 강건성이 그 분야를 벗어났다는 것을 알게 될 것이다. 그 문제에 투입된 막대한 자원에도 불구하고, 딥러닝은 지금까지도 그 문제를 해결하지 못했다.

반대로, 지금까지의 딥러닝 기술은 데이터에 굶주리고, 얕고, 취약하며, 일반화 능력이 제한적이라는 것이 입증되었다(Marcus, 2018).

> *AI의 한계 : 우리가 특정 작업에서 매우 잘 수행하는 시스템을 설계할 수 있지만, 그것들은 여전히 취약하고, 데이터에 목말라하며, 훈련 데이터나 창작자의 가정으로부터 약간 벗어난 상황을 이해할 수 없으며, 중요한 작업 없이 새로운 작업을 처리하기 위해 용도를 변경할 수 없는 뚜렷한 한계를 가지고 있다.* <br>
  \- Facebook AI 연구팀 -

> *증가하는 증거에 따르면 최신 모델은 데이터셋에서 인간이 하는 유연하고 일반화 가능한 방법으로 의미를 배우는 대신에 가짜 통계 패턴을 활용하는 법을 배우고 있다.* <br>
  \-  Yoshua Bengio - 
  
> *현재의 기계 학습 방법은 연습에서 종종 필요한 훈련 분포를 넘어 일반화해야 할 때 약하게 보인다.*

AI를 한 단계 끌어올리기 위해 우리가 할 수 있는 일은 무엇인가?

우리는 Ernie Davis가 만든 시스템을 먼저 개발하지 않고서는 강력한 지능을 달성할 수 없다. 그리고 **Deep inderstanding**이란, 복잡한 데이터 세트의 미묘한 패턴을 상호 연관시키고 식별할 수 있는 능력뿐만 아니라, 어떤 시나리오도 살펴보고 기자가 물어볼 수 있는 질문*(who, what, why, when, how)*도 해결할 수 있는 능력이다.

널리 논의된 신경 네트워크 GPT-2(이야기나 주어진 문장 조각들을 만들어 냄)와 같은 시스템은 표면적으로 깊은 이해를 반영하는 것처럼 보이는 것을 전달할 수 있다. 예를 들어, "두 명의 병사가 술집에 들어왔다"와 같은 문장 조각은 종종 유창하고 그럴듯하게 들리는 연속성(예를 들어, 사람, 술집, 술집 및 돈 사이의 관계 : 두명의 군인이 모술에 있는 술집에 들어가서 그들의 모든 돈을 술값으로 썼다.)을 만들어낼 수 있다.
하지만 아무리 많은 GPT-2 사례가 설득력 있게 보여도 현실은 그것의 표현이 얇고, 종종 면밀한 검사 아래 무너지는 경우가 많다. 다음은 2019년 12월 NeurIPS에 제시된 개발 중 벤치마크에서 도출한 두 가지 대표적인 사례이다.

 - *어제 세탁소에 옷을 맡기고 아직 가지러 가지 않았다. 내 옷들은 어디있지?*
 - *통나무 위에 개구리 여섯 마리가 있다. 두 번 떠나고, 세 번 왔다. 통나무에 있는 개구리의 수는 현재 17마리이다.*

첫 번째 GPT-2는 의문 조각(위치 기준)을 따르지만 드라이 클리닝이 있는 위치를 추적하지 못하는 요소의 범주를 정확하게 예측한다. <br>
두 번째 GPT-2는 다시 올바른 반응 범주(이 경우 숫자)를 정확하게 예측하여 세부 정보를 파악하지 못한다. <br>
Marcus에서 논의된 바와 같이 이러한 오류는 널리 퍼져 있다. 우리는 견고함을 달성하기 위해서는 분명히 더 안정적인 기질이 필요할 것이다.

관련 사업은 딥러닝 툴박스 내에서 기능 근사 및 구성을 위한 도구를 꾸준히 개선하고, 대규모 학습 세트를 수집하여 점점 더 큰 규모의 GPU 및 TPU 군집으로 확장하는 데 주력해 왔다. 더 큰 데이터 세트를 수집하고, 다양한 방식으로 데이터 세트를 보강하며, 기본 아키텍처에 다양한 종류의 개선 사항을 통합함으로써 GPT-2와 같은 시스템을 개선할 수 있다. 이러한 접근 방식은 가치가 있지만, 보다 근본적인 재검토가 필요하다.

더 많은 과감한 접근법이 추진될 수 있다. Yoshua Bengi는 딥러닝 툴킷을 대폭 확장하기 위해 여러 가지 복잡한 제안(분포 변화에 대한 민감성을 통해 통계적으로 인과 관계를 추출하는 기술 개발, 모듈형 구조를 자동으로 추출하는 기술 등)을 했다.

하지만 이것으로는 충분하지 않다. 더 강한 방법이 필요하다. 특히, 시스템을 구축하기 위한 프레임워크를 개발해야 한다. 이 프레임워크는 **복잡한 외부 세계에 대한 내부 모델 구축, 업데이트 및 추론을 위해 해당 지식을 사용하여 추상적 지식 획득, 표현 및 조작할 수 있다.**

어떤 의미에서 *지식, 내부 모델, 추론* 등 전통적인 인공지능의 세 가지 관심사로 돌아가고 있다. 그러나 현대적 기술로 새로운 방식으로 그것들을 다루기를 희망합니다.

이러한 각각의 우려의 중심은 고전적인 AI에 있다. John McCarthy는 선구적인 논문 "상식이 있는 프로그램"에서 상식적인 지식의 가치를 언급했다. Doug Lenat는 그의 삶의 작품에서 기계가 해석할 수 있는 상식적인 지식을 표현했다. Terry Winograd(구글 창업자 Larry Page, Sergey Brin의 멘토)에 의해 설계된 고전적인 AI "blocks world" 시스템 SHRLDU는 축적된 물리적 물체 세트의 위치와 특성에 대한 소프트웨어의 이해를 나타내는 업데이트 가능한 인지 모델의 내부 모델을 확인시켰다. SHRLDU는 시간이 지남에 따라 블록 세계의 상태에 대한 추론을 하기 위해 인지 모델에 대해 추론했다. 
> 기타 중요한 구성 요소( 간단한 물리학, 2-D 렌더러, 사용자 지정 도메인별 언어 구조 분석)는 가장 높은 피라미드의 서포트가 지원하는 가장 짧은 것이 녹색을 지원하는 것처럼 복잡한 문장들을 해독할 수 있는 것인가?

기계 학습에서 최신 논문의 제목을 스캔하면 이러한 종류의 아이디어에 대한 참조가 줄어든다. 소수의 사람들은 추리를 언급할 것이고, 상식을 구현하려는 욕망을 언급할지도 모른다. 이는 대부분 (반드시) 개인이나 사물, 그들의 성질 같은 사물의 풍부한 인지 모델, 그들의 관계 같은 것이 결여될 것이다.

예를 들어 CPT-2와 같은 시스템이 더 좋고 더 나쁜 것을 위해 하는 일은 어떠한 명시적 (직접 표현되고 쉽게 공유되는 의미에서의) 상식에 대한 지식 없이, 어떠한 명시적 추론 없이, 그리고 세상의 어떤 명시적 인지 모델 없이 토론하고자 하는 것이다.

많은 사람들은 이러한 노동적으로 인코딩된 명시적 지식의 부족을 장점으로 본다. GPT-2는 이례적인 것이 아니라 기존 AI의 우려에서 벗어나 딥러닝의 부활에 힘입어 더욱 데이터 중심적인 패러다임으로의 추세적 특성이다. 이러한 경향은 많이 알려진 DeepMind의 Atari 게임 시스템으로 가속화되었으며, 나중에 논의된 바와 같이 상세한 인지 모델을 사용하지 않고 다양한 게임을 하는 데 성공했다.

이러한 경향은 최근 강화학습의 창시자 중 한 명인 Rich Sutton에 의해 널리 읽혀진 **"The Bitter Lesson"** 에서 결정되었다.
이 에세이는 인간의 지식을 이용하지 말라고 분명히 충고했다.

> *70년간의 AI 연구에서 읽을 수 있는 가장 큰 교훈은 계산을 활용하는 일반적인 방법이 궁극적으로 가장 효과적이라는 것이다. 연구자들은 그 영역에 대한 인간의 지식을 활용하려고 한다. 그러나 장기적으로 중요한 것은 계산의 활용이다. 인간의 지식 접근은 계산법을 활용하는 일반적인 방법을 이용하는데 덜 적합하게 만드는 방법으로 방법을 복잡하게 만드는 경향이 있다.*

기계 학습 시스템에 인간의 지식을 쌓는 것은 기계 학습계 내에서 부정행위로 간주되어 왔고, 확실히 그렇게 바람직하지 않다. DeepMind의 가장 영향력 있는 논문 중 하나인 “Mastering the game of Go without human knowledge”의 목표는 인간의 지식을 완전히 없애는 것이었다. *"도전적인 영역에서 초인적인 숙련도를 배우다"* 최소한의 사전 제약과 대규모 집합으로부터 상식을 유도한다면 기계 학습 커뮤니티의 많은 부분집합은 매우 만족스러울 것이다. 모델 제작 역시 힘든 일이었음이 입증되었고, 일반적으로 그 단계를 생략할 수 있다면 삶이 더 쉬울 것이라는 것이었다. 
> 물론 맹목적으로 인간들이 말하는 모든 것을 동화시키면서 나름의 문제가 해결될 것이다. ConceptNet의 수석 유지 관리자인 Robyn Speer가 말했듯이, 우리의 야망은 더 좋아져야 한다. "우리는 단지 사람들에게 나쁘다고 해서 컴퓨터가 사람들에게 끔찍하게 되는 것을 피하고 싶다. 기술적으로만 최고가 아닌 도덕적으로도 좋은 [지식 표현]을 제공하고자 한다."

방대한 양의 데이터와 새로운 아키텍처에도 불구하고 생기는 Transformer과 같은 문제는 GPT-2의 기초가 되는 것으로서, 현대 신경망이 수집한 지식은 여전히 모호하고 점묘하다. 틀림없이 유용하고 확실히 인상적이지만 믿을수는 없다.

위의 예와 아래와 같은 GPT-2의 좀 더 명확한 테스트에는 이러한 명확성과 신뢰성이 내포되어 있다.
 - 만약 당신이 유리병을 깨뜨린다면, 물은 아마도 구를 것이다.
 - 만약 당신이 유리병을 깨뜨린다면, 물은 아마 더 깨지고 바닥에서 튈 것이다. 물은 병의 물의 양이 증가할 때 팽창하는 거품을 만든다.
 - 만약 장난감 병사가 든 유리병을 깨뜨린다면, 장난감 병사들은 아마도 그 안에서 당신을 따라갈 것이다.
 
결정적으로 인간의 지식 대신 "일반적인 방법"의 가치에 대한 Sutton의 예는 폐쇄적인 영역에서 온다(게임, 객체 분류, 음성 인식). 반면에 상식은 개방적이다. 바둑과 같은 게임에서 이기는 것은 뉴스를 해석하고 평가하거나 예상치 못한 계획 문제를 해결(지식이 없는 심층 강화 학습이 관리할 수 있는 범위를 훨씬 벗어난 것처럼 보이는 일종의 일회성 솔루션)하는 것과는 매우 다르다. 드라이 클리닝이 어디에 남아 있는지 알 수 있는 경우(앞의 예에서와 같이, *어제 나는 세탁소에 내 옷을 맡기고 아직 그것들을 가지러 가지 않았다. 내 옷 어딨어?*), 당신은 세계의 내부 모델과 시간 경과에 따라 모델을 업데이트하는 방법(몇몇 언어학자들이 말하는 *담화 업데이트 과정*)이 필요하다. GPT-2와 같은 시스템은 단순히 그것을 가지고 있지 않다.

개방형 도메인에 세계에 대한 대화 언어 이해 및 추론과 같은 컴퓨팅 파워가 적용되는 경우 일이 계획대로 되지 않는다. 결과는 항상 너무 점묘하고 모호해서 믿을 수 없다.

만약 우리가 딥러닝의 교훈을 얻는다면 우리의 시스템은 어떻게 보일까? 인간의 지식과 인지 모델은 다시 한번 인공지능을 찾는 일류의 시민이 될 수 있을까?

# 2. 지식 기반 인지 모델 기반의 하이브리드 접근 방식

많은 인지 과학자들은 인지를 일종의 순환으로 본다. 유기체(예: 인간)는 외부에서 지각 정보를 받아들인다. 그들은 그 정보에 대한 그들의 인식에 기초한 내부 인지 모델을 구축한다. 그리고 그들은 그러한 인지적 모델에 관한 결정을 내린다. 인지적 모델에 관한 결정은 외부 세계에 어떤 종류의 실체가 있는지에 대한 정보(그들의 속성, 실체들이 서로 어떻게 관련되어 있는지)를 포함할 수 있다. 인지 과학자들은 일반적으로 그러한 인지 모델이 불완전하거나 부정확할 수 있다는 것을 인식하지만, 유기체가 어떻게 세상을 보는지에 있어서 중심적인 것으로 본다. 심지어 불완전한 형태에서도, 인지 모델은 세계에 대한 강력한 지침 역할을 할 수 있다. 매우 큰 범위의 세계에서 유기체가 번성하는 정도는 그 내부 인지 모델이 얼마나 좋은가에 대한 함수이다.

비디오 게임은 기본적으로 유사한 논리에 따라 실행된다. 그 시스템은 세계의 어떤 내부 모델을 가지고 있다. 그리고 그 모델은 사용자 입력에 기초하여 주기적으로 업데이트된다. 게임의 내부 모델은 캐릭터의 위치, 캐릭터의 건강, 소지품 등을 추적할 수 있다. 게임에서 발생하는 현상(사용자가 특정 방향으로 이동한 후 충돌이 발생하는 경우 또는 없는 경우)은 해당 모델에 대한 동적 업데이트의 기능이다.

언어학자들은 보통 비슷한 주기에 따라 언어를 이해한다 : 문장의 단어들은 다양한 실체가 참여하는 이벤트와 같은 것들을 지정하는 의미론에 연결되는 구문으로 구문 분석된다. 의미론은 세계의 모델을 동적으로 업데이트하는데 사용된다(예: 다양한 실체의 현재 상태와 위치). 많은 (전부는 아니지만) 로봇 작업은 유사한 방식(인지, 모델 업데이트, 의사 결정)으로 작동한다. 

현재 논문의 가장 강력하고 가장 핵심적인 주장은 우리가 이와 유사한 것을 하지 않으면 우리는 강력한 지능을 추구하는데 성공하지 못할 것이다. 만약 우리의 AI 시스템이 세계와 세계의 역학에 대한 실질적인 지식을 바탕으로 외부 세계의 상세하고 구조화된 내부 모델을 표현하고 추론하지 않는다면, 그들은 영원히 GPT-2를 닮을 것이다 : 방대한 상관 관계형 데이터베이스를 활용하는 몇 가지 작업을 올바르게 수행할 수 있을 것입니다. 하지만 무슨 일이 일어나고 있는지 이해하지 못할 것입니다. 따라서 우리는 이러한 데이터베이스를 신뢰할 수 없습니다(특히 실제 상황이 훈련 데이터에서 벗어날 때). 
> GPT-2의 입력이 단순한 텍스트가 아닌 지각적 입력을 포함하도록 확대된다면 GPT-2가 더 잘 수행될 것인가? 그럴 수도 있지만, 단순히 입력 범위를 넓히는 것만으로는 시스템의 기본적인 연결 내부 모델 부족을 해결할 수 없다고 생각한다. 한편, 앞이 안보이는 작품들은 풍부한 내부 모델을 개발하고 언어와 그 모델들을 어떻게 연관시키는지에 대해 꽤 많이 배운다는 것은 흥미롭다.

준비 운동으로, 간단한 임무를 더 큰 도전을 위한 대역으로 간주한다. 소량의 자료에 근거하여 광범위한 일반화를 획득해야 하는 기계 학습 시스템을 구축하고 있다고 가정한다. 그리고 입력과 출력을 모두 이진수로 표시하여 소수의 훈련쌍을 얻을 수 있다.
| Input | Output |
|-|-|
| 0010 | 0010 |
| 1000 | 1000 |
| 1010 | 1010 |
| 0100 | 0100 |

어떤 사람에게든 여기에 광범위하게 적용되는 매우 중요한 일반화("규칙"이라고 함)가 있다는 것은 f(x) = x + 0와 같이 더하는 수학적 법칙과 같다. 이 규칙은 새로운 사례에 쉽게 일반화될 수 있다 [f(111) | 1111; f(10101) | 10101 등].

놀랍게도 다층 퍼셉트론과 같은 일부 신경 네트워크 구조는 딥러닝의 전형적인 예로서 최근의 교과서에 의해 기술되었고, 이것과 관련된 문제를 가지고 있다. 여기 다층 퍼셉트론, 하단의 입력, 상단의 출력, 그 사이에 숨겨진 레이어의 예가 있습니다. 신경 네트워크에 노출된 사람이라면 누구나 쉽게 알 수 있다 : 항등 함수에 대해 학습된 다층 퍼셉트론

![항등 함수에 대해 학습된 다층 퍼셉트론](https://user-images.githubusercontent.com/76898072/104171865-abb2d580-5446-11eb-998a-99660441897d.png)

이러한 네트워크는 입력을 출력에 연결하는 방법을 쉽게 학습할 수 있다. 그리고 실제로 "범용 함수 근사치"의 다양한 법칙이 이것을 보증한다. 충분한 훈련 데이터와 훈련 데이터를 통한 충분한 반복을 감안할 때 네트워크는 훈련 데이터를 쉽게 마스터할 수 있다. 

모든 것이 잘 진행되는 경우(예: 아키텍처가 제대로 설정되고 학습이 고착되는 로컬 최소값이 없는 경우), "교육 분포 내"인 예에 대해 그것은 또한 그것이 본 것들과 중요한 측면에서 유사한 다른 예들에 일반화할 수 있다.
| Test Input | 전형적인 Test Output |
|-|-|
| 1110 | 1110 |
| 1100 | 1100 |
| 0110 | 0110 |

그러나 훈련분포를 벗어나 일반화하는 것은 완전히 다른 것으로 판명되었다.
| Test Input | 전형적인 사람 반응 | 전형적인 Test Output |
|-|-|-|
| 0011 | 0011 | 0010 |
| 1001 | 1001 | 1000 |
| 1101 | 1101 | 1110 |
| 1111 | 1111 | 1110 |

이러한 예는 다층 퍼셉트론 신경망이 훈련 분포 내에 있는 사례에서 우수한 성능에도 불구하고 결국 아이덴티티 관계를 학습하지 않았음을 보여준다. 동일한 시스템이 짝수 기간 동안만 f(x) = x에 대해 교육되는 경우 수는 사람의 학습 분배권 밖에 있는 ID 기능을 홀수까지 확장하지 않습니다. 가장 오른쪽 노드를 포함한 각 출력 노드가 몇 가지 예에서 명백합니다. 맨 오른쪽을 포함해서 "1"bit를 나타낸다. 이것은 유사한 방법으로 나타내야 한다 : 우리는 가장 왼쪽의 비트를 가장 오른쪽의 숫자로 적용한다는 추상화를 취한다. 역 전파에 의해 훈련된 다층 퍼셉트론은 다른 무언가에 반응하고, 맨 오른쪽 노드는 항상 0이다. 그래서 네트워크는 가장 오른쪽 노드가 항상 0일 것이라고 계속 예측합니다. 예를 들어 입력값과 출력값에 상관없이 f(1111)=1110이다. 이 네트워크는 그 자체의 독특한 방식으로 일반화된다. 그러나 이것은 인간에게 자연스럽게 일어날 정체성 관계를 일반화시키지 않는다.

숨겨진 계층을 추가해도 네트워크 동작이 변경되지 않는다. 노드가 더 많은 숨겨진 계층 추가도 마찬가지다. 물론 특정 문제를 해결하기 위해 여러 솔루션을 함께 해킹할 수 있다(짝수에서 정체성만 학습, 이진 예제).그리고 나는 여기 간단한 정체성 예시를 오직 노출의 목적으로만 사용해왔다. 그러나 훈련 분포를 넘어 추론하는 문제는 널리 퍼져 있으며, 점점 더 많이 인식되고 있다. Joel Grus는 fizz-buzz 게임, Lake, Baroni를 통해 간단한 예시를 제공한다. 이것은 어떤 현대 자연어 시스템이 어떻게 유사한 문제에 취약한지 보여준다(추상적인 패턴을 다양한 방법으로 새로운 단어에 일반화하지 못하는 것). Bengio는 그의 최근 NeurIPS에서 중심적으로 현존하는 신경 네트워크의 능력에 제한을 두었다. 표준 신경 네트워크 아키텍처 내에서 광범위한 보편성의 불균일 확장(예: 정체성)은 놀라울 정도로 일반적이다. 그리고 내가 보기에 그것은 진보의 중심 장애물로 남아 있다.

본질적으로 특정 종류의 확장된 신경 네트워크(예: 여기서 논의된 역전파로 훈련된 다층 퍼셉트론)는 두 가지에 탁월하다 : 암기 훈련 사례, 초차원 공간의 일부 클러스터(교육 공간 내 일반화라고 함)에서 이러한 예들을 둘러싸는 점들의 클라우드 내 덧붙인다. 그러나 그들은 훈련 공간 밖에서 잘 일반화되지 않는다.

![다층 퍼셉트론](https://user-images.githubusercontent.com/76898072/104183170-e3287e80-5454-11eb-8810-70ea56aac85c.png) <br>
*다층 퍼셉트론 : 훈련 사례의 공간 내에서 일반화하는 데 능숙하며, 훈련 사례의 공간 밖에서 아이덴티티 기능을 일반화하는 데 서투르다.*

결과적으로 두 가지 밀접하게 관련된 문제가 발생한다.
1. **특이성**
교육 사례의 공간을 넘어서는 확실한 일반화 방법이 없는 시스템은 개방형 도메인에서 신뢰할 수 없다. 각 개별 시스템을 함수 근사치로 생각한다면 현재 널리 사용되는 시스템은 암기된 예제를 잘 하는 경향이 있으며, 교육 예와 유사한 예제를 많이(전부는 아니지만) 잘하는 편이다. 이는 분류를 중심으로 하는 많은 응용 프로그램에 유용하지만 훈련 분포를 벗어나면 열악하다. 예를 들어 최근의 수학 학습 시스템에서 1+1=2, 1+1+1=3 ~ 1+1+1+1+1+1=6은 잘 된다. 하지만 1+1+1+1+1+1+1+1=7 및 모든 더 큰 예에서 떨어졌다. (7 미만의 카운터 값에 대해서만 실행을 신뢰할 수 있는 컴퓨터 프로그램에서 FOR 루프를 작성하는 것을 상상해 보자) 이에 비해 유도 프로그램 합성을 기반으로 하는 상징적인 시스템인 Microsoft Excel의 Flash fill은 이러한 다양성의 많은 경우에 훨씬 더 효과적이다. 

2. **학습 제도의 정확한 세부 사항에 대한 과도한 의존성**
모든 정상적인 인간 학습자들이 매우 다양한 환경에도 불구하고 그들의 모국어와 세계에 대한 이해를 얻는 반면, 신경 네트워크들은 종종 훈련 항목이 제시되는 순서와 같은 정확한 세부사항에 꽤 민감하게 반응하는 경향이 있다(신경망을 위한 "기술"에 관한 문헌을 참조). 마찬가지로, 신경 네트워크는 30년 동안 이전의 연관성이 후대의 연관성에 의해 덮어쓰는 치명적인 간섭으로 알려진 문제에 취약하다는 것이 알려져 왔다. 항목을 표시하는 순서에 매우 민감하게 만드는 잠재적인 솔루션은 정기적으로 계속 제안되지만 문제는 남아 있다. 마찬가지로 최근 한 신문에 따르면 "네트워크가 보여주는 일반화의 정도는 주어진 작업이 예시화된 환경의 세부 사항에 따라 결정적으로 좌우될 수 있다."

훈련 분포를 넘어 추론할 수 없는 특이성과 무능은 우리의 상식적인 지식의 많은 일반성과 대립한다. 이것은 또한 인과관계를 헤아리기 어렵게 만든다. Pearl과 Mackenzie를 참조하라. 
도입부에서의 예를 확장하면 대부분의 일반 성인과 아이들은 다음과 같은 추상적이고 인과적인 일반화가 사실이라는 것(특정 경험에서 유도하는 것으로 추정)을 인식할 것이다 :
*액체가 들어 있는 병을 깨뜨린다면, 액체의 일부는 아마 그 병에서 빠져나올 것이다.*

그러한 진실은 단지 몇 개의 특정 품목뿐만 아니라 병의 색이나 모양 또는 크기, 음료의 종류에 관계없이 기본적으로 개방된 대형 실체 등급에 대해 보유한다는 점에서 추상적이다. 비록 깨진 병에 대한 우리의 이전의 경험이 거의 오로지 액체를 포함한 병에 관련되었다 하더라도 우리는 볼베어링이나 게임 주사위를 포함한 병에 대해서도 유사한 일반화를 유지할 것으로 예상한다.  

거의 모든 사람들이 다음과 같은 일반화를 신뢰할 수 없다고 생각할 것이다: 
*액체가 들어 있는 병을 깨뜨린다면, 액체의 일부는 아마도 300 미터 떨어진 곳에서 감겨질 것이다.*

개인의 경험과 상관없이 우리는 소형 및 대형 병 모두 해당 청구가 사실일 가능성이 낮다는 점을 인식하여 많은 방법으로 이전에 접한 병보다 훨씬 작거나 큰 병들에 대한 이 지식을 넓힐 수 있다. 

어떻게 우리가 이런 의미에서 특정 실체뿐만 아니라 모든 계급에 관계되는 추상적인 지식을 표현하고 조작하고 이끌어 낼 수 있는가? 대립법의 어려움은 역전달 훈련을 받은 다층 퍼셉트론과 같은 일반적인 도구가 작업에 적합한 도구가 아니라는 것을 의미한다. 대신에 추상적인 지식을 배우고, 표현하고, 확장하기 위한 대체 메커니즘을 찾는 것이 필수적이다.

## 2.1. 하이브리드 아키텍쳐

### 2.1.1 변수에 대한 기호 연산은 오직 알려진 솔루션을 제공하지만 부분적으로만 제공된다.

변수에 대한 상징적 연산이 하나의 잠재적 해답을 제시한다. 항상 사용되는 솔루션으로서, 사실상 전 세계 모든 소프트웨어의 기반이 되고 있습니다.
사실상 모든 컴퓨팅 프로그램 아래에 있는 네 가지 기본 아이디어 : 변수, 예시, 예시에 변수를 연결하는 바인딩 및 변수에 대한 연산이 포함된다.

이러한 각각의 아이디어는 x와 y와 같은 실체가 변수인 기본 대수학에서 친숙하다. 특정 숫자(2, 3.5 등)는 해당 변수가 구속될 수 있는 예시다(예: x는 현재 3과 동일할 수 있음). 운영에는 추가 및 곱셈과 같은 것들이 포함된다. 이것는 특정 클래스의 모든 값(예: 모든 숫자)으로 자동으로 확장되는 관계를 나타내는 것을 가능하게 합니다. 변수를 인스턴스에 연결하는 프로세스를 변수 바인딩이라고도 한다.

물론 컴퓨터 프로그램은 같은 기반 위에 만들어진다. 알고리즘은 주로 변수에 대해 수행되는 운영 측면에서 지정된다. 변수는 인스턴스에 바인딩되고, 알고리즘은 호출되고, 연산이 수행되고, 값은 반환된다.

중요한 것은 핵심 연산은 일반적으로 일부 클래스의 모든 인스턴스(예: 모든 정수, 모든 문자열 또는 모든 부동 소수점 번호)에 적용되는 방식으로 지정된다. 핵심 연산에는 일반적으로 산술 연산(덧셈, 곱셈 등), 비교 사항(x의 값이 y 값보다 크다), 제어 구조(현재 변수 n이 어떤 값에 속하게 되는가에 대해 여러 번 실행한다 : x의 값이 y의 값을 초과하는 경우 대안 a를 선택하고, 그렇지 않은 경우 대안 b 등을 선택한다)와 같은 기본 사항이 포함된다. 첫 번째 근사치(버그 무시, 프로그래머 논리 오류 등)에 대해, 이것은 적절하게 구현된 함수가 어떤 입력에 노출될 수 있거나 노출되지 않았을지 완전히 독립적으로 어떤 클래스의 모든 입력에 대해 작동한다는 것을 의미한다.

작동 측면에서 정의되는 기능적 측면으로 사물을 정의하는 이러한 접근 방식은 표준 기계 학습과는 완전히 다른 패러다임이라는 점에 유의할 필요가 있다. 기계 학습 시스템은 일반적으로 입력 변수와 출력 변수에 관련된 대략적인 함수를 학습한다. Judea Pearl은 곡선 맞춤에 비유한 프로세스를 통해 일반적으로 변수에 대한 운영 측면에서 훈련 데이터와 독립적으로 알고리즘을 *정의*한다. 이것은 전통적인 컴퓨터 프로그래머들에게 운영 체제에서 웹 브라우저, 비디오 게임, 스프레드시트에 이르는 모든 기능 지원 등 좋은 서비스를 제공해 왔다.

결정적으로 변수에 대한 시스템의 핵심 운영은 일반적으로 *경험과 무관*하게 체계적으로 작동하도록 구축된다. 예를 들어 마이크로프로세서의 *원형 비트 시프트 작동 메커니즘*은 마이크로프로세서 워드 폭까지 각 비트마다 하나씩 일련의 병렬 하위 연산에 의해 정의된다 : 연산은 이전에 사용된 적이 있는지 여부와 상관없이 동일하게 작동하며 학습이 필요하지 않는다. 프로그래머는 경험에 관계 없이 시프트 조작이 작동하리라는 것을 안전하게 예측할 수 있고, 앞으로도 그럴 것이다. 모든 기계의 장점(변수, 인스턴스, 바인딩, 운영)은 프로그래머가 특정 추상화 수준에서 특정 종류의 신뢰도를 부산물로 지정할 수 있도록 한다.

일괄적으로 변수에 대한 네 가지 가정(변수, 바인딩, 인스턴스, 운영)은 *기호-변환*의 핵심을 구성한다. (기호 그 자체는 단순히 다른 시스템에서 사용할 수 있는 인코딩 방식이다. 예를 들어 ASCII 코드에서 문자를 나타내기 위해 사용되는 이진수의 패턴 또는 신경 네트워크에서 출력 노드가 특정 단어를 나타낼 수 있도록 하는 인코딩과 같은 것이다.) 일부 기호 조작 시스템에는 추가, 연결, 비교와 같은 적은 수의 운영만 있을 수 있을 수 있다. 다른 것들은 마이크로프로세서가 핵심 명령 집합의 크기에 따라 달라질 수 있는 것처럼 더 풍부한 연산(예: 복잡한 논리 공식의 통일)을 가질 수 있다. 재귀는 기호를 조작하는 아키텍처를 기반으로 할 수 있지만 절대적인 논리 요구 사항은 아니다.

아이가 추상적인 언어 패턴을 배울 때처럼 어떤 형태로든 상징 조작은 인간의 인식에 필수적인 것처럼 보인다. 이것에 대한 가장 설득력 있는 증거들 중 일부는 나와 내 동료들이 7개월 된 유아들이 단순한 추상적인 패턴을 인식할 수 있다는 것을 보여준 1999년 연구에서 나왔다. 예를 들어 데이터의 ABB 패턴과 같이 일련의 훈련 예제를 넘어 음성학적으로 그들의 훈련 세트와 겹치지 않는 다른 음절로 구성된 새로운 문자열로 그것들이 추론된다. 후속 연구는 심지어 신생아들도 이런 종류의 추론을 할 수 있는 것처럼 보인다는 것을 보여준다. Gallistel과 King은 변수의 저장과 회수가 동물 인식에 필수적이라고 주장해왔다. 예를 들어 꿀벌은 태양 방위 기능을 아직 노출되지 않은 조명 조건까지 확장할 수 있는 것으로 보인다.

기호 조작의 다재다능한 기계 또한 구조화된 표현을 위한 기초를 제공한다. 예를 들어 컴퓨터 프로그래밍은 일반적으로 변수에 대한 연산을 통해 조합된 기호로 구성된 트리 구조를 사용하여 다양한 항목(예: 계층 구조 폴더 또는 디렉토리)을 나타낸다.

마찬가지로, 기호 조작 기계는 시간이 지남에 따라 변하는 개인의 속성을 추적할 수 있다(예: 데이터베이스 기록의 형태). 이러한 능력은 인간의 언어(재귀적인 문장 구조에서처럼)와 시간이 지남에 따라 변화하는 개인과 사물에 대한 우리의 지식에서 중점적으로 보인다. 

그러한 기계는 압도적으로 강력하다. 세계의 모든 웹 브라우저, 세계의 모든 운영 체제, 세계의 모든 앱 등이 그 위에 구축되어 있다. (동일한 도구가 세계의 거의 모든 신경 네트워크의 규격과 실행에 사용되기도 한다.)

그러나 역사적으로 주류인 딥러닝은 신경망이 왜 고전적인 패러다임에 대한 대안을 제공하는지에 대한 규명의 일환으로 상징-조작 기계 없이 대부분 의도적으로 회피하려고 했다. 현대의 많은 딥러닝을 예측했던 유명한 PDP 책에서 Rumelhart와 McClelland는 기호 조작을 "인간 연산의 본질은 아니다"라는 한계적 현상으로 치부했다. 2015년 Hinton은 인공 지능의 구성 요소로서의 상징적 논리의 추구는 "광채 에테르"에 상징을 비유했다.

> 광파가 발광 에테르에 장애를 일으켜야만 우주를 통과할 수 있다는 믿음만큼 부정확하다. 필요한 속성을 가진 유일한 시스템과의 강제적이지만 부정확한 유사성으로 인해 현혹되었습니다.

개인들을 위한 데이터베이스식 기록과 같은 아이디어들은 신경 네트워크에서의 작업의 엄청난 우세함에서 제외되어있다. 그리고 계층 구조화된 문장과 같은 복잡한 구조화된 표현은 연구의 극히 일부에서만 발견된다. 반면 입력과 출력의 표준은 단순 벡터 또는 2차원 비트맵이다. 그리고 연구 대상자를 위한 계층적 데이터 구조 및 기록은 피했다. 
> DeepMind의 새로운 MEMO 아키텍처는 레코드 데이터베이스를 대표한다

이런 식일 필요 없다. Fodor와 Plyshyn이 도입한 용어 "실현적 연결주의"를 사용하여 호환 가능한 신경망을 구축 할 수도 있다. 그리고 기호-조작 원칙("제거적 연결주의")에 구애받지 않고 작동하는 Marcus 또는 신경망에 의해 채택되었다. 지금까지의 대부분의 작업은 제거주의적인 다양성이었다. 그러나 그 우세는 논리의 필요성이 아닌 사회학적 사실을 반영한다.

나는 몇년 안에 많은 사람들은 딥러닝이 기호 조작 없이 오랫동안 해온 많은 일들을 궁금해 할 것이라고 예상한다. 사실상 인류의 모든 위대한 공학적 업적은 어떤 상징적 추론에 의존해 왔다. 그리고 인간이 일상에 그것들을 사용한다는 증거는 많다. 새로운 것의 힌트와 함께 광범위한 실용주의가 변화하기 시작했다. 
> 독단주의를 극복하기를 바라는 광범위한 실용주의

이 에세이의 첫 번째 주요 문장은 다음과 같다 : **AI에 대한 강력한 지식 기반 접근 방식을 구축하려면 툴킷에 기호 조작 장치가 있어야 한다.** 추상화를 표현하고 조작하는 도구 없이 만들기에는 너무 많은 유용한 지식이 추상적이다. 그리고 현재까지 우리가 알고 있는 그런 추상적인 지식을 믿을 수 있게 조작할 수 있는 유일한 기계는 상징 조작 장치이다.

변수들에 대한 운영 장치는 스스로 학습에 대해 아무 것도 말하지 않는다. 
> 유도 논리 프로그래밍은 현재 논문의 범위를 벗어나지만 어느 정도 고려할 가치가 있는 학습에 대한 완전한 규칙 기반 접근법이다.

여기서부터 심볼 조작과 딥러닝과 같은 다른 기술을 결합한 하이브리드 아키텍처의 기본적 필요성이 가장 근본적으로 대두된다. 특히 대용량 데이터셋에서 기호 조작이 추상화를 표현하고 조작하는 표준을 설정하며 딥러닝의 학습 기준을 높였다.  우리가 그 두 개(또는 그와 비슷한 것)을 하나로 모을 필요가 있는 것은 분명하다. 
> 강력한 지능은 상징적 운영을 기계 학습 메커니즘과 결합하는 일종의 하이브리드에 의존할 것이다. 딥러닝이 데이터 및 에너지 사용 측면에서 지배적인 기계 학습 메커니즘의  마지막 열할을 수행하거나 후계자의 역할을 수행할 것인지의 여부는 확실하지 않다. 통계적 관계 학습 및 확률적 프로그래밍과 같은 접근법은 연구할 가치가 있다.

### 2.1.2 하이브리드는 종종 효과적이다

하이브리드는 새로운 것이 아니다. Pinker와 나는 30년 전에 어떻게 아이들이 영어 과거시제를 배웠는지에 대한 가장 좋은 설명은 하이브리드와 관련이 있다고 제안했다. 이 하이브리드는 정규 동사의 과거 시제를 형성하기 위한 규칙과 불규칙 동사를 획득하고 검색하기 위한 신경 네트워크 같은 시스템이다. 그리고 상징적 지식과 지각적 지식을 결합하는 것은 오랫동안 명백하게 요구되어 왔다. (예를 들어, 말이 어떻게 생겼는지에 대한 지각적 지식과 얼룩말을 줄무늬가 있는 말과 비유하는 언어적 정의를 결합하여 얼룩말을 인식는 것이 있다.)
> 기존의 제로샷 학습 문헌은 다양한 형태의 다중 모델 지식을 통합하려고 노력해왔다. 하지만 현재 시스템은 사전 정의에서 찾을 수 있는 정확한 정보를 활용할 수 없다.
Ron Sun과 같은 컴퓨터 과학자들은 1990년대 내내 하이브리드 모델을 지지했다. Shavlik은 (제한적인)논리의 부분집합을 신경망으로 변환하는 것이 가능하다는 것을 보여주었다. D’Avila Garcez, Lamb, Gabbay는 신경증 치료 접근법에 대한 중요한 초기 연구를 진행했다. 심지어 Hinton도 한때 하이브리드를 지지했다. 하지만 초기 하이브리드 접근 방식은 큰 관심을 끌지 못했다. 그 당시의 결과는 설득력이 없었다(아마도 일부 이유는 TPU 이전의 신경 네트워크 자체가 그 당시 저전력이었기 때문일 것이다.). 그리고 신경 네트워크 커뮤니티는 종종 하이브리드와 기호조작과 관련된 모든 것을 무시한다. 최근까지 하이브리드는 역사적으로 상징적인 접근과 신경적인 접근 사이의 교차에 휘말려왔다. 

상징 조각 세계와 딥러닝 분야 사이의 오랜 갈등의 해소가 다가오고 있다. 예를 들어 Yoshua Bengio는 일부 초기 컴퓨터 언어에서 사용된 표준 기호 조정 기술의 변수들을 이름으로 전달할 수 있는 기술들을 통합하는 것에 대해 이야기했다. 그리고 실제적인 필요와 새로운 접근법의 개발을 위해 노력하며 기호와 신경망을 더욱 가깝게 만들기 위해 적극적이게 되었다. 

구글 검색과 같은 세계의 AI 시스템의 일부는 기호 조정 작업과 딥러닝을 혼합한 하이브리드이다. 구글 검색은 강력한 인공지능은 아니고, 높은 정확도로 엄청난 양의 작업을 수행하는 효과적인 AI 기반 정보 검색 시스템이다. 구글 검색의 설계자들은 이것을 고도의 데이터 중심적인 방법으로 광범위하게 최적화했고 현재 신경 네트워크 커뮤니티의 도구(BERT, RankBrain)와 전통적인 기호 조작 AI의 기술(구글 지식 그래프)을 혼합하여 최고의 결과를 얻고 있다. 구글은 무엇이 광범위한 규모로 잘 작동하는지를 보기 위해 거대한 경험적 실험을 한다. 그리고 그들이 여전히 구글 지식 그래프를 사용한다는 사실은 학문이 중요한 시대에도 기호와 하이브리디의 가치에 대해 말해주는 것이다. (다양한 구성 요소의 상대적 강점과 약점에 대한 자세한 논의는 알지 못한다.)

AlphaGo는 Monte Carlo 트리 검색(동적으로 구성되고 상징적으로 표현된 검색 트리에서의 횡단 및 평가)와 다양한 위치의 가치를 추정하기 위한 다양한 딥러닝 모듈을 결합한 것이다. 딥러닝 하나는 프로세스의 약한 기능이다. 

OpenAi의 Rubik은 루빅 큐브의 인지적 측면을 해결하기 위한 상징적 알고리즘의 혼합체이다. 그리고 수동 조작 측면에 대한 심층 강화 학습이다. 

Mao, Gan, Kohli, Tenenbaum은 그들이 조사한 딥러닝 대안을 능가하는 작은 규모의 NS-CL(Neuro-Symbolic 개념 학습자의 줄임말)이라고 하는 시각적 질문 답변을 위한 하이브리드 신경망 기호 시스템을 최근 제안했다. 이는 비교 가능한 순수 블랙박스 딥러닝 접근방식을 훨씬 능가하는 예측과 물리학 기반 계획을 수립하기 위해 개별 객체에 대한 명시적 기록을 쌍으로 묶는다. Evans와 Grefenstette는 다층적 퍼셉트론에 반항하는 하이브리드 모델이 다양한 학습 과제를 더 잘 포착할 수 있는 방법을 보여주었다. Smolensky와 Schmidhuber의 팀은 BERT와 텐서 제품을 결합함으로써 수학 문제집합에서 더 나은 새로운 시스템(TP-Transformer, 기호 변수와 그 구속력을 나타내는 공식 시스템)을 만들어냈다.

신경 상징 모델에 대한 기초적인 작업은 상징 시스템과 신경 네트워크 사이의 연결을 조사한 것이다. 이것은 전통적인 신경 네트워크에서 나타낼 수 있는 지식의 종류에 중요한 한계를 보여주었다. 그리고 표현 및 추론 능력 측면에서 혼합 시스템(핵심 및 신경 네트워크) 구축의 가치를 입증했다. 첫 번째 근사치로는 기존의 신경망이 제안 논리를 위한 엔진으로 생각될 수 있다. 미적분학에서 알 수 있듯이 정량화된 진술을 표현할 수 있는 좋은 방법은 없다. 따라서 논리 텐서 네트워크는 심층 텐서 신경 네트워크에서 형식 논리를 구현하는 것을 목표로 한다.

> Vergari <br>
  통계적 관계 학습은 논리적 추상화 및 관계를 확률과 통계와 결합하는 것을 목표로 하는 또 다른 접근 방식 연구 <br>
  Domingo
  Markov 논리 네트워크로 기호 조작과 기계 학습의 장점을 결합 연구
  Arabshaghi
  스택 역할을 하는 외부 메모리에 의해 트리 LSTM이 증강되는 방법 연구
  Fawzi
  최근 다항식 부등식의 증거를 찾기 위한 하이브리드 시스템을 제시
  Minervini
  최근 대규모 데이터베이스에서 작동하는 GNTP(Gready Neural Organization Provider)라고 하는 하이브리드 신경 상징 추론 시스템을 제시
  Battaglia
  상징적인 그래프와 딥러닝을 통합하는 시스템과 함께 물리적인 추론 연구
  Allen의 AI연구소 ARISTO
  8단계 과학 검사에서 가른 시스템보다 우수한 다중 파트 하이브리드 복합시설

이 모든 것들은 빠르게 성장하는 분야의 몇가지 예시일 뿐이다. 가장 좋은 이론을 내놓기에는 너무 이르다.  질 나쁜 대규모 데이터 셋에서 추상적인 지식을 추출하고 일반화하여 더 나은 기술 개발을 위하여 상징적 접근법의 강점과 기계 학습의 통찰력을 결합하는 아키택처를 구축하기 위한 많은 단계가 있다. 

### 2.1.3 하이브리드 모델 및 기호 조작에 대한 일반적인 반대

하이브리드 모델 조사에 대한 관심과 다양한 고려 사항에도 불구하고 기계 학습 커뮤니티의 일부에서 기호 표시에 대한 반대가 존재한다.
> *하이브리드 모델에 대한 유럽의 투자는 "큰 실수"가 될 것이다. 하이브리드 모델의 연구는 전기 자동차 시대에 구식 가솔린 엔진의 사용과 같다.*
  \- Geoffrey Hinton -
  
그러나 Hinton은 왜 그가 부분적으고 상징적인 하이브리드 모델을 반대하는지에 대해 최근 몇 년간 장황한 글을 쓰지 않았다.

다음은 다른 사람들로부터 들은 일반적인 몇 가지 반대 의견과 각 의견에 대한 간략한 답변이다. 

- **기호는 생물학적으로 타당하지 않다.**
> 1. 우리가 아직 상징 조절을 지원하는 신경 메커니즘을 결정적으로 식별하지 않았다고 해서 우리가 결코 그렇지 않을 것이라는 것을 의미하지는 않는다. 일부 유명한 신경 기질은 이미 확인되었다. 그리고 다른 문헌들은 이론적으로 그럴듯한 신경 기판을 가리켰다. 어떤 설득력 있는 근거도 그러한 메커니즘이 단순히 뇌와 비슷한 존재가 될 수 없다는 것을 보여준다. 예를 들어 단일 뉴런 네에서 활동할 수 있는 기호 조작의 중심인 변수의 값 저장 및 검색이 있다. 
  
  2. 2.1.1에서 확인한 많은 심리학적 증거는 기호 조작이 뇌에서 인스턴트화 된다는 개념을 뒷받침한다. 새로운 아이템으로 새로운 추상적인 패턴을 확장시키는 유아들의 능력과 같은 것과 그들이 적접 정보를 가지고 있지 않은 비원음들로 추상적인 언어 패턴을 일반화하는 성인들의 능력 등이 있다. 인간은 상징적으로 표현된 표현된 컴퓨터 프로그램을 프로그래밍히고 디버깅 하면서 외부로 표현된 상징물에 형식논리를 적용하는 것을 배울 수 있다. 이 모든 것은 적어도 어떤 구성에서 (부분적인 메모리 제한에 의해) 실제로 신경 두뇌가 기호를 조작할 수 있다는 것을 보여준다. 그리고 우리는 언어를 본질적으로 무한한 다양성으로 이해할 수 있고, 끝없는 문장의 범위에서 무한한 범위의 의미를 추론할 수 있다. 변수에 대한 연산의 특징인 자유 일반화의 종류는 인식 전체에 걸쳐 널리 퍼져 있다.
  
  3. 신경실현의 현존하는 증거의 부족은 우리에게 거의 아무것도 말해주지 않는다. 우리는 현재 Kasparov 수준의 체스가 어떻게 뇌에서 구현될 수 있는지에 대한 자세한 이해가 없다. 그러나 그것이 Kasparov의 체스놀이가 신경이 아닌 메커니즘에 의존했다는 것을 의미하지는 않는다.
  
  4. 비록 뇌가 기호를 조작하는 기계를 사용하지 않는 것으로 밝혀졌다고 해도, 왜 AI가 그러한 메커니즘을 이용하지 못하는지에 대한 원칙적인 주장은 없다. 인간에게는 부동 소수점 사술 칩이 탑재되어 있지 않지만 이것은 인간이 AI에 길들여져야 한다는 것을 의미하지 않는다. 
   
- **과거에는 상징적인 시스템과 하이브리드 시스템이 제대로 작동하지 않았다.**
> 나는 종종 이것들을 들은 적 있지만, 이것은 이상한 주장인것 같다. 하이브리드 모델을 입증할 수 없거나 구식으로 묘사하는 것은 정확한 것이 아니다. 실제로 하이브리드 모델에 대한 적극적이고 효과적인 연구가 진행 될 때는 2.1.2 절에 기술되었다. 

  > 과거에

### 2.1.4 지정된 시스템이 하이브리드 시스템인지 여부를 확인하는 것이 항상 사소한 것은 아니다.

### 2.1.5 요약

특정한 변수에 대한 운영 체계의 기호 조작은 훈련 체제를 넘어서 추정하는 도전에 대해 자연스럽지만 불완전한 해결책을 제공한다 : 변수에 대한 연산 측면에서의 알고리즘을 나타낸다. 그리고 이것은 본질적으로 어떤 클래스의 모든 인스턴스로 확장되도록 정의될 것이다. 그리고 구조화된 표현(예: 생성 언어학에서 기초가 되는 나무 구조)과 개인 및 그 속성에 대한 기록을 나타내기 위한 명확한 근거를 제공한다. 신경 세포 조직의 한 구획을 XOR을 계산할 수 있다. 이것은 개별 뉴런이 종종 추정되는 것보다 휠씬 더 정교할 수 있는 가능성을 높여준다. 

무언가 부족한 것은 학습을 위한 만족스러운 틀이다. 하이브리드는 양쪽 세계의 최고를 결합하는 방법이 될 수 있다 : 딥러닝의 본보기가 되듯이 대규모 데이터 세트에서 학습할 수 있는 능력은 세계 모든 컴퓨터 프로그래밍 언어의 의미적으로 통용되는 추상적 표현을 표현할 수 있는 능력을 갖추고 있다. 나는 그것들이 강력한 지능에 안전하게 도달하기 위한 전제 조건이라고 추측한다. 인간은 분명히 어떤 형태의 가변 구속 조건이 전제조건이 된다면 단기기억을 즉시 회수해서 한번에 쓰는 메커니즘을 가지고 있다. 하지만 우리는 관련 메커니즘이 무엇인지 모른다. 이것은 우리가 AI에 그런 메커니즘을 사용해서는 안된다는 것을 의미하지는 않는다. 

하이브리드 모델의 우주를 연구하는 데 투입된 리소스는 기호 조작을 회피하는 "순수한" 딥러닝 시스템에 투입된 리소스보다 훨씬 적다. 그러나 2.1.2절에서 검토된 작업의 증가 중 다양한 구글 검색 연구소에서의 모두 하이브리드 아키텍처에 대한 연구 가치는 말할 것도 없다.

아직 우리는 어려움에서 벗어나지 못했다. 강력한 데이터 중심 학습 기법과 대표성을 결합한 하이브리드 모델과 기호 표시의 계산 자원은 강력한 지능을 위해 필요할지도 모른다. 그러나 확실하지는 않다. 다음에 이어지는 내용에서 세 가지 추가 연구 과제를 설명하겠다.

## 2.2. 대규모 지식 중 일부는 추상적이고 인과적이다.

### 2.2.1 강력한 인공지능은 어떤 종류의 지식을 필요로 하는가?

### 2.2.2 사례연구: 컨테이너

### 2.2.3 타고난 지식 체계

## 2.3. 추론

## 2.4. 인지 모델

# 3.토론

## 3.1. 지속적이고 추상적인 지식을 바탕으로 한 지능을 지향한다.

## 3.2. 다른 방법이 없을까?

### 3.2.1 엔지니어링 실무

### 3.2.2 문화

## 3.3. 한번에 조금씩 전체 코끼리를 보는 것

## 3.4. 결론, 전망 및 시사점

# 4. 감사
