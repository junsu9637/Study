# The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence

인공지능의 다음 10년: 강력한 인공지능을 향한 4단계

## 요약

인공지능과 기계 학습에 대한 최근의 연구는 범용 학습과 더 큰 훈련 세트 그리고 점점 더 많은 컴퓨팅을 주로 강조하고 있다.
대조적으로, 더 풍부하고 강력한 AI의 기질을 제공할 수 있는 인지 모델 중심의 복합적인 지식과 추론 기반 접근법을 제안한다.

## 1. 강력한 인공지능을 향하여

어느 누구도 향후 수십 년 동안 딥러닝이나 AI가 어떤 방향으로 진화할지는 잘 모르지만, 우리가 새로운 수준에 도달하려면 지난 10년 동안 무엇을 배웠는지, 다음에 무엇을 조사해야 하는지 모두 고려해 볼 가치가 있다.

그것을 새로운 차원의 *강력한 인공지능*이라고 부르자. 이것이 반드시 초인적이거나 자기 중심적인 것은 아니지만, *체계적이고 신뢰할 수 있는 방법*으로 넓은 범위의 문제에 그것이 알고 있는 것을 적용하는 것으로 셀 수 있다. 그리고 세계에 대해 *유연하고 역동적으로* 추론할 수 있는 다양한 출처로부터의 지식을 종합하고, 우리가 보통 어른에게 기대하는 방식으로 한 문맥에서 배우는 것을 다른 문맥으로 *옮깁니다*.

어떤 의미에서는 "초인적인" 또는 "일반적인 일반 지능"만큼 야심적이거나 제한되지 않는 작은 목표이지만, 그럼에도 불구하고 아마도 성취할 수 있는 중요한 단계일 것이다. 그리고 중요한 것은, 만약 우리가 인공지능을 만든다면 우리는 우리의 집, 우리의 길, 의사 사무실 병원, 우리의 사업, 그리고 우리의 지역사회에서 믿을 수 있습니다.

아주 간단하게, 만약 우리가 AI가 안정적으로 작동할 것이라고 기대할 수 없다면, 우리는 그것을 신뢰하지 말아야 한다. <br>
~~그 반대는 사실이 아니다. 신뢰성은 신뢰도를 보장하지 않는다. 신뢰성은 가치 및 우수한 엔지니어링 관행을 포함한 많은 요소 중 하나의 전제 조건일 뿐이다.~~

예를 들어 *narrow intelligence*와 같은 강력한 AI와 대조할 수 있다. *narrow intelligence*은 하나의 좁은 목표를 매우 잘 수행하는 시스템이다. (예: 체스 경기 또는 개 품종 식별) 그러나 종종 단일 작업 중심으로 극도로 집중되어 있고 광범위한 재교육이 없어 약간 다른 환경(예: 크기가 다른 보드 또는 한 비디오 게임에서 다른 캐릭터와 설정)으로도 강력하고 *이전할 수 없는 방식*으로 이루어진다. 이러한 시스템은 종종 그들이 훈련받은 정확한 환경에 적용될 때 인상적으로 잘 작동한다. 하지만 우리는 환경이 훈련 받은 환경과 다를 경우, 작은 방법일지라도 그들을 믿을 수 없다. 이러한 시스템은 게임의 맥락에서 강력함을 보여주었다. 그러나 아직 현실 세계의 역동적이고 개방적인 흐름에서 적절한 것으로 입증되지는 않았다.

사람들은 강력한 지능을 점묘법적 지능(표면적으로는 비슷하고 다소 예측할 수 없는 방식의 많은 경우에 작동하지만 많은 다른 경우에서는 실패하는 지능)이라고 부르는 것과 대조해야 한다.  그림 1의 왼쪽은 일반적인 스쿨버스를 인식하지만, 눈길에 전복된 스쿨버스를 인식하지 못하는 경우를 보여준다. 그리고 오른쪽은 일부 문장을 정확하게 해석하지만 관련 없는 소재가 있을 때 실패하는 읽기 시스템을 보여준다.

![그림 1: 비전 및 언어의 특이적 오류](https://user-images.githubusercontent.com/76898072/104152556-413c6e00-5423-11eb-9443-45ca1d6c8661.png)

AI 문헌을 자세히 살펴보면 누구나 처음부터 강건성이 그 분야를 벗어났다는 것을 알게 될 것이다. 그 문제에 투입된 막대한 자원에도 불구하고, 딥러닝은 지금까지도 그 문제를 해결하지 못했다.

반대로, 지금까지의 딥러닝 기술은 데이터에 굶주리고, 얕고, 취약하며, 일반화 능력이 제한적이라는 것이 입증되었다(Marcus, 2018).

> *AI의 한계 : 우리가 특정 작업에서 매우 잘 수행하는 시스템을 설계할 수 있지만, 그것들은 여전히 취약하고, 데이터에 목말라하며, 훈련 데이터나 창작자의 가정으로부터 약간 벗어난 상황을 이해할 수 없으며, 중요한 작업 없이 새로운 작업을 처리하기 위해 용도를 변경할 수 없는 뚜렷한 한계를 가지고 있다.* <br>
  \- Facebook AI 연구팀 -

> *증가하는 증거에 따르면 최신 모델은 데이터셋에서 인간이 하는 유연하고 일반화 가능한 방법으로 의미를 배우는 대신에 가짜 통계 패턴을 활용하는 법을 배우고 있다.* <br>
  \-  Yoshua Bengio - 
  
> *현재의 기계 학습 방법은 연습에서 종종 필요한 훈련 분포를 넘어 일반화해야 할 때 약하게 보인다.*

AI를 한 단계 끌어올리기 위해 우리가 할 수 있는 일은 무엇인가?

우리는 Ernie Davis가 만든 시스템을 먼저 개발하지 않고서는 강력한 지능을 달성할 수 없다. 그리고 **Deep inderstanding**이란, 복잡한 데이터 세트의 미묘한 패턴을 상호 연관시키고 식별할 수 있는 능력뿐만 아니라, 어떤 시나리오도 살펴보고 기자가 물어볼 수 있는 질문*(who, what, why, when, how)*도 해결할 수 있는 능력이다.

널리 논의된 신경 네트워크 GPT-2(이야기나 주어진 문장 조각들을 만들어 냄)와 같은 시스템은 표면적으로 깊은 이해를 반영하는 것처럼 보이는 것을 전달할 수 있다. 예를 들어, "두 명의 병사가 술집에 들어왔다"와 같은 문장 조각은 종종 유창하고 그럴듯하게 들리는 연속성(예를 들어, 사람, 술집, 술집 및 돈 사이의 관계 : 두명의 군인이 모술에 있는 술집에 들어가서 그들의 모든 돈을 술값으로 썼다.)을 만들어낼 수 있다.
하지만 아무리 많은 GPT-2 사례가 설득력 있게 보여도 현실은 그것의 표현이 얇고, 종종 면밀한 검사 아래 무너지는 경우가 많다. 다음은 2019년 12월 NeurIPS에 제시된 개발 중 벤치마크에서 도출한 두 가지 대표적인 사례이다.

 - *어제 세탁소에 옷을 맡기고 아직 가지러 가지 않았다. 내 옷들은 어디있지?*
 - *통나무 위에 개구리 여섯 마리가 있다. 두 번 떠나고, 세 번 왔다. 통나무에 있는 개구리의 수는 현재 17마리이다.*

첫 번째 GPT-2는 의문 조각(위치 기준)을 따르지만 드라이 클리닝이 있는 위치를 추적하지 못하는 요소의 범주를 정확하게 예측한다. <br>
두 번째 GPT-2는 다시 올바른 반응 범주(이 경우 숫자)를 정확하게 예측하여 세부 정보를 파악하지 못한다. <br>
Marcus에서 논의된 바와 같이 이러한 오류는 널리 퍼져 있다. 우리는 견고함을 달성하기 위해서는 분명히 더 안정적인 기질이 필요할 것이다.

관련 사업은 딥러닝 툴박스 내에서 기능 근사 및 구성을 위한 도구를 꾸준히 개선하고, 대규모 학습 세트를 수집하여 점점 더 큰 규모의 GPU 및 TPU 군집으로 확장하는 데 주력해 왔다. 더 큰 데이터 세트를 수집하고, 다양한 방식으로 데이터 세트를 보강하며, 기본 아키텍처에 다양한 종류의 개선 사항을 통합함으로써 GPT-2와 같은 시스템을 개선할 수 있다. 이러한 접근 방식은 가치가 있지만, 보다 근본적인 재검토가 필요하다.

더 많은 과감한 접근법이 추진될 수 있다. Yoshua Bengi는 딥러닝 툴킷을 대폭 확장하기 위해 여러 가지 복잡한 제안(분포 변화에 대한 민감성을 통해 통계적으로 인과 관계를 추출하는 기술 개발, 모듈형 구조를 자동으로 추출하는 기술 등)을 했다.

하지만 이것으로는 충분하지 않다. 더 강한 방법이 필요하다. 특히, 시스템을 구축하기 위한 프레임워크를 개발해야 한다. 이 프레임워크는 **복잡한 외부 세계에 대한 내부 모델 구축, 업데이트 및 추론을 위해 해당 지식을 사용하여 추상적 지식 획득, 표현 및 조작할 수 있다.**

어떤 의미에서 *지식, 내부 모델, 추론* 등 전통적인 인공지능의 세 가지 관심사로 돌아가고 있다. 그러나 현대적 기술로 새로운 방식으로 그것들을 다루기를 희망합니다.

이러한 각각의 우려의 중심은 고전적인 AI에 있다. John McCarthy는 선구적인 논문 "상식이 있는 프로그램"에서 상식적인 지식의 가치를 언급했다. Doug Lenat는 그의 삶의 작품에서 기계가 해석할 수 있는 상식적인 지식을 표현했다. Terry Winograd(구글 창업자 Larry Page, Sergey Brin의 멘토)에 의해 설계된 고전적인 AI "blocks world" 시스템 SHRLDU는 축적된 물리적 물체 세트의 위치와 특성에 대한 소프트웨어의 이해를 나타내는 업데이트 가능한 인지 모델의 내부 모델을 확인시켰다. SHRLDU는 시간이 지남에 따라 블록 세계의 상태에 대한 추론을 하기 위해 인지 모델에 대해 추론했다.
~~기타 중요한 구성 요소( 간단한 물리학, 2-D 렌더러, 사용자 지정 도메인별 언어 구조 분석)는 가장 높은 피라미드의 서포트가 지원하는 가장 짧은 것이 녹색을 지원하는 것처럼 복잡한 문장들을 해독할 수 있는 것인가?~~
